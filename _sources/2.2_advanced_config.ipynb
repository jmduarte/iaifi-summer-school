{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKzGsHkWHyIN",
    "outputId": "6f23fee8-05f3-45a7-9a43-558b68c84af8"
   },
   "outputs": [],
   "source": [
    "!apt-get  -qq  install  -y  graphviz  &&  pip  install  pydot\n",
    "!pip  install  -U  matplotlib\n",
    "!pip  install  git+https://github.com/fastmachinelearning/hls4ml.git@main#egg=hls4ml[profiling]\n",
    "!pip  install  qkeras==0.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xMA9sXNHpPs"
   },
   "source": [
    "# Advanced Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-_uEPAmHpPs"
   },
   "source": [
    "## Load the dataset and model (if you are restarting from this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90kuGPh1HpPs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import plotting\n",
    "\n",
    "# import os\n",
    "# os.environ['PATH'] = '/opt/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "# for this tutorial we wont be actually running Vivado, so I have commented these lines out\n",
    "#     but if you want to look into actually running on an FPGA then simply uncomment these lines\n",
    "\n",
    "X_train_val = np.load(\"X_train_val.npy\")\n",
    "X_test = np.ascontiguousarray(np.load(\"X_test.npy\"))\n",
    "y_train_val = np.load(\"y_train_val.npy\")\n",
    "y_test = np.load(\"y_test.npy\", allow_pickle=True)\n",
    "classes = np.load(\"classes.npy\", allow_pickle=True)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"model_1/KERAS_check_best_model.h5\")\n",
    "y_keras = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTgJ3WInHpPs"
   },
   "source": [
    "## Make a new hls4ml config & model\n",
    "This time, we'll create a config with finer granularity. When we print the config dictionary, you'll notice that an entry is created for each named Layer of the model. See for the first layer, for example:\n",
    "```LayerName:\n",
    "    fc1:\n",
    "        Precision:\n",
    "            weight: ap_fixed<10,4>\n",
    "            bias:   ap_fixed<10,4>\n",
    "            result: ap_fixed<10,4>\n",
    "        ReuseFactor: 1\n",
    "```\n",
    "We will also modify the default_precision to be smaller than we know is good just to demonstrate the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ad2XumgoHpPt",
    "outputId": "81057fc9-14b7-4764-f982-d01c3bdd1f04"
   },
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    model, granularity=\"name\", default_precision=\"ap_fixed<10,4>\"\n",
    ")\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9GbtuCfHpPt"
   },
   "source": [
    "## Profiling\n",
    "As you can see, hls4ml will allow is to choose the precision of _everything_ in our Neural Network. This is a powerful way to tune the performance, but it's also complicated. Luckily there are tools in `hls4ml.model.profiling` that will help choose the right precision for a given model.\n",
    "\n",
    "The first thing we will do is to numerically profile the model. This method plots the distribution of the weights (and biases) as a box and whisker plot. The grey boxes show the values which can be represented with the data types used in the `hls_model`. Generally, you need the box to overlap completely with the whisker 'to the right' (large values) otherwise you'll get saturation & wrap-around issues from exceeding the top of the fixed-point range. It can be okay for the box not to overlap completely 'to the left' (small values), but finding how small you can go is a matter of trial-and-error.\n",
    "\n",
    "Providing data, in this case just using the first 1000 examples for speed, will show the same distributions captured at the output of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ytgFaddEHpPt",
    "outputId": "07c73acd-80f1-424c-8024-823e2b802366",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for layer in config[\"LayerName\"].keys():\n",
    "    config[\"LayerName\"][layer][\"Trace\"] = True\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    output_dir=\"model_1/hls4ml_prj_2\",\n",
    "    part=\"xcu250-figd2104-2L-e\",\n",
    ")\n",
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOKeWYYIHpPt"
   },
   "source": [
    "We can see that in this case the default precision of `ap_fixed<16,6>` will fully cover the upper range of the outputs from each layer. This is fully consistent with what we saw earlier from the ROC curve where the fixed-point model was capable of reproducing the floating point result. However, we know that reducing the integer or fractional precision slightly will begin to result in degraded performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "Qh60oT50HpPt",
    "outputId": "1dece026-961b-45a3-bdae-56a9ba94cbdd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "y_hls = hls_model.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"Keras  Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"hls4ml Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_keras, classes)\n",
    "plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls, classes, linestyle=\"--\")\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "lines = [Line2D([0], [0], ls=\"-\"), Line2D([0], [0], ls=\"--\")]\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "leg = Legend(ax, lines, labels=[\"keras\", \"hls4ml\"], loc=\"lower right\", frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkNIrbOwHpPt"
   },
   "source": [
    "Not good at all! Let's see if we can figure out how to create a model that will work at these lower precisions.\n",
    "\n",
    "The first thing we can try is adding some regularizers. This will penalize the model for using large weights, which can help to reduce the number of bits that are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0S4Qq28LHpPt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bL_UMkFxHpPu"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(\n",
    "        64,\n",
    "        input_shape=(16,),\n",
    "        name=\"fc1\",\n",
    "        kernel_initializer=\"lecun_uniform\",\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(activation=\"relu\", name=\"relu1\"))\n",
    "model.add(\n",
    "    Dense(\n",
    "        32,\n",
    "        name=\"fc2\",\n",
    "        kernel_initializer=\"lecun_uniform\",\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(activation=\"relu\", name=\"relu2\"))\n",
    "model.add(\n",
    "    Dense(\n",
    "        32,\n",
    "        name=\"fc3\",\n",
    "        kernel_initializer=\"lecun_uniform\",\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(activation=\"relu\", name=\"relu3\"))\n",
    "model.add(\n",
    "    Dense(\n",
    "        5,\n",
    "        name=\"output\",\n",
    "        kernel_initializer=\"lecun_uniform\",\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(activation=\"softmax\", name=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVsTAFjkHpPu",
    "outputId": "6ad8fd92-31d3-4a06-94d8-2a9726b32c67"
   },
   "outputs": [],
   "source": [
    "train = True\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(\n",
    "        optimizer=adam, loss=[\"categorical_crossentropy\"], metrics=[\"accuracy\"]\n",
    "    )\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir=\"model_2\",\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        batch_size=1024,\n",
    "        epochs=30,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "    )\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    model = load_model(\"model_2/KERAS_check_best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xdw14e95HpPu"
   },
   "source": [
    "Again we will se the default precision to be `ap_fixed<10,4>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9GqXvtnBHpPu",
    "outputId": "69f93417-b7cb-4360-e2d0-dec6370b0ac2"
   },
   "outputs": [],
   "source": [
    "for layer in config[\"LayerName\"].keys():\n",
    "    config[\"LayerName\"][layer][\"Trace\"] = True\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    output_dir=\"model_2/hls4ml_prj_1\",\n",
    "    part=\"xcu250-figd2104-2L-e\",\n",
    ")\n",
    "\n",
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_test[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0XFsNmGHpPu"
   },
   "source": [
    "You can see the difference in the weight profile plots between this model and the previous one quite clearly. Whereas before the smallest weight in the first layer was approximately $10^{-14}$, now its almost $10^{-24}$! However, it hasn't markedly improved the upper bound of the layers post-activation, so we will need to try something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4mHUXyeHpPu"
   },
   "source": [
    "## Trace\n",
    "Another thing we can try is to use different precisions in different layers. In this case, it seems that the third layer is the one with the largest output, so perhaps we could increase only that precision and leave the others as is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDGOfKEIHpPu",
    "outputId": "42cbca32-be8c-451e-c426-8a17fbd6879b"
   },
   "outputs": [],
   "source": [
    "config[\"LayerName\"][\"fc1\"][\"Precision\"][\"weight\"] = \"ap_fixed<12,6>\"\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    output_dir=\"model_2/hls4ml_prj_2\",\n",
    "    part=\"xcu250-figd2104-2L-e\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTXbbj5gHpPv"
   },
   "source": [
    "Now lets check how this model performs. We are also going to enable a functionality that will extract the intermediate network values from each layer, for botht the hls4ml model and the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlV52oWuHpPv",
    "outputId": "6a8cb8e6-f3d2-4d60-e1fa-8d0d90732d8a"
   },
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "hls4ml_pred, hls4ml_trace = hls_model.trace(X_test[:1000])\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test[:1000])\n",
    "y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTdCRzV4HpPv"
   },
   "source": [
    "## Inspect\n",
    "Now we can print out, make plots, or do any other more detailed analysis on the output of each layer to understand the performance we see. Let's print the output of that third layer, for the first sample, for both the Keras and hls4ml models, and also make a plot of the mean difference per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqlhqEDXHpPv",
    "outputId": "cf3bbf09-ee9e-44f0-e919-0f77123115ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Keras layer 'fc3', first sample:\")\n",
    "print(keras_trace[\"fc3\"][0])\n",
    "print(\"hls4ml layer 'fc3', first sample:\")\n",
    "print(hls4ml_trace[\"fc3\"][0])\n",
    "print(\"layer fc3 diff, first sample:\")\n",
    "print(hls4ml_trace[\"fc3\"][0] - keras_trace[\"fc3\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "gdpQT-3SHpPv",
    "outputId": "dac2ac62-9c7e-40b9-ad7a-30a2c3b11ead",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    np.mean(hls4ml_trace[\"fc3\"] - keras_trace[\"fc3\"], axis=-1),\n",
    "    bins=np.linspace(-1.0, 1.0, 51),\n",
    "    density=True,\n",
    ")\n",
    "plt.xlabel(\"mean difference (hls4ml - keras)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnQJvOehHpPv"
   },
   "source": [
    "## Compare \n",
    "It's not looking great. Let's check the accuracy and ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "rPFgU9yAHpPw",
    "outputId": "061f1ecf-d9b7-4fae-fe12-5edc55252ea6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Keras  Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"hls4ml Accuracy: {}\".format(\n",
    "        accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_keras, classes)\n",
    "plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls, classes, linestyle=\"--\")\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "lines = [Line2D([0], [0], ls=\"-\"), Line2D([0], [0], ls=\"--\")]\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "leg = Legend(ax, lines, labels=[\"keras\", \"hls4ml\"], loc=\"lower right\", frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYbglF3HpPw"
   },
   "source": [
    "### Improving\n",
    "Better, but still not great, especially depending on which class we look at. In principle we could try this for other layers, but eventually we may find we are just back to a larger model. Let's look at some other methods for reducing the size of the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python  3  (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
