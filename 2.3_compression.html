
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Compression (Pruning) &#8212; IAIFI Summer School Tutorials</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jduarte.physics.ucsd.edu/iaifi-summer-school/2.3_compression.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quantization" href="2.4_quantization.html" />
    <link rel="prev" title="Advanced Configuration" href="2.2_advanced_config.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IAIFI Summer School Tutorials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    IAIFI Summer School Tutorials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations, Networks, and Symmetries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1.1_tabular_data_efps.html">
   Tabular Data using Energy Flow Polynomials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.2_jet_images.html">
   Jet Images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.3_deep_sets.html">
   Deep Sets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.4_gnn_in.html">
   Interaction Network GNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.5_gnn_lorentz.html">
   Lorentz-Equivariant GNN
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model Compression and Fast Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2.1_getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.2_advanced_config.html">
   Advanced Configuration
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Compression (Pruning)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.4_quantization.html">
   Quantization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jmduarte/iaifi-summer-school/main?urlpath=tree/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jmduarte/iaifi-summer-school/blob/main/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school/issues/new?title=Issue%20on%20page%20%2F2.3_compression.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Compression (Pruning)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>apt-get  -qq  install  -y  graphviz  <span class="o">&amp;&amp;</span>  pip  install  pydot
<span class="o">!</span>pip  install  -U  matplotlib
<span class="o">!</span>pip  install  git+https://github.com/fastmachinelearning/hls4ml.git@main#egg<span class="o">=</span>hls4ml<span class="o">[</span>profiling<span class="o">]</span>
<span class="o">!</span>pip  install  <span class="nv">qkeras</span><span class="o">==</span><span class="m">0</span>.9.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)
E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (3.5.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: numpy&gt;=1.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.21.6)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (9.2.0)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (21.3)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (4.34.4)
Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (0.11.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib) (4.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting hls4ml[profiling]
  Cloning https://github.com/fastmachinelearning/hls4ml.git (to revision main) to /tmp/pip-install-8daxafwk/hls4ml_d558f2da942a414b8f81affdd7d7db34
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Running command git clone --filter=blob:none --quiet https://github.com/fastmachinelearning/hls4ml.git /tmp/pip-install-8daxafwk/hls4ml_d558f2da942a414b8f81affdd7d7db34
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Resolved https://github.com/fastmachinelearning/hls4ml.git to commit 62046d799a4dbec150addc7f78fea5b579efeda1
  Running command git submodule update --init --recursive -q
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Preparing metadata (setup.py) ... ?25l-
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> done
?25hRequirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.21.6)
Requirement already satisfied: six in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.16.0)
Requirement already satisfied: pyyaml in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (6.0)
Requirement already satisfied: h5py in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.7.0)
Requirement already satisfied: onnx&gt;=1.4.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.12.0)
Requirement already satisfied: calmjs.parse in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.0)
Requirement already satisfied: tabulate in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.8.10)
Requirement already satisfied: pydigitalwavetools==1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.1)
Requirement already satisfied: qkeras in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.9.0)
Requirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.5)
Requirement already satisfied: seaborn in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.11.2)
Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.5.2)
Requirement already satisfied: protobuf&lt;=3.20.1,&gt;=3.12.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (3.19.4)
Requirement already satisfied: typing-extensions&gt;=3.6.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (4.3.0)
Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (63.3.0)
Requirement already satisfied: ply&gt;=3.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (3.11)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (4.34.4)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (1.4.4)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (21.3)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (9.2.0)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (2.8.2)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (3.0.9)
Requirement already satisfied: pytz&gt;=2017.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pandas-&gt;hls4ml[profiling]) (2022.1)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (0.7.3)
Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (2.6.3)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (4.64.0)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.7.3)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.1.3)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.0.4)
Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (7.34.0)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.28.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.1.0)
Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.7)
Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras-&gt;hls4ml[profiling]) (1.6.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.12.0)
Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.0)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.18.1)
Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.1.1)
Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.8.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.0.30)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.3)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.5)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.3.0)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2022.6.15)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.26.11)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.4.1)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.2.0)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.37.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.8.1)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.47.0)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.6.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.2.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.6)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.2.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.8)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.9)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.3.1)
Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.0)
Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.8.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.2.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: qkeras==0.9.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (0.9.0)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (0.7.3)
Requirement already satisfied: numpy&gt;=1.16.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.21.6)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (4.64.0)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0.2)
Requirement already satisfied: setuptools&gt;=41.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (63.3.0)
Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.1.3)
Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (2.6.3)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.7.3)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.28.1)
Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (7.34.0)
Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.0.4)
Requirement already satisfied: packaging in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (21.3)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (3.1.0)
Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (0.1.7)
Requirement already satisfied: six~=1.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (1.16.0)
Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras==0.9.0) (1.6.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.1.1)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.1.3)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.3.0)
Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.30)
Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.8.0)
Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.12.0)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.18.1)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.5)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from packaging-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.9)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2022.6.15)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.26.11)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.3)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.6.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.6)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.37.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.2.1)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.2.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.47.0)
Requirement already satisfied: protobuf&lt;3.20,&gt;=3.9.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.19.4)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.4.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.8)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.2.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.3.1)
Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.5)
Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions&gt;=3.6.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.3.0)
Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.8.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.2.0)
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="compression-pruning">
<h1>Compression (Pruning)<a class="headerlink" href="#compression-pruning" title="Permalink to this headline">#</a></h1>
<section id="load-the-dataset-if-you-are-restarting-from-this-point">
<h2>Load the dataset (if you are restarting from this point)<a class="headerlink" href="#load-the-dataset-if-you-are-restarting-from-this-point" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># import os</span>
<span class="c1"># os.environ[&#39;PATH&#39;] = &#39;/opt/Xilinx/Vivado/2019.2/bin:&#39; + os.environ[&#39;PATH&#39;]</span>
<span class="c1"># for this tutorial we wont be actually running Vivado, so I have commented these lines out</span>
<span class="c1">#     but if you want to look into actually running on an FPGA then simply uncomment these lines</span>

<span class="n">X_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_train_val.npy&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
<span class="n">y_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_train_val.npy&quot;</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;classes.npy&quot;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 00:57:08.450488: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 00:57:08.450518: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div>
</div>
</div>
</div>
</section>
<section id="construct-a-new-model">
<h2>Construct a new model<a class="headerlink" href="#construct-a-new-model" title="Permalink to this headline">#</a></h2>
<p>We’ll now use the same architecture as we originally used: 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span>
<span class="kn">from</span> <span class="nn">callbacks</span> <span class="kn">import</span> <span class="n">all_callbacks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">64</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 00:57:11.476086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 00:57:11.476130: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-08-02 00:57:11.476150: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az47-558): /proc/driver/nvidia/version does not exist
2022-08-02 00:57:11.476395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-sparse">
<h2>Train sparse<a class="headerlink" href="#train-sparse" title="Permalink to this headline">#</a></h2>
<p>This time we’ll use the Tensorflow model optimization sparsity to train a sparse model (forcing many weights to ‘0’). In this instance, the target sparsity is 75%</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.75</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model">
<h2>Train the model<a class="headerlink" href="#train-the-model" title="Permalink to this headline">#</a></h2>
<p>We’ll use the same settings as the previous model: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory ‘model_3’
The model isn’t very complex, so this should just take a few minutes even on the CPU.
If you’ve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_3&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 20:29 - loss: 1.6388 - accuracy: 0.3027
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0078s). Check your callbacks.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 1.6334 - accuracy: 0.2803   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 1.6132 - accuracy: 0.3037
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 62/487 [==&gt;...........................] - ETA: 1s - loss: 1.5949 - accuracy: 0.3280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/487 [====&gt;.........................] - ETA: 1s - loss: 1.5779 - accuracy: 0.3469
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
103/487 [=====&gt;........................] - ETA: 0s - loss: 1.5630 - accuracy: 0.3606
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
123/487 [======&gt;.......................] - ETA: 0s - loss: 1.5493 - accuracy: 0.3712
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 1.5346 - accuracy: 0.3831
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 1.5199 - accuracy: 0.3955
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 1.5062 - accuracy: 0.4054
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
203/487 [===========&gt;..................] - ETA: 0s - loss: 1.4915 - accuracy: 0.4147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 1.4778 - accuracy: 0.4218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
243/487 [=============&gt;................] - ETA: 0s - loss: 1.4645 - accuracy: 0.4299
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
264/487 [===============&gt;..............] - ETA: 0s - loss: 1.4509 - accuracy: 0.4377
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
285/487 [================&gt;.............] - ETA: 0s - loss: 1.4372 - accuracy: 0.4464
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
305/487 [=================&gt;............] - ETA: 0s - loss: 1.4244 - accuracy: 0.4554
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
325/487 [===================&gt;..........] - ETA: 0s - loss: 1.4121 - accuracy: 0.4643
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
345/487 [====================&gt;.........] - ETA: 0s - loss: 1.4002 - accuracy: 0.4725
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
365/487 [=====================&gt;........] - ETA: 0s - loss: 1.3889 - accuracy: 0.4799
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/487 [======================&gt;.......] - ETA: 0s - loss: 1.3778 - accuracy: 0.4869
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
405/487 [=======================&gt;......] - ETA: 0s - loss: 1.3674 - accuracy: 0.4934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
425/487 [=========================&gt;....] - ETA: 0s - loss: 1.3571 - accuracy: 0.4996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
445/487 [==========================&gt;...] - ETA: 0s - loss: 1.3474 - accuracy: 0.5054
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
465/487 [===========================&gt;..] - ETA: 0s - loss: 1.3383 - accuracy: 0.5108
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 1.3292 - accuracy: 0.5160
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 4s 4ms/step - loss: 1.3290 - accuracy: 0.5161 - val_loss: 1.1252 - val_accuracy: 0.6363 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 1.1001 - accuracy: 0.6299
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 1.1162 - accuracy: 0.6376
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 1.1173 - accuracy: 0.6369
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 62/487 [==&gt;...........................] - ETA: 1s - loss: 1.1144 - accuracy: 0.6395
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 82/487 [====&gt;.........................] - ETA: 1s - loss: 1.1078 - accuracy: 0.6417
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 0s - loss: 1.1059 - accuracy: 0.6428
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 1.1029 - accuracy: 0.6439
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 1.0983 - accuracy: 0.6463
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 1.0952 - accuracy: 0.6479
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
184/487 [==========&gt;...................] - ETA: 0s - loss: 1.0923 - accuracy: 0.6493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 1.0894 - accuracy: 0.6504
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
225/487 [============&gt;.................] - ETA: 0s - loss: 1.0858 - accuracy: 0.6524
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
246/487 [==============&gt;...............] - ETA: 0s - loss: 1.0832 - accuracy: 0.6540
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/487 [===============&gt;..............] - ETA: 0s - loss: 1.0808 - accuracy: 0.6551
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/487 [================&gt;.............] - ETA: 0s - loss: 1.0780 - accuracy: 0.6566
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 1.0754 - accuracy: 0.6578
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 1.0732 - accuracy: 0.6588
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/487 [====================&gt;.........] - ETA: 0s - loss: 1.0705 - accuracy: 0.6600
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/487 [=====================&gt;........] - ETA: 0s - loss: 1.0677 - accuracy: 0.6613
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
392/487 [=======================&gt;......] - ETA: 0s - loss: 1.0648 - accuracy: 0.6626
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/487 [========================&gt;.....] - ETA: 0s - loss: 1.0628 - accuracy: 0.6634
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
434/487 [=========================&gt;....] - ETA: 0s - loss: 1.0604 - accuracy: 0.6644
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
454/487 [==========================&gt;...] - ETA: 0s - loss: 1.0586 - accuracy: 0.6653
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
474/487 [============================&gt;.] - ETA: 0s - loss: 1.0564 - accuracy: 0.6663
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0550 - accuracy: 0.6668 - val_loss: 1.0071 - val_accuracy: 0.6900 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9859 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 1.0066 - accuracy: 0.6899
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.9997 - accuracy: 0.6893
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 60/487 [==&gt;...........................] - ETA: 1s - loss: 1.0011 - accuracy: 0.6897
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 80/487 [===&gt;..........................] - ETA: 1s - loss: 0.9983 - accuracy: 0.6901
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
100/487 [=====&gt;........................] - ETA: 1s - loss: 0.9966 - accuracy: 0.6908
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
120/487 [======&gt;.......................] - ETA: 0s - loss: 0.9973 - accuracy: 0.6905
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
140/487 [=======&gt;......................] - ETA: 0s - loss: 0.9966 - accuracy: 0.6909
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
160/487 [========&gt;.....................] - ETA: 0s - loss: 0.9935 - accuracy: 0.6925
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
180/487 [==========&gt;...................] - ETA: 0s - loss: 0.9917 - accuracy: 0.6936
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
200/487 [===========&gt;..................] - ETA: 0s - loss: 0.9907 - accuracy: 0.6938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
220/487 [============&gt;.................] - ETA: 0s - loss: 0.9894 - accuracy: 0.6943
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
240/487 [=============&gt;................] - ETA: 0s - loss: 0.9879 - accuracy: 0.6950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
260/487 [===============&gt;..............] - ETA: 0s - loss: 0.9862 - accuracy: 0.6958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
280/487 [================&gt;.............] - ETA: 0s - loss: 0.9846 - accuracy: 0.6962
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
299/487 [=================&gt;............] - ETA: 0s - loss: 0.9827 - accuracy: 0.6968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
319/487 [==================&gt;...........] - ETA: 0s - loss: 0.9818 - accuracy: 0.6970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
339/487 [===================&gt;..........] - ETA: 0s - loss: 0.9811 - accuracy: 0.6973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
359/487 [=====================&gt;........] - ETA: 0s - loss: 0.9797 - accuracy: 0.6978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
379/487 [======================&gt;.......] - ETA: 0s - loss: 0.9784 - accuracy: 0.6982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
399/487 [=======================&gt;......] - ETA: 0s - loss: 0.9769 - accuracy: 0.6987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
419/487 [========================&gt;.....] - ETA: 0s - loss: 0.9758 - accuracy: 0.6991
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
438/487 [=========================&gt;....] - ETA: 0s - loss: 0.9744 - accuracy: 0.6995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
457/487 [===========================&gt;..] - ETA: 0s - loss: 0.9731 - accuracy: 0.6999
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
477/487 [============================&gt;.] - ETA: 0s - loss: 0.9718 - accuracy: 0.7003
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9712 - accuracy: 0.7004 - val_loss: 0.9450 - val_accuracy: 0.7098 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9507 - accuracy: 0.7021
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.9433 - accuracy: 0.7085
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.9387 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.9414 - accuracy: 0.7104
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.9407 - accuracy: 0.7107
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
101/487 [=====&gt;........................] - ETA: 0s - loss: 0.9401 - accuracy: 0.7105
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 0.9376 - accuracy: 0.7111
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 0.9349 - accuracy: 0.7114
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/487 [=========&gt;....................] - ETA: 0s - loss: 0.9330 - accuracy: 0.7117
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
185/487 [==========&gt;...................] - ETA: 0s - loss: 0.9327 - accuracy: 0.7116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/487 [===========&gt;..................] - ETA: 0s - loss: 0.9313 - accuracy: 0.7116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
227/487 [============&gt;.................] - ETA: 0s - loss: 0.9296 - accuracy: 0.7120
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
248/487 [==============&gt;...............] - ETA: 0s - loss: 0.9288 - accuracy: 0.7121
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
268/487 [===============&gt;..............] - ETA: 0s - loss: 0.9282 - accuracy: 0.7121
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/487 [================&gt;.............] - ETA: 0s - loss: 0.9270 - accuracy: 0.7124
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 0.9262 - accuracy: 0.7126
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
330/487 [===================&gt;..........] - ETA: 0s - loss: 0.9247 - accuracy: 0.7130
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/487 [====================&gt;.........] - ETA: 0s - loss: 0.9238 - accuracy: 0.7133
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 0.9226 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
392/487 [=======================&gt;......] - ETA: 0s - loss: 0.9221 - accuracy: 0.7136
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/487 [========================&gt;.....] - ETA: 0s - loss: 0.9216 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
434/487 [=========================&gt;....] - ETA: 0s - loss: 0.9205 - accuracy: 0.7138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
454/487 [==========================&gt;...] - ETA: 0s - loss: 0.9195 - accuracy: 0.7140
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
475/487 [============================&gt;.] - ETA: 0s - loss: 0.9186 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9183 - accuracy: 0.7143 - val_loss: 0.9005 - val_accuracy: 0.7187 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8668 - accuracy: 0.7334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8882 - accuracy: 0.7204
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8911 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.9480 - accuracy: 0.6853
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 1.0547 - accuracy: 0.6254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 95/487 [====&gt;.........................] - ETA: 1s - loss: 1.1004 - accuracy: 0.6028
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
114/487 [======&gt;.......................] - ETA: 0s - loss: 1.1194 - accuracy: 0.5983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/487 [=======&gt;......................] - ETA: 0s - loss: 1.1280 - accuracy: 0.6009
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
154/487 [========&gt;.....................] - ETA: 0s - loss: 1.1308 - accuracy: 0.6053
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
174/487 [=========&gt;....................] - ETA: 0s - loss: 1.1296 - accuracy: 0.6099
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
194/487 [==========&gt;...................] - ETA: 0s - loss: 1.1273 - accuracy: 0.6138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/487 [============&gt;.................] - ETA: 0s - loss: 1.1231 - accuracy: 0.6176
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
234/487 [=============&gt;................] - ETA: 0s - loss: 1.1200 - accuracy: 0.6200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
254/487 [==============&gt;...............] - ETA: 0s - loss: 1.1159 - accuracy: 0.6229
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/487 [===============&gt;..............] - ETA: 0s - loss: 1.1118 - accuracy: 0.6254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/487 [=================&gt;............] - ETA: 0s - loss: 1.1082 - accuracy: 0.6273
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
313/487 [==================&gt;...........] - ETA: 0s - loss: 1.1050 - accuracy: 0.6288
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
333/487 [===================&gt;..........] - ETA: 0s - loss: 1.1014 - accuracy: 0.6304
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
352/487 [====================&gt;.........] - ETA: 0s - loss: 1.0979 - accuracy: 0.6321
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 1.0943 - accuracy: 0.6336
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
392/487 [=======================&gt;......] - ETA: 0s - loss: 1.0908 - accuracy: 0.6351
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/487 [========================&gt;.....] - ETA: 0s - loss: 1.0873 - accuracy: 0.6365
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
432/487 [=========================&gt;....] - ETA: 0s - loss: 1.0837 - accuracy: 0.6379
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
452/487 [==========================&gt;...] - ETA: 0s - loss: 1.0804 - accuracy: 0.6393
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
472/487 [============================&gt;.] - ETA: 0s - loss: 1.0770 - accuracy: 0.6406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0749 - accuracy: 0.6415 - val_loss: 0.9990 - val_accuracy: 0.6722 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.9407 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.9816 - accuracy: 0.6824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.9890 - accuracy: 0.6777
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.9896 - accuracy: 0.6761
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.9901 - accuracy: 0.6765
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 0s - loss: 0.9869 - accuracy: 0.6771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 0.9858 - accuracy: 0.6775
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 0.9842 - accuracy: 0.6777
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 0.9819 - accuracy: 0.6786
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 0.9801 - accuracy: 0.6790
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.9795 - accuracy: 0.6794
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
225/487 [============&gt;.................] - ETA: 0s - loss: 0.9784 - accuracy: 0.6796
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
246/487 [==============&gt;...............] - ETA: 0s - loss: 0.9764 - accuracy: 0.6807
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/487 [===============&gt;..............] - ETA: 0s - loss: 0.9743 - accuracy: 0.6817
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/487 [================&gt;.............] - ETA: 0s - loss: 0.9731 - accuracy: 0.6824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 0.9722 - accuracy: 0.6827
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
330/487 [===================&gt;..........] - ETA: 0s - loss: 0.9714 - accuracy: 0.6828
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/487 [====================&gt;.........] - ETA: 0s - loss: 0.9700 - accuracy: 0.6833
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 0.9688 - accuracy: 0.6839
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
393/487 [=======================&gt;......] - ETA: 0s - loss: 0.9669 - accuracy: 0.6845
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
414/487 [========================&gt;.....] - ETA: 0s - loss: 0.9656 - accuracy: 0.6848
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
435/487 [=========================&gt;....] - ETA: 0s - loss: 0.9645 - accuracy: 0.6851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
454/487 [==========================&gt;...] - ETA: 0s - loss: 0.9632 - accuracy: 0.6856
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
473/487 [============================&gt;.] - ETA: 0s - loss: 0.9621 - accuracy: 0.6861
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9615 - accuracy: 0.6864 - val_loss: 0.9364 - val_accuracy: 0.6952 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.9119 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/487 [&gt;.............................] - ETA: 1s - loss: 0.9275 - accuracy: 0.6986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/487 [=&gt;............................] - ETA: 1s - loss: 0.9378 - accuracy: 0.6950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 63/487 [==&gt;...........................] - ETA: 1s - loss: 0.9351 - accuracy: 0.6960
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/487 [====&gt;.........................] - ETA: 1s - loss: 0.9331 - accuracy: 0.6962
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
103/487 [=====&gt;........................] - ETA: 0s - loss: 0.9316 - accuracy: 0.6964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
124/487 [======&gt;.......................] - ETA: 0s - loss: 0.9288 - accuracy: 0.6975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
145/487 [=======&gt;......................] - ETA: 0s - loss: 0.9297 - accuracy: 0.6972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
165/487 [=========&gt;....................] - ETA: 0s - loss: 0.9291 - accuracy: 0.6972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
186/487 [==========&gt;...................] - ETA: 0s - loss: 0.9283 - accuracy: 0.6974
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/487 [===========&gt;..................] - ETA: 0s - loss: 0.9268 - accuracy: 0.6982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
227/487 [============&gt;.................] - ETA: 0s - loss: 0.9261 - accuracy: 0.6983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/487 [==============&gt;...............] - ETA: 0s - loss: 0.9249 - accuracy: 0.6987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/487 [===============&gt;..............] - ETA: 0s - loss: 0.9239 - accuracy: 0.6992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/487 [================&gt;.............] - ETA: 0s - loss: 0.9230 - accuracy: 0.6995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
307/487 [=================&gt;............] - ETA: 0s - loss: 0.9214 - accuracy: 0.7002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
327/487 [===================&gt;..........] - ETA: 0s - loss: 0.9210 - accuracy: 0.7003
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
347/487 [====================&gt;.........] - ETA: 0s - loss: 0.9197 - accuracy: 0.7006
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 0.9188 - accuracy: 0.7008
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.9181 - accuracy: 0.7011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
406/487 [========================&gt;.....] - ETA: 0s - loss: 0.9176 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
425/487 [=========================&gt;....] - ETA: 0s - loss: 0.9169 - accuracy: 0.7013
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
444/487 [==========================&gt;...] - ETA: 0s - loss: 0.9169 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
464/487 [===========================&gt;..] - ETA: 0s - loss: 0.9164 - accuracy: 0.7013
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
483/487 [============================&gt;.] - ETA: 0s - loss: 0.9159 - accuracy: 0.7015
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9157 - accuracy: 0.7015 - val_loss: 0.9021 - val_accuracy: 0.7052 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9369 - accuracy: 0.6934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8925 - accuracy: 0.7069
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.8935 - accuracy: 0.7082
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8964 - accuracy: 0.7059
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 80/487 [===&gt;..........................] - ETA: 1s - loss: 0.8973 - accuracy: 0.7062
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/487 [=====&gt;........................] - ETA: 1s - loss: 0.8964 - accuracy: 0.7067
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/487 [======&gt;.......................] - ETA: 0s - loss: 0.8978 - accuracy: 0.7064
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
139/487 [=======&gt;......................] - ETA: 0s - loss: 0.8978 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
159/487 [========&gt;.....................] - ETA: 0s - loss: 0.8959 - accuracy: 0.7069
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
179/487 [==========&gt;...................] - ETA: 0s - loss: 0.8961 - accuracy: 0.7069
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
196/487 [===========&gt;..................] - ETA: 0s - loss: 0.8950 - accuracy: 0.7075
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
216/487 [============&gt;.................] - ETA: 0s - loss: 0.8955 - accuracy: 0.7073
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
236/487 [=============&gt;................] - ETA: 0s - loss: 0.8944 - accuracy: 0.7078
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/487 [==============&gt;...............] - ETA: 0s - loss: 0.8942 - accuracy: 0.7080
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
276/487 [================&gt;.............] - ETA: 0s - loss: 0.8931 - accuracy: 0.7083
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
296/487 [=================&gt;............] - ETA: 0s - loss: 0.8921 - accuracy: 0.7087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
316/487 [==================&gt;...........] - ETA: 0s - loss: 0.8916 - accuracy: 0.7087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/487 [===================&gt;..........] - ETA: 0s - loss: 0.8915 - accuracy: 0.7087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
358/487 [=====================&gt;........] - ETA: 0s - loss: 0.8911 - accuracy: 0.7088
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
378/487 [======================&gt;.......] - ETA: 0s - loss: 0.8906 - accuracy: 0.7089
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
397/487 [=======================&gt;......] - ETA: 0s - loss: 0.8897 - accuracy: 0.7091
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
416/487 [========================&gt;.....] - ETA: 0s - loss: 0.8891 - accuracy: 0.7092
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
436/487 [=========================&gt;....] - ETA: 0s - loss: 0.8885 - accuracy: 0.7093
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
456/487 [===========================&gt;..] - ETA: 0s - loss: 0.8881 - accuracy: 0.7095
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
476/487 [============================&gt;.] - ETA: 0s - loss: 0.8869 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8865 - accuracy: 0.7102 - val_loss: 0.8775 - val_accuracy: 0.7122 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8805 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8701 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.8726 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 60/487 [==&gt;...........................] - ETA: 1s - loss: 0.8707 - accuracy: 0.7136
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 80/487 [===&gt;..........................] - ETA: 1s - loss: 0.8705 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
100/487 [=====&gt;........................] - ETA: 0s - loss: 0.8718 - accuracy: 0.7138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
120/487 [======&gt;.......................] - ETA: 0s - loss: 0.8697 - accuracy: 0.7147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/487 [=======&gt;......................] - ETA: 0s - loss: 0.8710 - accuracy: 0.7135
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
161/487 [========&gt;.....................] - ETA: 0s - loss: 0.8711 - accuracy: 0.7135
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/487 [==========&gt;...................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7141
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
202/487 [===========&gt;..................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7141
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 0.8694 - accuracy: 0.7144
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
244/487 [==============&gt;...............] - ETA: 0s - loss: 0.8695 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
265/487 [===============&gt;..............] - ETA: 0s - loss: 0.8688 - accuracy: 0.7147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
286/487 [================&gt;.............] - ETA: 0s - loss: 0.8678 - accuracy: 0.7152
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
307/487 [=================&gt;............] - ETA: 0s - loss: 0.8672 - accuracy: 0.7153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/487 [===================&gt;..........] - ETA: 0s - loss: 0.8675 - accuracy: 0.7149
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
349/487 [====================&gt;.........] - ETA: 0s - loss: 0.8668 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
370/487 [=====================&gt;........] - ETA: 0s - loss: 0.8670 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/487 [=======================&gt;......] - ETA: 0s - loss: 0.8668 - accuracy: 0.7152
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/487 [========================&gt;.....] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
433/487 [=========================&gt;....] - ETA: 0s - loss: 0.8668 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
454/487 [==========================&gt;...] - ETA: 0s - loss: 0.8665 - accuracy: 0.7152
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
475/487 [============================&gt;.] - ETA: 0s - loss: 0.8658 - accuracy: 0.7156
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8655 - accuracy: 0.7156 - val_loss: 0.8604 - val_accuracy: 0.7173 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8281 - accuracy: 0.7246
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8626 - accuracy: 0.7165
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/487 [=&gt;............................] - ETA: 1s - loss: 0.8607 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 62/487 [==&gt;...........................] - ETA: 1s - loss: 0.8591 - accuracy: 0.7171
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 82/487 [====&gt;.........................] - ETA: 1s - loss: 0.8573 - accuracy: 0.7173
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 0s - loss: 0.8544 - accuracy: 0.7182
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 0.8538 - accuracy: 0.7183
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
142/487 [=======&gt;......................] - ETA: 0s - loss: 0.8516 - accuracy: 0.7197
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 0.8517 - accuracy: 0.7196
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 0.8526 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
203/487 [===========&gt;..................] - ETA: 0s - loss: 0.8532 - accuracy: 0.7187
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 0.8530 - accuracy: 0.7186
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
243/487 [=============&gt;................] - ETA: 0s - loss: 0.8523 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
263/487 [===============&gt;..............] - ETA: 0s - loss: 0.8519 - accuracy: 0.7191
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
283/487 [================&gt;.............] - ETA: 0s - loss: 0.8516 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
303/487 [=================&gt;............] - ETA: 0s - loss: 0.8512 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
323/487 [==================&gt;...........] - ETA: 0s - loss: 0.8513 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
343/487 [====================&gt;.........] - ETA: 0s - loss: 0.8505 - accuracy: 0.7198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
364/487 [=====================&gt;........] - ETA: 0s - loss: 0.8504 - accuracy: 0.7198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/487 [======================&gt;.......] - ETA: 0s - loss: 0.8503 - accuracy: 0.7199
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
405/487 [=======================&gt;......] - ETA: 0s - loss: 0.8501 - accuracy: 0.7198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
426/487 [=========================&gt;....] - ETA: 0s - loss: 0.8507 - accuracy: 0.7196
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
447/487 [==========================&gt;...] - ETA: 0s - loss: 0.8505 - accuracy: 0.7195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.8506 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8507 - accuracy: 0.7192
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_epoch10.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8506 - accuracy: 0.7192 - val_loss: 0.8477 - val_accuracy: 0.7208 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8714 - accuracy: 0.7158
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8338 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.8424 - accuracy: 0.7221
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 0.8415 - accuracy: 0.7229
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/487 [===&gt;..........................] - ETA: 1s - loss: 0.8411 - accuracy: 0.7229
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/487 [=====&gt;........................] - ETA: 1s - loss: 0.8437 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/487 [======&gt;.......................] - ETA: 0s - loss: 0.8424 - accuracy: 0.7212
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
139/487 [=======&gt;......................] - ETA: 0s - loss: 0.8416 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
160/487 [========&gt;.....................] - ETA: 0s - loss: 0.8429 - accuracy: 0.7210
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
181/487 [==========&gt;...................] - ETA: 0s - loss: 0.8421 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
202/487 [===========&gt;..................] - ETA: 0s - loss: 0.8414 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 0.8419 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
243/487 [=============&gt;................] - ETA: 0s - loss: 0.8420 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
263/487 [===============&gt;..............] - ETA: 0s - loss: 0.8413 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
283/487 [================&gt;.............] - ETA: 0s - loss: 0.8412 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
303/487 [=================&gt;............] - ETA: 0s - loss: 0.8411 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
323/487 [==================&gt;...........] - ETA: 0s - loss: 0.8413 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
341/487 [====================&gt;.........] - ETA: 0s - loss: 0.8404 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
361/487 [=====================&gt;........] - ETA: 0s - loss: 0.8401 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
381/487 [======================&gt;.......] - ETA: 0s - loss: 0.8403 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
401/487 [=======================&gt;......] - ETA: 0s - loss: 0.8404 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/487 [========================&gt;.....] - ETA: 0s - loss: 0.8404 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
441/487 [==========================&gt;...] - ETA: 0s - loss: 0.8401 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
461/487 [===========================&gt;..] - ETA: 0s - loss: 0.8395 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8393 - accuracy: 0.7219
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8392 - accuracy: 0.7219 - val_loss: 0.8378 - val_accuracy: 0.7228 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8592 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8279 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.8307 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8280 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.8300 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
101/487 [=====&gt;........................] - ETA: 1s - loss: 0.8302 - accuracy: 0.7249
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/487 [======&gt;.......................] - ETA: 0s - loss: 0.8287 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/487 [=======&gt;......................] - ETA: 0s - loss: 0.8299 - accuracy: 0.7249
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
161/487 [========&gt;.....................] - ETA: 0s - loss: 0.8306 - accuracy: 0.7248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/487 [==========&gt;...................] - ETA: 0s - loss: 0.8294 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
203/487 [===========&gt;..................] - ETA: 0s - loss: 0.8294 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8304 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/487 [==============&gt;...............] - ETA: 0s - loss: 0.8306 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
266/487 [===============&gt;..............] - ETA: 0s - loss: 0.8321 - accuracy: 0.7239
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/487 [================&gt;.............] - ETA: 0s - loss: 0.8310 - accuracy: 0.7244
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
307/487 [=================&gt;............] - ETA: 0s - loss: 0.8306 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
326/487 [===================&gt;..........] - ETA: 0s - loss: 0.8308 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
346/487 [====================&gt;.........] - ETA: 0s - loss: 0.8309 - accuracy: 0.7242
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
366/487 [=====================&gt;........] - ETA: 0s - loss: 0.8315 - accuracy: 0.7238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.8316 - accuracy: 0.7238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
406/487 [========================&gt;.....] - ETA: 0s - loss: 0.8309 - accuracy: 0.7240
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
426/487 [=========================&gt;....] - ETA: 0s - loss: 0.8303 - accuracy: 0.7241
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
446/487 [==========================&gt;...] - ETA: 0s - loss: 0.8299 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.8298 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8299 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8299 - accuracy: 0.7243 - val_loss: 0.8295 - val_accuracy: 0.7256 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8336 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8250 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.8257 - accuracy: 0.7269
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8231 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.8262 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
101/487 [=====&gt;........................] - ETA: 1s - loss: 0.8260 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/487 [======&gt;.......................] - ETA: 0s - loss: 0.8264 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/487 [=======&gt;......................] - ETA: 0s - loss: 0.8247 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/487 [========&gt;.....................] - ETA: 0s - loss: 0.8240 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 0.8249 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8251 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8243 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
244/487 [==============&gt;...............] - ETA: 0s - loss: 0.8251 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
265/487 [===============&gt;..............] - ETA: 0s - loss: 0.8250 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
286/487 [================&gt;.............] - ETA: 0s - loss: 0.8244 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
306/487 [=================&gt;............] - ETA: 0s - loss: 0.8248 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
326/487 [===================&gt;..........] - ETA: 0s - loss: 0.8244 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
346/487 [====================&gt;.........] - ETA: 0s - loss: 0.8239 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
366/487 [=====================&gt;........] - ETA: 0s - loss: 0.8239 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.8233 - accuracy: 0.7260
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
406/487 [========================&gt;.....] - ETA: 0s - loss: 0.8234 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
426/487 [=========================&gt;....] - ETA: 0s - loss: 0.8231 - accuracy: 0.7260
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
446/487 [==========================&gt;...] - ETA: 0s - loss: 0.8228 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/487 [===========================&gt;..] - ETA: 0s - loss: 0.8222 - accuracy: 0.7263
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8220 - accuracy: 0.7263
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8220 - accuracy: 0.7263 - val_loss: 0.8222 - val_accuracy: 0.7270 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8205 - accuracy: 0.7461
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8147 - accuracy: 0.7320
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.8155 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8189 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.8192 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
101/487 [=====&gt;........................] - ETA: 1s - loss: 0.8188 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/487 [======&gt;.......................] - ETA: 0s - loss: 0.8193 - accuracy: 0.7274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/487 [=======&gt;......................] - ETA: 0s - loss: 0.8185 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/487 [========&gt;.....................] - ETA: 0s - loss: 0.8182 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 0.8170 - accuracy: 0.7276
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8174 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8174 - accuracy: 0.7276
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
244/487 [==============&gt;...............] - ETA: 0s - loss: 0.8187 - accuracy: 0.7270
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
264/487 [===============&gt;..............] - ETA: 0s - loss: 0.8184 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
284/487 [================&gt;.............] - ETA: 0s - loss: 0.8176 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
304/487 [=================&gt;............] - ETA: 0s - loss: 0.8170 - accuracy: 0.7277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
324/487 [==================&gt;...........] - ETA: 0s - loss: 0.8165 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
344/487 [====================&gt;.........] - ETA: 0s - loss: 0.8165 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
364/487 [=====================&gt;........] - ETA: 0s - loss: 0.8160 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/487 [======================&gt;.......] - ETA: 0s - loss: 0.8155 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
404/487 [=======================&gt;......] - ETA: 0s - loss: 0.8163 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/487 [=========================&gt;....] - ETA: 0s - loss: 0.8162 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
444/487 [==========================&gt;...] - ETA: 0s - loss: 0.8160 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
464/487 [===========================&gt;..] - ETA: 0s - loss: 0.8152 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
484/487 [============================&gt;.] - ETA: 0s - loss: 0.8150 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8150 - accuracy: 0.7282 - val_loss: 0.8156 - val_accuracy: 0.7286 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8110 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8140 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.8149 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 60/487 [==&gt;...........................] - ETA: 1s - loss: 0.8115 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 80/487 [===&gt;..........................] - ETA: 1s - loss: 0.8122 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
100/487 [=====&gt;........................] - ETA: 1s - loss: 0.8140 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
120/487 [======&gt;.......................] - ETA: 0s - loss: 0.8148 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
140/487 [=======&gt;......................] - ETA: 0s - loss: 0.8147 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
159/487 [========&gt;.....................] - ETA: 0s - loss: 0.8154 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
178/487 [=========&gt;....................] - ETA: 0s - loss: 0.8142 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
197/487 [===========&gt;..................] - ETA: 0s - loss: 0.8135 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
217/487 [============&gt;.................] - ETA: 0s - loss: 0.8133 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
237/487 [=============&gt;................] - ETA: 0s - loss: 0.8128 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
257/487 [==============&gt;...............] - ETA: 0s - loss: 0.8127 - accuracy: 0.7288
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
277/487 [================&gt;.............] - ETA: 0s - loss: 0.8128 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
297/487 [=================&gt;............] - ETA: 0s - loss: 0.8123 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
317/487 [==================&gt;...........] - ETA: 0s - loss: 0.8119 - accuracy: 0.7290
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/487 [===================&gt;..........] - ETA: 0s - loss: 0.8114 - accuracy: 0.7291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
356/487 [====================&gt;.........] - ETA: 0s - loss: 0.8104 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/487 [======================&gt;.......] - ETA: 0s - loss: 0.8102 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
396/487 [=======================&gt;......] - ETA: 0s - loss: 0.8099 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
416/487 [========================&gt;.....] - ETA: 0s - loss: 0.8095 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
436/487 [=========================&gt;....] - ETA: 0s - loss: 0.8093 - accuracy: 0.7297
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
456/487 [===========================&gt;..] - ETA: 0s - loss: 0.8091 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
476/487 [============================&gt;.] - ETA: 0s - loss: 0.8088 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8086 - accuracy: 0.7299 - val_loss: 0.8097 - val_accuracy: 0.7300 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8227 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8089 - accuracy: 0.7274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.8117 - accuracy: 0.7270
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8099 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.8066 - accuracy: 0.7300
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 0s - loss: 0.8038 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 0.8019 - accuracy: 0.7316
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
142/487 [=======&gt;......................] - ETA: 0s - loss: 0.8034 - accuracy: 0.7309
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/487 [========&gt;.....................] - ETA: 0s - loss: 0.8030 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/487 [==========&gt;...................] - ETA: 0s - loss: 0.8028 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
202/487 [===========&gt;..................] - ETA: 0s - loss: 0.8018 - accuracy: 0.7317
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
222/487 [============&gt;.................] - ETA: 0s - loss: 0.8034 - accuracy: 0.7312
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
242/487 [=============&gt;................] - ETA: 0s - loss: 0.8039 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
263/487 [===============&gt;..............] - ETA: 0s - loss: 0.8048 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
284/487 [================&gt;.............] - ETA: 0s - loss: 0.8047 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
305/487 [=================&gt;............] - ETA: 0s - loss: 0.8042 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
326/487 [===================&gt;..........] - ETA: 0s - loss: 0.8043 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
347/487 [====================&gt;.........] - ETA: 0s - loss: 0.8042 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
368/487 [=====================&gt;........] - ETA: 0s - loss: 0.8038 - accuracy: 0.7309
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
388/487 [======================&gt;.......] - ETA: 0s - loss: 0.8033 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
408/487 [========================&gt;.....] - ETA: 0s - loss: 0.8033 - accuracy: 0.7309
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
429/487 [=========================&gt;....] - ETA: 0s - loss: 0.8032 - accuracy: 0.7311
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
450/487 [==========================&gt;...] - ETA: 0s - loss: 0.8026 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
470/487 [===========================&gt;..] - ETA: 0s - loss: 0.8027 - accuracy: 0.7315
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 16: val_loss improved from 0.80966 to 0.80423, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: val_loss improved from 0.80966 to 0.80423, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8028 - accuracy: 0.7313 - val_loss: 0.8042 - val_accuracy: 0.7314 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8746 - accuracy: 0.7129
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8053 - accuracy: 0.7304
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.7979 - accuracy: 0.7339
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8002 - accuracy: 0.7334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 82/487 [====&gt;.........................] - ETA: 1s - loss: 0.7999 - accuracy: 0.7331
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
103/487 [=====&gt;........................] - ETA: 0s - loss: 0.8014 - accuracy: 0.7320
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
124/487 [======&gt;.......................] - ETA: 0s - loss: 0.7999 - accuracy: 0.7319
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
144/487 [=======&gt;......................] - ETA: 0s - loss: 0.8008 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/487 [=========&gt;....................] - ETA: 0s - loss: 0.7992 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
185/487 [==========&gt;...................] - ETA: 0s - loss: 0.7996 - accuracy: 0.7321
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/487 [===========&gt;..................] - ETA: 0s - loss: 0.7991 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
227/487 [============&gt;.................] - ETA: 0s - loss: 0.7998 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
247/487 [==============&gt;...............] - ETA: 0s - loss: 0.7991 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/487 [===============&gt;..............] - ETA: 0s - loss: 0.7988 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/487 [================&gt;.............] - ETA: 0s - loss: 0.7990 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 0.7989 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/487 [===================&gt;..........] - ETA: 0s - loss: 0.7997 - accuracy: 0.7319
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 0.7990 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
368/487 [=====================&gt;........] - ETA: 0s - loss: 0.7990 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
388/487 [======================&gt;.......] - ETA: 0s - loss: 0.7982 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
408/487 [========================&gt;.....] - ETA: 0s - loss: 0.7981 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/487 [=========================&gt;....] - ETA: 0s - loss: 0.7980 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
448/487 [==========================&gt;...] - ETA: 0s - loss: 0.7977 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.7976 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
487/487 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 17: val_loss improved from 0.80423 to 0.79944, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17: val_loss improved from 0.80423 to 0.79944, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.7976 - accuracy: 0.7325 - val_loss: 0.7994 - val_accuracy: 0.7325 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8032 - accuracy: 0.7227
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.7992 - accuracy: 0.7319
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.7931 - accuracy: 0.7336
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.7913 - accuracy: 0.7340
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.7925 - accuracy: 0.7335
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_5673</span><span class="o">/</span><span class="mf">3673671120.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">24</span>         <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>     <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/utils/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">64</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
<span class="g g-Whitespace">     </span><span class="mi">66</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ni">fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">   </span><span class="mi">1407</span>                 <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1408</span>               <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1409</span>               <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1410</span>               <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1411</span>                 <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">913</span> 
<span class="g g-Whitespace">    </span><span class="mi">914</span>       <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">915</span>         <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">916</span> 
<span class="g g-Whitespace">    </span><span class="mi">917</span>       <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">_call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">945</span>       <span class="c1"># In this case we have created variables on the first call, so we run the</span>
<span class="g g-Whitespace">    </span><span class="mi">946</span>       <span class="c1"># defunned version which is guaranteed to never create variables.</span>
<span class="ne">--&gt; </span><span class="mi">947</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateless_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>     <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateful_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span>       <span class="c1"># Release the lock early so that multiple threads can perform the call</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2452</span>        <span class="n">filtered_flat_args</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_define_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2453</span>     <span class="k">return</span> <span class="n">graph_function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">2454</span>         <span class="n">filtered_flat_args</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">graph_function</span><span class="o">.</span><span class="n">captured_inputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">   </span><span class="mi">2455</span> 
<span class="g g-Whitespace">   </span><span class="mi">2456</span>   <span class="nd">@property</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">_call_flat</span><span class="nt">(self, args, captured_inputs, cancellation_manager)</span>
<span class="g g-Whitespace">   </span><span class="mi">1859</span>       <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="g g-Whitespace">   </span><span class="mi">1860</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_call_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">1861</span>           <span class="n">ctx</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_manager</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1862</span>     <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1863</span>         <span class="n">args</span><span class="p">,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">call</span><span class="nt">(self, ctx, args, cancellation_manager)</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span>               <span class="n">inputs</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>               <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">502</span>               <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>           <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/execute.py</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>     <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>     <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">55</span>                                         <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>     <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-sparsity">
<h2>Check sparsity<a class="headerlink" href="#check-sparsity" title="Permalink to this headline">#</a></h2>
<p>Make a quick check that the model was indeed trained sparse. We’ll just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing ‘0’. Note logarithmic y axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.75
</pre></div>
</div>
<img alt="_images/2.3_compression_12_1.png" src="_images/2.3_compression_12_1.png" />
</div>
</div>
<p>Compare this to the first model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_orig</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">w_orig</span> <span class="o">=</span> <span class="n">model_orig</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">_</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w_orig</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Original&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Pruned&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb44373f90&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_14_1.png" src="_images/2.3_compression_14_1.png" />
</div>
</div>
</section>
<section id="check-performance">
<h2>Check performance<a class="headerlink" href="#check-performance" title="Permalink to this headline">#</a></h2>
<p>How does this 75% sparse model compare against the unpruned model? Let’s report the accuracy and make a ROC curve. The pruned model is shown with solid lines, the unpruned model is shown with dashed lines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned: 0.7516927710843373
Accuracy pruned:   0.7428975903614458
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb3f857d10&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_16_2.png" src="_images/2.3_compression_16_2.png" />
</div>
</div>
<section id="reduced-size-model">
<h3>Reduced size model<a class="headerlink" href="#reduced-size-model" title="Permalink to this headline">#</a></h3>
<p>What if instead of pruning our model we simply shrink the size? Let’s now train a model where the hidden layers are a quarter of the size they are in the original model: 3 hidden layers with 16, then 8, then 8 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_small</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">16</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_1_half&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model_small</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
  1/487 [..............................] - ETA: 4:42 - loss: 1.5291 - accuracy: 0.3262WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>470/487 [===========================&gt;..] - ETA: 0s - loss: 1.4362 - accuracy: 0.3850
***callbacks***
saving losses to model_1_half/losses.log

Epoch 1: val_loss improved from inf to 1.34936, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 1.34936, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 1.4334 - accuracy: 0.3867 - val_loss: 1.3494 - val_accuracy: 0.4396 - lr: 1.0000e-04
Epoch 2/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.2798 - accuracy: 0.5151
***callbacks***
saving losses to model_1_half/losses.log

Epoch 2: val_loss improved from 1.34936 to 1.21631, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 1.34936 to 1.21631, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.2784 - accuracy: 0.5160 - val_loss: 1.2163 - val_accuracy: 0.5594 - lr: 1.0000e-04
Epoch 3/30
469/487 [===========================&gt;..] - ETA: 0s - loss: 1.1709 - accuracy: 0.5623
***callbacks***
saving losses to model_1_half/losses.log

Epoch 3: val_loss improved from 1.21631 to 1.12769, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 1.21631 to 1.12769, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.1693 - accuracy: 0.5627 - val_loss: 1.1277 - val_accuracy: 0.5736 - lr: 1.0000e-04
Epoch 4/30
478/487 [============================&gt;.] - ETA: 0s - loss: 1.0857 - accuracy: 0.6013
***callbacks***
saving losses to model_1_half/losses.log

Epoch 4: val_loss improved from 1.12769 to 1.04812, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 1.12769 to 1.04812, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 1.0851 - accuracy: 0.6021 - val_loss: 1.0481 - val_accuracy: 0.6488 - lr: 1.0000e-04
Epoch 5/30
474/487 [============================&gt;.] - ETA: 0s - loss: 1.0160 - accuracy: 0.6735
***callbacks***
saving losses to model_1_half/losses.log

Epoch 5: val_loss improved from 1.04812 to 0.99132, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 5: val_loss improved from 1.04812 to 0.99132, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.0155 - accuracy: 0.6739 - val_loss: 0.9913 - val_accuracy: 0.6873 - lr: 1.0000e-04
Epoch 6/30
487/487 [==============================] - ETA: 0s - loss: 0.9674 - accuracy: 0.6938
***callbacks***
saving losses to model_1_half/losses.log

Epoch 6: val_loss improved from 0.99132 to 0.95099, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 6: val_loss improved from 0.99132 to 0.95099, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 0.9674 - accuracy: 0.6938 - val_loss: 0.9510 - val_accuracy: 0.6983 - lr: 1.0000e-04
Epoch 7/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.9316 - accuracy: 0.7022
***callbacks***
saving losses to model_1_half/losses.log

Epoch 7: val_loss improved from 0.95099 to 0.91891, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 7: val_loss improved from 0.95099 to 0.91891, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 0.9312 - accuracy: 0.7023 - val_loss: 0.9189 - val_accuracy: 0.7051 - lr: 1.0000e-04
Epoch 8/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9022 - accuracy: 0.7086
***callbacks***
saving losses to model_1_half/losses.log

Epoch 8: val_loss improved from 0.91891 to 0.89320, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 8: val_loss improved from 0.91891 to 0.89320, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.9022 - accuracy: 0.7086 - val_loss: 0.8932 - val_accuracy: 0.7104 - lr: 1.0000e-04
Epoch 9/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8787 - accuracy: 0.7128
***callbacks***
saving losses to model_1_half/losses.log

Epoch 9: val_loss improved from 0.89320 to 0.87132, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 9: val_loss improved from 0.89320 to 0.87132, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8788 - accuracy: 0.7128 - val_loss: 0.8713 - val_accuracy: 0.7144 - lr: 1.0000e-04
Epoch 10/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8599 - accuracy: 0.7159
***callbacks***
saving losses to model_1_half/losses.log

Epoch 10: val_loss improved from 0.87132 to 0.85621, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 10: val_loss improved from 0.87132 to 0.85621, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8599 - accuracy: 0.7159 - val_loss: 0.8562 - val_accuracy: 0.7173 - lr: 1.0000e-04
Epoch 11/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.8471 - accuracy: 0.7182
***callbacks***
saving losses to model_1_half/losses.log

Epoch 11: val_loss improved from 0.85621 to 0.84522, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 11: val_loss improved from 0.85621 to 0.84522, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8470 - accuracy: 0.7183 - val_loss: 0.8452 - val_accuracy: 0.7187 - lr: 1.0000e-04
Epoch 12/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8373 - accuracy: 0.7199
***callbacks***
saving losses to model_1_half/losses.log

Epoch 12: val_loss improved from 0.84522 to 0.83681, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 12: val_loss improved from 0.84522 to 0.83681, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 12: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 12: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8373 - accuracy: 0.7199 - val_loss: 0.8368 - val_accuracy: 0.7207 - lr: 1.0000e-04
Epoch 13/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8297 - accuracy: 0.7212
***callbacks***
saving losses to model_1_half/losses.log

Epoch 13: val_loss improved from 0.83681 to 0.82991, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 13: val_loss improved from 0.83681 to 0.82991, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 7ms/step - loss: 0.8296 - accuracy: 0.7212 - val_loss: 0.8299 - val_accuracy: 0.7218 - lr: 1.0000e-04
Epoch 14/30
473/487 [============================&gt;.] - ETA: 0s - loss: 0.8233 - accuracy: 0.7223
***callbacks***
saving losses to model_1_half/losses.log

Epoch 14: val_loss improved from 0.82991 to 0.82427, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 14: val_loss improved from 0.82991 to 0.82427, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8234 - accuracy: 0.7223 - val_loss: 0.8243 - val_accuracy: 0.7225 - lr: 1.0000e-04
Epoch 15/30
474/487 [============================&gt;.] - ETA: 0s - loss: 0.8181 - accuracy: 0.7230
***callbacks***
saving losses to model_1_half/losses.log

Epoch 15: val_loss improved from 0.82427 to 0.81937, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 15: val_loss improved from 0.82427 to 0.81937, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.8182 - accuracy: 0.7230 - val_loss: 0.8194 - val_accuracy: 0.7234 - lr: 1.0000e-04
Epoch 16/30
487/487 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.7237
***callbacks***
saving losses to model_1_half/losses.log

Epoch 16: val_loss improved from 0.81937 to 0.81514, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 16: val_loss improved from 0.81937 to 0.81514, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8136 - accuracy: 0.7237 - val_loss: 0.8151 - val_accuracy: 0.7243 - lr: 1.0000e-04
Epoch 17/30
479/487 [============================&gt;.] - ETA: 0s - loss: 0.8095 - accuracy: 0.7245
***callbacks***
saving losses to model_1_half/losses.log

Epoch 17: val_loss improved from 0.81514 to 0.81146, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 17: val_loss improved from 0.81514 to 0.81146, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.8096 - accuracy: 0.7245 - val_loss: 0.8115 - val_accuracy: 0.7250 - lr: 1.0000e-04
Epoch 18/30
484/487 [============================&gt;.] - ETA: 0s - loss: 0.8058 - accuracy: 0.7251
***callbacks***
saving losses to model_1_half/losses.log

Epoch 18: val_loss improved from 0.81146 to 0.80808, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 18: val_loss improved from 0.81146 to 0.80808, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8060 - accuracy: 0.7251 - val_loss: 0.8081 - val_accuracy: 0.7253 - lr: 1.0000e-04
Epoch 19/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8031 - accuracy: 0.7254
***callbacks***
saving losses to model_1_half/losses.log

Epoch 19: val_loss improved from 0.80808 to 0.80524, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 19: val_loss improved from 0.80808 to 0.80524, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8029 - accuracy: 0.7255 - val_loss: 0.8052 - val_accuracy: 0.7259 - lr: 1.0000e-04
Epoch 20/30
477/487 [============================&gt;.] - ETA: 0s - loss: 0.8000 - accuracy: 0.7262
***callbacks***
saving losses to model_1_half/losses.log

Epoch 20: val_loss improved from 0.80524 to 0.80243, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 20: val_loss improved from 0.80524 to 0.80243, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.8000 - accuracy: 0.7262 - val_loss: 0.8024 - val_accuracy: 0.7263 - lr: 1.0000e-04
Epoch 21/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7975 - accuracy: 0.7269
***callbacks***
saving losses to model_1_half/losses.log

Epoch 21: val_loss improved from 0.80243 to 0.79994, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 21: val_loss improved from 0.80243 to 0.79994, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.7975 - accuracy: 0.7270 - val_loss: 0.7999 - val_accuracy: 0.7268 - lr: 1.0000e-04
Epoch 22/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.7951 - accuracy: 0.7275
***callbacks***
saving losses to model_1_half/losses.log

Epoch 22: val_loss improved from 0.79994 to 0.79778, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 22: val_loss improved from 0.79994 to 0.79778, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 9ms/step - loss: 0.7951 - accuracy: 0.7275 - val_loss: 0.7978 - val_accuracy: 0.7273 - lr: 1.0000e-04
Epoch 23/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.7931 - accuracy: 0.7279
***callbacks***
saving losses to model_1_half/losses.log

Epoch 23: val_loss improved from 0.79778 to 0.79573, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 23: val_loss improved from 0.79778 to 0.79573, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7930 - accuracy: 0.7280 - val_loss: 0.7957 - val_accuracy: 0.7280 - lr: 1.0000e-04
Epoch 24/30
487/487 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7286
***callbacks***
saving losses to model_1_half/losses.log

Epoch 24: val_loss improved from 0.79573 to 0.79387, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 24: val_loss improved from 0.79573 to 0.79387, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.7911 - accuracy: 0.7286 - val_loss: 0.7939 - val_accuracy: 0.7284 - lr: 1.0000e-04
Epoch 25/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7892 - accuracy: 0.7291
***callbacks***
saving losses to model_1_half/losses.log

Epoch 25: val_loss improved from 0.79387 to 0.79224, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 25: val_loss improved from 0.79387 to 0.79224, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.7892 - accuracy: 0.7291 - val_loss: 0.7922 - val_accuracy: 0.7287 - lr: 1.0000e-04
Epoch 26/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.7874 - accuracy: 0.7294
***callbacks***
saving losses to model_1_half/losses.log

Epoch 26: val_loss improved from 0.79224 to 0.79057, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 26: val_loss improved from 0.79224 to 0.79057, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 7ms/step - loss: 0.7876 - accuracy: 0.7294 - val_loss: 0.7906 - val_accuracy: 0.7293 - lr: 1.0000e-04
Epoch 27/30
476/487 [============================&gt;.] - ETA: 0s - loss: 0.7862 - accuracy: 0.7299
***callbacks***
saving losses to model_1_half/losses.log

Epoch 27: val_loss improved from 0.79057 to 0.78915, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 27: val_loss improved from 0.79057 to 0.78915, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.7860 - accuracy: 0.7299 - val_loss: 0.7892 - val_accuracy: 0.7300 - lr: 1.0000e-04
Epoch 28/30
479/487 [============================&gt;.] - ETA: 0s - loss: 0.7844 - accuracy: 0.7305
***callbacks***
saving losses to model_1_half/losses.log

Epoch 28: val_loss improved from 0.78915 to 0.78767, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 28: val_loss improved from 0.78915 to 0.78767, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7845 - accuracy: 0.7304 - val_loss: 0.7877 - val_accuracy: 0.7299 - lr: 1.0000e-04
Epoch 29/30
471/487 [============================&gt;.] - ETA: 0s - loss: 0.7830 - accuracy: 0.7309
***callbacks***
saving losses to model_1_half/losses.log

Epoch 29: val_loss improved from 0.78767 to 0.78623, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 29: val_loss improved from 0.78767 to 0.78623, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 5ms/step - loss: 0.7830 - accuracy: 0.7308 - val_loss: 0.7862 - val_accuracy: 0.7304 - lr: 1.0000e-04
Epoch 30/30
475/487 [============================&gt;.] - ETA: 0s - loss: 0.7819 - accuracy: 0.7311
***callbacks***
saving losses to model_1_half/losses.log

Epoch 30: val_loss improved from 0.78623 to 0.78488, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 30: val_loss improved from 0.78623 to 0.78488, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.7816 - accuracy: 0.7312 - val_loss: 0.7849 - val_accuracy: 0.7310 - lr: 1.0000e-04
</pre></div>
</div>
</div>
</div>
<p>How does this small model compare in terms of performance?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_small</span> <span class="o">=</span> <span class="n">model_small</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy small:    </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_small</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_small</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned: 0.7516927710843373
Accuracy pruned:   0.7456506024096385
Accuracy small:    0.7289518072289156
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb468b5590&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_21_2.png" src="_images/2.3_compression_21_2.png" />
</div>
</div>
<p>This looks quite good. Can we go further? Let’s try a sparsity of 95%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.95</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2>Train the model<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>We’ll use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory ‘model_2’
The model isn’t very complex, so this should just take a few minutes even on the CPU.
If you’ve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_4&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 17:22 - loss: 0.7500 - accuracy: 0.7529WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7544 - accuracy: 0.7454
***callbacks***
saving losses to model_4/losses.log

Epoch 1: val_loss improved from inf to 0.75678, saving model to model_4/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 0.75678, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_4/KERAS_check_model_last.h5

Epoch 1: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 5s 6ms/step - loss: 0.7541 - accuracy: 0.7455 - val_loss: 0.7568 - val_accuracy: 0.7454 - lr: 1.0000e-04
Epoch 2/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.7504 - accuracy: 0.7468
***callbacks***
saving losses to model_4/losses.log

Epoch 2: val_loss improved from 0.75678 to 0.75333, saving model to model_4/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 0.75678 to 0.75333, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_4/KERAS_check_model_last.h5

Epoch 2: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7505 - accuracy: 0.7468 - val_loss: 0.7533 - val_accuracy: 0.7468 - lr: 1.0000e-04
Epoch 3/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.7473 - accuracy: 0.7477
***callbacks***
saving losses to model_4/losses.log

Epoch 3: val_loss improved from 0.75333 to 0.75063, saving model to model_4/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 0.75333 to 0.75063, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_4/KERAS_check_model_last.h5

Epoch 3: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7473 - accuracy: 0.7477 - val_loss: 0.7506 - val_accuracy: 0.7478 - lr: 1.0000e-04
Epoch 4/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7487
***callbacks***
saving losses to model_4/losses.log

Epoch 4: val_loss improved from 0.75063 to 0.74790, saving model to model_4/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 0.75063 to 0.74790, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_4/KERAS_check_model_last.h5

Epoch 4: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7445 - accuracy: 0.7487 - val_loss: 0.7479 - val_accuracy: 0.7489 - lr: 1.0000e-04
Epoch 5/30
479/487 [============================&gt;.] - ETA: 0s - loss: 1.2867 - accuracy: 0.5367
***callbacks***
saving losses to model_4/losses.log

Epoch 5: val_loss did not improve from 0.74790

Epoch 5: val_loss did not improve from 0.74790

Epoch 5: saving model to model_4/KERAS_check_model_last.h5

Epoch 5: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.2865 - accuracy: 0.5369 - val_loss: 1.2808 - val_accuracy: 0.5486 - lr: 1.0000e-04
Epoch 6/30
485/487 [============================&gt;.] - ETA: 0s - loss: 1.2340 - accuracy: 0.5611
***callbacks***
saving losses to model_4/losses.log

Epoch 6: val_loss did not improve from 0.74790

Epoch 6: val_loss did not improve from 0.74790

Epoch 6: saving model to model_4/KERAS_check_model_last.h5

Epoch 6: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.2339 - accuracy: 0.5611 - val_loss: 1.1963 - val_accuracy: 0.5635 - lr: 1.0000e-04
Epoch 7/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.1660 - accuracy: 0.5707
***callbacks***
saving losses to model_4/losses.log

Epoch 7: val_loss did not improve from 0.74790

Epoch 7: val_loss did not improve from 0.74790

Epoch 7: saving model to model_4/KERAS_check_model_last.h5

Epoch 7: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.1655 - accuracy: 0.5708 - val_loss: 1.1432 - val_accuracy: 0.5714 - lr: 1.0000e-04
Epoch 8/30
482/487 [============================&gt;.] - ETA: 0s - loss: 1.1242 - accuracy: 0.5774
***callbacks***
saving losses to model_4/losses.log

Epoch 8: val_loss did not improve from 0.74790

Epoch 8: val_loss did not improve from 0.74790

Epoch 8: saving model to model_4/KERAS_check_model_last.h5

Epoch 8: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.1240 - accuracy: 0.5774 - val_loss: 1.1107 - val_accuracy: 0.5768 - lr: 1.0000e-04
Epoch 9/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0962 - accuracy: 0.5821
***callbacks***
saving losses to model_4/losses.log

Epoch 9: val_loss did not improve from 0.74790

Epoch 9: val_loss did not improve from 0.74790

Epoch 9: saving model to model_4/KERAS_check_model_last.h5

Epoch 9: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0961 - accuracy: 0.5822 - val_loss: 1.0869 - val_accuracy: 0.5809 - lr: 1.0000e-04
Epoch 10/30
485/487 [============================&gt;.] - ETA: 0s - loss: 1.0754 - accuracy: 0.5857
***callbacks***
saving losses to model_4/losses.log

Epoch 10: val_loss did not improve from 0.74790

Epoch 10: val_loss did not improve from 0.74790

Epoch 10: saving model to model_4/KERAS_check_model_last.h5

Epoch 10: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_4/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0754 - accuracy: 0.5858 - val_loss: 1.0690 - val_accuracy: 0.5836 - lr: 1.0000e-04
Epoch 11/30
483/487 [============================&gt;.] - ETA: 0s - loss: 1.0592 - accuracy: 0.5880
***callbacks***
saving losses to model_4/losses.log

Epoch 11: val_loss did not improve from 0.74790

Epoch 11: val_loss did not improve from 0.74790

Epoch 11: saving model to model_4/KERAS_check_model_last.h5

Epoch 11: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0592 - accuracy: 0.5880 - val_loss: 1.0543 - val_accuracy: 0.5860 - lr: 1.0000e-04
Epoch 12/30
486/487 [============================&gt;.] - ETA: 0s - loss: 1.0455 - accuracy: 0.5896
***callbacks***
saving losses to model_4/losses.log

Epoch 12: val_loss did not improve from 0.74790

Epoch 12: val_loss did not improve from 0.74790

Epoch 12: saving model to model_4/KERAS_check_model_last.h5

Epoch 12: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0455 - accuracy: 0.5896 - val_loss: 1.0416 - val_accuracy: 0.5875 - lr: 1.0000e-04
Epoch 13/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0330 - accuracy: 0.5906
***callbacks***
saving losses to model_4/losses.log

Epoch 13: val_loss did not improve from 0.74790

Epoch 13: val_loss did not improve from 0.74790

Epoch 13: saving model to model_4/KERAS_check_model_last.h5

Epoch 13: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0329 - accuracy: 0.5907 - val_loss: 1.0290 - val_accuracy: 0.5889 - lr: 1.0000e-04
Epoch 14/30
480/487 [============================&gt;.] - ETA: 0s - loss: 1.0210 - accuracy: 0.5919
***callbacks***
saving losses to model_4/losses.log

Epoch 14: val_loss did not improve from 0.74790

Epoch 14: val_loss did not improve from 0.74790

Epoch 14: saving model to model_4/KERAS_check_model_last.h5

Epoch 14: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0209 - accuracy: 0.5918 - val_loss: 1.0178 - val_accuracy: 0.5901 - lr: 1.0000e-04
Epoch 15/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0126 - accuracy: 0.5927
***callbacks***
saving losses to model_4/losses.log

Epoch 15: val_loss did not improve from 0.74790

Epoch 15: val_loss did not improve from 0.74790

Epoch 15: saving model to model_4/KERAS_check_model_last.h5

Epoch 15: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0126 - accuracy: 0.5928 - val_loss: 1.0123 - val_accuracy: 0.5905 - lr: 5.0000e-05
Epoch 16/30
479/487 [============================&gt;.] - ETA: 0s - loss: 1.0073 - accuracy: 0.5934
***callbacks***
saving losses to model_4/losses.log

Epoch 16: val_loss did not improve from 0.74790

Epoch 16: val_loss did not improve from 0.74790

Epoch 16: saving model to model_4/KERAS_check_model_last.h5

Epoch 16: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0072 - accuracy: 0.5932 - val_loss: 1.0069 - val_accuracy: 0.5912 - lr: 5.0000e-05
Epoch 17/30
486/487 [============================&gt;.] - ETA: 0s - loss: 1.0019 - accuracy: 0.5938
***callbacks***
saving losses to model_4/losses.log

Epoch 17: val_loss did not improve from 0.74790

Epoch 17: val_loss did not improve from 0.74790

Epoch 17: saving model to model_4/KERAS_check_model_last.h5

Epoch 17: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0018 - accuracy: 0.5938 - val_loss: 1.0015 - val_accuracy: 0.5916 - lr: 5.0000e-05
Epoch 18/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9964 - accuracy: 0.5943
***callbacks***
saving losses to model_4/losses.log

Epoch 18: val_loss did not improve from 0.74790

Epoch 18: val_loss did not improve from 0.74790

Epoch 18: saving model to model_4/KERAS_check_model_last.h5

Epoch 18: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9965 - accuracy: 0.5942 - val_loss: 0.9963 - val_accuracy: 0.5921 - lr: 5.0000e-05
Epoch 19/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9916 - accuracy: 0.5945
***callbacks***
saving losses to model_4/losses.log

Epoch 19: val_loss did not improve from 0.74790

Epoch 19: val_loss did not improve from 0.74790

Epoch 19: saving model to model_4/KERAS_check_model_last.h5

Epoch 19: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9914 - accuracy: 0.5946 - val_loss: 0.9912 - val_accuracy: 0.5927 - lr: 5.0000e-05
Epoch 20/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.9864 - accuracy: 0.5951
***callbacks***
saving losses to model_4/losses.log

Epoch 20: val_loss did not improve from 0.74790

Epoch 20: val_loss did not improve from 0.74790

Epoch 20: saving model to model_4/KERAS_check_model_last.h5

Epoch 20: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_4/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9864 - accuracy: 0.5951 - val_loss: 0.9864 - val_accuracy: 0.5931 - lr: 5.0000e-05
Epoch 21/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9818 - accuracy: 0.5955
***callbacks***
saving losses to model_4/losses.log

Epoch 21: val_loss did not improve from 0.74790

Epoch 21: val_loss did not improve from 0.74790

Epoch 21: saving model to model_4/KERAS_check_model_last.h5

Epoch 21: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9817 - accuracy: 0.5955 - val_loss: 0.9818 - val_accuracy: 0.5934 - lr: 5.0000e-05
Epoch 22/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9772 - accuracy: 0.5959
***callbacks***
saving losses to model_4/losses.log

Epoch 22: val_loss did not improve from 0.74790

Epoch 22: val_loss did not improve from 0.74790

Epoch 22: saving model to model_4/KERAS_check_model_last.h5

Epoch 22: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.9772 - accuracy: 0.5959 - val_loss: 0.9774 - val_accuracy: 0.5938 - lr: 5.0000e-05
Epoch 23/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.9730 - accuracy: 0.5962
***callbacks***
saving losses to model_4/losses.log

Epoch 23: val_loss did not improve from 0.74790

Epoch 23: val_loss did not improve from 0.74790

Epoch 23: saving model to model_4/KERAS_check_model_last.h5

Epoch 23: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.9728 - accuracy: 0.5963 - val_loss: 0.9731 - val_accuracy: 0.5944 - lr: 5.0000e-05
Epoch 24/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9687 - accuracy: 0.5966
***callbacks***
saving losses to model_4/losses.log

Epoch 24: val_loss did not improve from 0.74790

Epoch 24: val_loss did not improve from 0.74790

Epoch 24: saving model to model_4/KERAS_check_model_last.h5

Epoch 24: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9687 - accuracy: 0.5966 - val_loss: 0.9691 - val_accuracy: 0.5947 - lr: 5.0000e-05
Epoch 25/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9648 - accuracy: 0.5969
***callbacks***
saving losses to model_4/losses.log

Epoch 25: val_loss did not improve from 0.74790

Epoch 25: val_loss did not improve from 0.74790

Epoch 25: saving model to model_4/KERAS_check_model_last.h5

Epoch 25: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9647 - accuracy: 0.5970 - val_loss: 0.9652 - val_accuracy: 0.5951 - lr: 5.0000e-05
Epoch 26/30
481/487 [============================&gt;.] - ETA: 0s - loss: 0.9616 - accuracy: 0.5973
***callbacks***
saving losses to model_4/losses.log

Epoch 26: val_loss did not improve from 0.74790

Epoch 26: val_loss did not improve from 0.74790

Epoch 26: saving model to model_4/KERAS_check_model_last.h5

Epoch 26: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9616 - accuracy: 0.5973 - val_loss: 0.9630 - val_accuracy: 0.5953 - lr: 2.5000e-05
Epoch 27/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.9594 - accuracy: 0.5975
***callbacks***
saving losses to model_4/losses.log

Epoch 27: val_loss did not improve from 0.74790

Epoch 27: val_loss did not improve from 0.74790

Epoch 27: saving model to model_4/KERAS_check_model_last.h5

Epoch 27: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9593 - accuracy: 0.5977 - val_loss: 0.9606 - val_accuracy: 0.5958 - lr: 2.5000e-05
Epoch 28/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.9569 - accuracy: 0.5984
***callbacks***
saving losses to model_4/losses.log

Epoch 28: val_loss did not improve from 0.74790

Epoch 28: val_loss did not improve from 0.74790

Epoch 28: saving model to model_4/KERAS_check_model_last.h5

Epoch 28: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9570 - accuracy: 0.5984 - val_loss: 0.9583 - val_accuracy: 0.5969 - lr: 2.5000e-05
Epoch 29/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.9547 - accuracy: 0.5999
***callbacks***
saving losses to model_4/losses.log

Epoch 29: val_loss did not improve from 0.74790

Epoch 29: val_loss did not improve from 0.74790

Epoch 29: saving model to model_4/KERAS_check_model_last.h5

Epoch 29: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9547 - accuracy: 0.5999 - val_loss: 0.9561 - val_accuracy: 0.5984 - lr: 2.5000e-05
Epoch 30/30
487/487 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6017
***callbacks***
saving losses to model_4/losses.log

Epoch 30: val_loss did not improve from 0.74790

Epoch 30: val_loss did not improve from 0.74790

Epoch 30: saving model to model_4/KERAS_check_model_last.h5

Epoch 30: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_4/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9524 - accuracy: 0.6017 - val_loss: 0.9538 - val_accuracy: 0.6002 - lr: 2.5000e-05
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>Check sparsity<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.9501953125
</pre></div>
</div>
<img alt="_images/2.3_compression_27_1.png" src="_images/2.3_compression_27_1.png" />
</div>
</div>
</section>
<section id="id3">
<h2>Check performance<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p>How does this 95% sparse model compare against the other models?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="n">model_prune75</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_2/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune75</span> <span class="o">=</span> <span class="n">model_prune75</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune95</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned:     </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (75%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (95%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune75</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune95</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span>
    <span class="n">lines</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (75%)&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (95%)&quot;</span><span class="p">],</span>
    <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span>
    <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned:     0.7516927710843373
Accuracy pruned (75%): 0.7506325301204819
Accuracy pruned (95%): 0.6019036144578314
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb3d85e050&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_29_2.png" src="_images/2.3_compression_29_2.png" />
</div>
</div>
<p>Ok, clearly 95% is too sparse for this model (at least using this scheme). For some classes you see that the performance is not terrible, but overall the performance loss is quite substantial.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2.2_advanced_config.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Advanced Configuration</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="2.4_quantization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Quantization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Javier Duarte, Dylan Rankin, and Patrick McCormack<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>