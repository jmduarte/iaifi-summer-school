
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Compression (Pruning) &#8212; IAIFI Summer School Tutorials</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jduarte.physics.ucsd.edu/iaifi-summer-school/2.3_compression.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quantization" href="2.4_quantization.html" />
    <link rel="prev" title="Advanced Configuration" href="2.2_advanced_config.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IAIFI Summer School Tutorials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    IAIFI Summer School Tutorials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations, Networks, and Symmetries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1.1_tabular_data_efps.html">
   Tabular Data using Energy Flow Polynomials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.2_jet_images.html">
   Jet Images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.3_deep_sets.html">
   Deep Sets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.4_gnn_in.html">
   Interaction Network GNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.5_gnn_lorentz.html">
   Lorentz-Equivariant GNN
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model Compression and Fast Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2.1_getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.2_advanced_config.html">
   Advanced Configuration
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Compression (Pruning)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.4_quantization.html">
   Quantization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jmduarte/iaifi-summer-school/main?urlpath=tree/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jmduarte/iaifi-summer-school/blob/main/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school/issues/new?title=Issue%20on%20page%20%2F2.3_compression.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Compression (Pruning)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>apt-get  -qq  install  -y  graphviz  <span class="o">&amp;&amp;</span>  pip  install  pydot
<span class="o">!</span>pip  install  -U  matplotlib
<span class="o">!</span>pip  install  git+https://github.com/fastmachinelearning/hls4ml.git@main#egg<span class="o">=</span>hls4ml<span class="o">[</span>profiling<span class="o">]</span>
<span class="o">!</span>pip  install  <span class="nv">qkeras</span><span class="o">==</span><span class="m">0</span>.9.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)
E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (3.5.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (4.34.4)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (9.2.0)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (21.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (0.11.0)
Requirement already satisfied: numpy&gt;=1.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.21.6)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (3.0.9)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib) (4.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting hls4ml[profiling]
  Cloning https://github.com/fastmachinelearning/hls4ml.git (to revision main) to /tmp/pip-install-byr6ltgi/hls4ml_1acad19e20214ec19d43d5f70bc16405
  Running command git clone --filter=blob:none --quiet https://github.com/fastmachinelearning/hls4ml.git /tmp/pip-install-byr6ltgi/hls4ml_1acad19e20214ec19d43d5f70bc16405
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Resolved https://github.com/fastmachinelearning/hls4ml.git to commit 62046d799a4dbec150addc7f78fea5b579efeda1
  Running command git submodule update --init --recursive -q
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Preparing metadata (setup.py) ... ?25l-
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> done
?25hRequirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.21.6)
Requirement already satisfied: six in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.16.0)
Requirement already satisfied: pyyaml in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (6.0)
Requirement already satisfied: h5py in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.7.0)
Requirement already satisfied: onnx&gt;=1.4.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.12.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: calmjs.parse in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.0)
Requirement already satisfied: tabulate in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.8.10)
Requirement already satisfied: pydigitalwavetools==1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.1)
Requirement already satisfied: qkeras in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.9.0)
Requirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.5)
Requirement already satisfied: seaborn in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.11.2)
Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.5.2)
Requirement already satisfied: protobuf&lt;=3.20.1,&gt;=3.12.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (3.19.4)
Requirement already satisfied: typing-extensions&gt;=3.6.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (4.3.0)
Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (63.3.0)
Requirement already satisfied: ply&gt;=3.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (3.11)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (1.4.4)
Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (4.34.4)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (9.2.0)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (3.0.9)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (21.3)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pytz&gt;=2017.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pandas-&gt;hls4ml[profiling]) (2022.1)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (0.7.3)
Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (2.6.3)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0.2)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.7.3)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (4.64.0)
Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.1.3)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (7.34.0)
Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.0.4)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.28.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.1.0)
Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.7)
Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras-&gt;hls4ml[profiling]) (1.6.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.12.0)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.3)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.5)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.3.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.0.30)
Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.0)
Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.1.1)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.18.1)
Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.8.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.26.11)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2022.6.15)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.3)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.47.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.4.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.6)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.2.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.8.1)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.6.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.2.1)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.37.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.9)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.2.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.3.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.0)
Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.8.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.2.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: qkeras==0.9.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (0.9.0)
Requirement already satisfied: setuptools&gt;=41.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (63.3.0)
Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.1.3)
Requirement already satisfied: numpy&gt;=1.16.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.21.6)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0)
Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (2.6.3)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0.2)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (4.64.0)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (0.7.3)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.7.3)
Requirement already satisfied: packaging in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (21.3)
Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.28.1)
Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (7.34.0)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.0.4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (3.1.0)
Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (1.1.0)
Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (0.1.7)
Requirement already satisfied: six~=1.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras==0.9.0) (1.6.5)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.30)
Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.12.0)
Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.1.1)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.18.1)
Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.8.0)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.5)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.3.0)
Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.1.3)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from packaging-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.9)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2022.6.15)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.26.11)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.3)
Requirement already satisfied: protobuf&lt;3.20,&gt;=3.9.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.19.4)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.47.0)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.2.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.8.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.6.1)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.2.0)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.37.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.4.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.6)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.2.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.9)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.3.1)
Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.0)
Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.8.1)
Requirement already satisfied: typing-extensions&gt;=3.6.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.3.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.2.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">COLAB</span><span class="o">=</span><span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install wget
<span class="kn">import</span> <span class="nn">wget</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="c1"># WGET for colab</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;callbacks.py&quot;</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/jmduarte/iaifi-summer-school/main/book/callbacks.py&quot;</span>
    <span class="n">callbacksFile</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;plotting.py&quot;</span><span class="p">):</span>
    <span class="n">urlPlot</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/jmduarte/iaifi-summer-school/main/book/plotting.py&quot;</span>
    <span class="n">plotFile</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">urlPlot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: wget in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (3.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;./iaifi-summer-school&quot;</span><span class="p">):</span>
        <span class="o">!</span>git clone https://github.com/jmduarte/iaifi-summer-school.git
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="compression-pruning">
<h1>Compression (Pruning)<a class="headerlink" href="#compression-pruning" title="Permalink to this headline">#</a></h1>
<section id="load-the-dataset-if-you-are-restarting-from-this-point">
<h2>Load the dataset (if you are restarting from this point)<a class="headerlink" href="#load-the-dataset-if-you-are-restarting-from-this-point" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># import os</span>
<span class="c1"># os.environ[&#39;PATH&#39;] = &#39;/opt/Xilinx/Vivado/2019.2/bin:&#39; + os.environ[&#39;PATH&#39;]</span>
<span class="c1"># for this tutorial we wont be actually running Vivado, so I have commented these lines out</span>
<span class="c1">#     but if you want to look into actually running on an FPGA then simply uncomment these lines</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="c1">#FOR LOCAL PULL</span>
    <span class="n">X_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_train_val.npy&quot;</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
    <span class="n">y_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_train_val.npy&quot;</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;classes.npy&quot;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="c1">#FOR COLAB</span>
    <span class="n">X_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/X_train_val.npy&quot;</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/X_test.npy&quot;</span><span class="p">)</span>
    <span class="n">y_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/y_train_val.npy&quot;</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/y_test.npy&quot;</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/classes.npy&quot;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 01:20:23.051755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 01:20:23.051789: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div>
</div>
</div>
</div>
</section>
<section id="construct-a-new-model">
<h2>Construct a new model<a class="headerlink" href="#construct-a-new-model" title="Permalink to this headline">#</a></h2>
<p>Well now use the same architecture as we originally used: 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span>
<span class="kn">from</span> <span class="nn">callbacks</span> <span class="kn">import</span> <span class="n">all_callbacks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">64</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 01:20:25.765007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 01:20:25.765052: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-08-02 01:20:25.765074: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az462-629): /proc/driver/nvidia/version does not exist
2022-08-02 01:20:25.765329: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-sparse">
<h2>Train sparse<a class="headerlink" href="#train-sparse" title="Permalink to this headline">#</a></h2>
<p>This time well use the Tensorflow model optimization sparsity to train a sparse model (forcing many weights to 0). In this instance, the target sparsity is 75%</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.75</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model">
<h2>Train the model<a class="headerlink" href="#train-the-model" title="Permalink to this headline">#</a></h2>
<p>Well use the same settings as the previous model: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory model_3
The model isnt very complex, so this should just take a few minutes even on the CPU.
If youve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_3&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 18:55 - loss: 1.6388 - accuracy: 0.3027
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0072s). Check your callbacks.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 19/487 [&gt;.............................] - ETA: 1s - loss: 1.6337 - accuracy: 0.2798   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 1.6150 - accuracy: 0.3018
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 1.5976 - accuracy: 0.3242
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 1.5817 - accuracy: 0.3427
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/487 [=====&gt;........................] - ETA: 1s - loss: 1.5667 - accuracy: 0.3575
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 1.5534 - accuracy: 0.3677
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
137/487 [=======&gt;......................] - ETA: 0s - loss: 1.5390 - accuracy: 0.3792
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
157/487 [========&gt;.....................] - ETA: 0s - loss: 1.5243 - accuracy: 0.3923
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
178/487 [=========&gt;....................] - ETA: 0s - loss: 1.5097 - accuracy: 0.4030
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
199/487 [===========&gt;..................] - ETA: 0s - loss: 1.4945 - accuracy: 0.4129
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
219/487 [============&gt;.................] - ETA: 0s - loss: 1.4805 - accuracy: 0.4205
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
240/487 [=============&gt;................] - ETA: 0s - loss: 1.4663 - accuracy: 0.4288
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
260/487 [===============&gt;..............] - ETA: 0s - loss: 1.4537 - accuracy: 0.4361
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
281/487 [================&gt;.............] - ETA: 0s - loss: 1.4399 - accuracy: 0.4448
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
301/487 [=================&gt;............] - ETA: 0s - loss: 1.4268 - accuracy: 0.4537
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
320/487 [==================&gt;...........] - ETA: 0s - loss: 1.4153 - accuracy: 0.4621
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/487 [===================&gt;..........] - ETA: 0s - loss: 1.4047 - accuracy: 0.4693
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
358/487 [=====================&gt;........] - ETA: 0s - loss: 1.3929 - accuracy: 0.4773
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
379/487 [======================&gt;.......] - ETA: 0s - loss: 1.3811 - accuracy: 0.4848
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
400/487 [=======================&gt;......] - ETA: 0s - loss: 1.3699 - accuracy: 0.4918
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
422/487 [========================&gt;.....] - ETA: 0s - loss: 1.3587 - accuracy: 0.4987
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
442/487 [==========================&gt;...] - ETA: 0s - loss: 1.3488 - accuracy: 0.5046
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
462/487 [===========================&gt;..] - ETA: 0s - loss: 1.3396 - accuracy: 0.5099
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/487 [============================&gt;.] - ETA: 0s - loss: 1.3315 - accuracy: 0.5147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 4s 4ms/step - loss: 1.3290 - accuracy: 0.5161 - val_loss: 1.1252 - val_accuracy: 0.6363 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 1.1001 - accuracy: 0.6299
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 19/487 [&gt;.............................] - ETA: 1s - loss: 1.1173 - accuracy: 0.6380
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 1.1179 - accuracy: 0.6371
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 1.1157 - accuracy: 0.6384
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 1.1093 - accuracy: 0.6408
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 95/487 [====&gt;.........................] - ETA: 1s - loss: 1.1072 - accuracy: 0.6421
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
113/487 [=====&gt;........................] - ETA: 1s - loss: 1.1043 - accuracy: 0.6434
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
133/487 [=======&gt;......................] - ETA: 0s - loss: 1.1002 - accuracy: 0.6451
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
153/487 [========&gt;.....................] - ETA: 0s - loss: 1.0967 - accuracy: 0.6472
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
174/487 [=========&gt;....................] - ETA: 0s - loss: 1.0932 - accuracy: 0.6489
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
193/487 [==========&gt;...................] - ETA: 0s - loss: 1.0910 - accuracy: 0.6498
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
212/487 [============&gt;.................] - ETA: 0s - loss: 1.0880 - accuracy: 0.6511
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
232/487 [=============&gt;................] - ETA: 0s - loss: 1.0850 - accuracy: 0.6529
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/487 [==============&gt;...............] - ETA: 0s - loss: 1.0826 - accuracy: 0.6544
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
271/487 [===============&gt;..............] - ETA: 0s - loss: 1.0802 - accuracy: 0.6553
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
291/487 [================&gt;.............] - ETA: 0s - loss: 1.0776 - accuracy: 0.6568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
311/487 [==================&gt;...........] - ETA: 0s - loss: 1.0750 - accuracy: 0.6579
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
330/487 [===================&gt;..........] - ETA: 0s - loss: 1.0730 - accuracy: 0.6589
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
349/487 [====================&gt;.........] - ETA: 0s - loss: 1.0707 - accuracy: 0.6599
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 1.0680 - accuracy: 0.6611
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/487 [======================&gt;.......] - ETA: 0s - loss: 1.0660 - accuracy: 0.6622
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
402/487 [=======================&gt;......] - ETA: 0s - loss: 1.0638 - accuracy: 0.6631
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
422/487 [========================&gt;.....] - ETA: 0s - loss: 1.0620 - accuracy: 0.6637
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
441/487 [==========================&gt;...] - ETA: 0s - loss: 1.0597 - accuracy: 0.6648
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
461/487 [===========================&gt;..] - ETA: 0s - loss: 1.0576 - accuracy: 0.6657
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/487 [============================&gt;.] - ETA: 0s - loss: 1.0556 - accuracy: 0.6665
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0550 - accuracy: 0.6668 - val_loss: 1.0071 - val_accuracy: 0.6900 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9859 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 1.0062 - accuracy: 0.6896
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.9997 - accuracy: 0.6893
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 60/487 [==&gt;...........................] - ETA: 1s - loss: 1.0011 - accuracy: 0.6897
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/487 [===&gt;..........................] - ETA: 1s - loss: 0.9986 - accuracy: 0.6902
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/487 [=====&gt;........................] - ETA: 1s - loss: 0.9969 - accuracy: 0.6908
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
118/487 [======&gt;.......................] - ETA: 0s - loss: 0.9975 - accuracy: 0.6903
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
137/487 [=======&gt;......................] - ETA: 0s - loss: 0.9963 - accuracy: 0.6909
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
156/487 [========&gt;.....................] - ETA: 0s - loss: 0.9939 - accuracy: 0.6922
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
175/487 [=========&gt;....................] - ETA: 0s - loss: 0.9924 - accuracy: 0.6933
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
193/487 [==========&gt;...................] - ETA: 0s - loss: 0.9909 - accuracy: 0.6939
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
213/487 [============&gt;.................] - ETA: 0s - loss: 0.9905 - accuracy: 0.6939
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
232/487 [=============&gt;................] - ETA: 0s - loss: 0.9890 - accuracy: 0.6946
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/487 [==============&gt;...............] - ETA: 0s - loss: 0.9868 - accuracy: 0.6955
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
272/487 [===============&gt;..............] - ETA: 0s - loss: 0.9853 - accuracy: 0.6960
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.9832 - accuracy: 0.6967
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 0.9820 - accuracy: 0.6970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/487 [===================&gt;..........] - ETA: 0s - loss: 0.9812 - accuracy: 0.6971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/487 [====================&gt;.........] - ETA: 0s - loss: 0.9802 - accuracy: 0.6976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/487 [=====================&gt;........] - ETA: 0s - loss: 0.9789 - accuracy: 0.6980
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
390/487 [=======================&gt;......] - ETA: 0s - loss: 0.9779 - accuracy: 0.6983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
410/487 [========================&gt;.....] - ETA: 0s - loss: 0.9765 - accuracy: 0.6988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
430/487 [=========================&gt;....] - ETA: 0s - loss: 0.9750 - accuracy: 0.6993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
451/487 [==========================&gt;...] - ETA: 0s - loss: 0.9732 - accuracy: 0.6999
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
471/487 [============================&gt;.] - ETA: 0s - loss: 0.9721 - accuracy: 0.7002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9712 - accuracy: 0.7004 - val_loss: 0.9450 - val_accuracy: 0.7098 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9507 - accuracy: 0.7021
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.9416 - accuracy: 0.7094
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.9386 - accuracy: 0.7097
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 0.9421 - accuracy: 0.7101
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 79/487 [===&gt;..........................] - ETA: 1s - loss: 0.9405 - accuracy: 0.7108
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/487 [=====&gt;........................] - ETA: 1s - loss: 0.9402 - accuracy: 0.7105
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/487 [======&gt;.......................] - ETA: 0s - loss: 0.9378 - accuracy: 0.7109
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
138/487 [=======&gt;......................] - ETA: 0s - loss: 0.9353 - accuracy: 0.7115
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
157/487 [========&gt;.....................] - ETA: 0s - loss: 0.9337 - accuracy: 0.7115
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
176/487 [=========&gt;....................] - ETA: 0s - loss: 0.9334 - accuracy: 0.7114
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
195/487 [===========&gt;..................] - ETA: 0s - loss: 0.9322 - accuracy: 0.7117
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/487 [============&gt;.................] - ETA: 0s - loss: 0.9306 - accuracy: 0.7117
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
233/487 [=============&gt;................] - ETA: 0s - loss: 0.9293 - accuracy: 0.7120
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/487 [==============&gt;...............] - ETA: 0s - loss: 0.9285 - accuracy: 0.7121
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
271/487 [===============&gt;..............] - ETA: 0s - loss: 0.9280 - accuracy: 0.7122
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
290/487 [================&gt;.............] - ETA: 0s - loss: 0.9269 - accuracy: 0.7124
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 0.9262 - accuracy: 0.7126
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.9248 - accuracy: 0.7130
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 0.9239 - accuracy: 0.7133
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 0.9230 - accuracy: 0.7135
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
387/487 [======================&gt;.......] - ETA: 0s - loss: 0.9224 - accuracy: 0.7136
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
406/487 [========================&gt;.....] - ETA: 0s - loss: 0.9217 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
426/487 [=========================&gt;....] - ETA: 0s - loss: 0.9210 - accuracy: 0.7138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
446/487 [==========================&gt;...] - ETA: 0s - loss: 0.9199 - accuracy: 0.7139
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/487 [===========================&gt;..] - ETA: 0s - loss: 0.9187 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.9183 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9183 - accuracy: 0.7143 - val_loss: 0.9005 - val_accuracy: 0.7187 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8668 - accuracy: 0.7334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8882 - accuracy: 0.7204
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8911 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.9562 - accuracy: 0.6803
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 1.0616 - accuracy: 0.6218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/487 [=====&gt;........................] - ETA: 1s - loss: 1.1049 - accuracy: 0.6008
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 1.1214 - accuracy: 0.5981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
136/487 [=======&gt;......................] - ETA: 0s - loss: 1.1287 - accuracy: 0.6011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
155/487 [========&gt;.....................] - ETA: 0s - loss: 1.1308 - accuracy: 0.6056
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
173/487 [=========&gt;....................] - ETA: 0s - loss: 1.1296 - accuracy: 0.6098
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
192/487 [==========&gt;...................] - ETA: 0s - loss: 1.1278 - accuracy: 0.6133
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
211/487 [===========&gt;..................] - ETA: 0s - loss: 1.1239 - accuracy: 0.6170
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
231/487 [=============&gt;................] - ETA: 0s - loss: 1.1204 - accuracy: 0.6198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/487 [==============&gt;...............] - ETA: 0s - loss: 1.1166 - accuracy: 0.6224
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
270/487 [===============&gt;..............] - ETA: 0s - loss: 1.1125 - accuracy: 0.6250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/487 [================&gt;.............] - ETA: 0s - loss: 1.1088 - accuracy: 0.6271
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 1.1058 - accuracy: 0.6284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/487 [===================&gt;..........] - ETA: 0s - loss: 1.1024 - accuracy: 0.6300
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 1.0988 - accuracy: 0.6316
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 1.0951 - accuracy: 0.6333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
383/487 [======================&gt;.......] - ETA: 0s - loss: 1.0924 - accuracy: 0.6344
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
402/487 [=======================&gt;......] - ETA: 0s - loss: 1.0892 - accuracy: 0.6358
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/487 [========================&gt;.....] - ETA: 0s - loss: 1.0856 - accuracy: 0.6372
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
440/487 [==========================&gt;...] - ETA: 0s - loss: 1.0823 - accuracy: 0.6385
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/487 [===========================&gt;..] - ETA: 0s - loss: 1.0794 - accuracy: 0.6397
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
477/487 [============================&gt;.] - ETA: 0s - loss: 1.0764 - accuracy: 0.6409
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0749 - accuracy: 0.6415 - val_loss: 0.9990 - val_accuracy: 0.6722 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9407 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.9816 - accuracy: 0.6824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.9890 - accuracy: 0.6777
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.9896 - accuracy: 0.6761
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 80/487 [===&gt;..........................] - ETA: 1s - loss: 0.9891 - accuracy: 0.6771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 99/487 [=====&gt;........................] - ETA: 1s - loss: 0.9876 - accuracy: 0.6767
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/487 [======&gt;.......................] - ETA: 0s - loss: 0.9863 - accuracy: 0.6773
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
139/487 [=======&gt;......................] - ETA: 0s - loss: 0.9843 - accuracy: 0.6777
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
159/487 [========&gt;.....................] - ETA: 0s - loss: 0.9820 - accuracy: 0.6787
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
179/487 [==========&gt;...................] - ETA: 0s - loss: 0.9806 - accuracy: 0.6789
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
199/487 [===========&gt;..................] - ETA: 0s - loss: 0.9797 - accuracy: 0.6792
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
219/487 [============&gt;.................] - ETA: 0s - loss: 0.9785 - accuracy: 0.6795
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
237/487 [=============&gt;................] - ETA: 0s - loss: 0.9769 - accuracy: 0.6805
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
255/487 [==============&gt;...............] - ETA: 0s - loss: 0.9757 - accuracy: 0.6810
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/487 [===============&gt;..............] - ETA: 0s - loss: 0.9741 - accuracy: 0.6818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.9727 - accuracy: 0.6825
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 0.9723 - accuracy: 0.6826
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/487 [===================&gt;..........] - ETA: 0s - loss: 0.9713 - accuracy: 0.6828
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/487 [====================&gt;.........] - ETA: 0s - loss: 0.9700 - accuracy: 0.6833
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
371/487 [=====================&gt;........] - ETA: 0s - loss: 0.9689 - accuracy: 0.6838
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
390/487 [=======================&gt;......] - ETA: 0s - loss: 0.9671 - accuracy: 0.6845
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
409/487 [========================&gt;.....] - ETA: 0s - loss: 0.9660 - accuracy: 0.6847
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
429/487 [=========================&gt;....] - ETA: 0s - loss: 0.9649 - accuracy: 0.6850
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
447/487 [==========================&gt;...] - ETA: 0s - loss: 0.9636 - accuracy: 0.6855
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/487 [===========================&gt;..] - ETA: 0s - loss: 0.9624 - accuracy: 0.6859
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9615 - accuracy: 0.6863
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9615 - accuracy: 0.6864 - val_loss: 0.9364 - val_accuracy: 0.6952 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9119 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.9286 - accuracy: 0.6986
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.9376 - accuracy: 0.6948
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.9364 - accuracy: 0.6950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 77/487 [===&gt;..........................] - ETA: 1s - loss: 0.9330 - accuracy: 0.6966
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 0.9325 - accuracy: 0.6960
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 0.9301 - accuracy: 0.6968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
137/487 [=======&gt;......................] - ETA: 0s - loss: 0.9300 - accuracy: 0.6973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
156/487 [========&gt;.....................] - ETA: 0s - loss: 0.9298 - accuracy: 0.6971
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
175/487 [=========&gt;....................] - ETA: 0s - loss: 0.9291 - accuracy: 0.6973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
194/487 [==========&gt;...................] - ETA: 0s - loss: 0.9277 - accuracy: 0.6978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/487 [============&gt;.................] - ETA: 0s - loss: 0.9267 - accuracy: 0.6984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
233/487 [=============&gt;................] - ETA: 0s - loss: 0.9257 - accuracy: 0.6985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/487 [==============&gt;...............] - ETA: 0s - loss: 0.9243 - accuracy: 0.6989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
272/487 [===============&gt;..............] - ETA: 0s - loss: 0.9237 - accuracy: 0.6992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.9225 - accuracy: 0.6999
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
307/487 [=================&gt;............] - ETA: 0s - loss: 0.9214 - accuracy: 0.7002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
326/487 [===================&gt;..........] - ETA: 0s - loss: 0.9210 - accuracy: 0.7003
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
344/487 [====================&gt;.........] - ETA: 0s - loss: 0.9199 - accuracy: 0.7005
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
363/487 [=====================&gt;........] - ETA: 0s - loss: 0.9189 - accuracy: 0.7008
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
381/487 [======================&gt;.......] - ETA: 0s - loss: 0.9181 - accuracy: 0.7011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
400/487 [=======================&gt;......] - ETA: 0s - loss: 0.9177 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
419/487 [========================&gt;.....] - ETA: 0s - loss: 0.9172 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
438/487 [=========================&gt;....] - ETA: 0s - loss: 0.9170 - accuracy: 0.7011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
457/487 [===========================&gt;..] - ETA: 0s - loss: 0.9165 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
475/487 [============================&gt;.] - ETA: 0s - loss: 0.9162 - accuracy: 0.7013
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9157 - accuracy: 0.7015 - val_loss: 0.9021 - val_accuracy: 0.7052 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.9369 - accuracy: 0.6934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8928 - accuracy: 0.7073
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.8948 - accuracy: 0.7081
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.8957 - accuracy: 0.7062
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 0.8973 - accuracy: 0.7062
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 95/487 [====&gt;.........................] - ETA: 1s - loss: 0.8967 - accuracy: 0.7067
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
114/487 [======&gt;.......................] - ETA: 1s - loss: 0.8978 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/487 [=======&gt;......................] - ETA: 0s - loss: 0.8975 - accuracy: 0.7064
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
153/487 [========&gt;.....................] - ETA: 0s - loss: 0.8963 - accuracy: 0.7069
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
170/487 [=========&gt;....................] - ETA: 0s - loss: 0.8962 - accuracy: 0.7068
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
189/487 [==========&gt;...................] - ETA: 0s - loss: 0.8956 - accuracy: 0.7072
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
208/487 [===========&gt;..................] - ETA: 0s - loss: 0.8952 - accuracy: 0.7075
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
227/487 [============&gt;.................] - ETA: 0s - loss: 0.8945 - accuracy: 0.7076
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
248/487 [==============&gt;...............] - ETA: 0s - loss: 0.8945 - accuracy: 0.7078
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
269/487 [===============&gt;..............] - ETA: 0s - loss: 0.8934 - accuracy: 0.7082
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/487 [================&gt;.............] - ETA: 0s - loss: 0.8921 - accuracy: 0.7086
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 0.8918 - accuracy: 0.7086
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.8916 - accuracy: 0.7086
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/487 [====================&gt;.........] - ETA: 0s - loss: 0.8913 - accuracy: 0.7088
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
370/487 [=====================&gt;........] - ETA: 0s - loss: 0.8907 - accuracy: 0.7089
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/487 [=======================&gt;......] - ETA: 0s - loss: 0.8900 - accuracy: 0.7091
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
412/487 [========================&gt;.....] - ETA: 0s - loss: 0.8892 - accuracy: 0.7092
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
433/487 [=========================&gt;....] - ETA: 0s - loss: 0.8888 - accuracy: 0.7092
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
454/487 [==========================&gt;...] - ETA: 0s - loss: 0.8882 - accuracy: 0.7094
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
475/487 [============================&gt;.] - ETA: 0s - loss: 0.8870 - accuracy: 0.7099
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8865 - accuracy: 0.7102 - val_loss: 0.8775 - val_accuracy: 0.7122 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8805 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/487 [&gt;.............................] - ETA: 1s - loss: 0.8702 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 43/487 [=&gt;............................] - ETA: 1s - loss: 0.8745 - accuracy: 0.7132
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 63/487 [==&gt;...........................] - ETA: 1s - loss: 0.8694 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/487 [====&gt;.........................] - ETA: 1s - loss: 0.8709 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
103/487 [=====&gt;........................] - ETA: 0s - loss: 0.8709 - accuracy: 0.7141
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
123/487 [======&gt;.......................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7144
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 0.8716 - accuracy: 0.7134
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 0.8714 - accuracy: 0.7135
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
184/487 [==========&gt;...................] - ETA: 0s - loss: 0.8701 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8703 - accuracy: 0.7140
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8693 - accuracy: 0.7144
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/487 [==============&gt;...............] - ETA: 0s - loss: 0.8693 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
265/487 [===============&gt;..............] - ETA: 0s - loss: 0.8688 - accuracy: 0.7147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
285/487 [================&gt;.............] - ETA: 0s - loss: 0.8680 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
304/487 [=================&gt;............] - ETA: 0s - loss: 0.8673 - accuracy: 0.7153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
323/487 [==================&gt;...........] - ETA: 0s - loss: 0.8677 - accuracy: 0.7149
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
342/487 [====================&gt;.........] - ETA: 0s - loss: 0.8669 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
361/487 [=====================&gt;........] - ETA: 0s - loss: 0.8672 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
381/487 [======================&gt;.......] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
400/487 [=======================&gt;......] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
419/487 [========================&gt;.....] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
438/487 [=========================&gt;....] - ETA: 0s - loss: 0.8668 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
457/487 [===========================&gt;..] - ETA: 0s - loss: 0.8662 - accuracy: 0.7153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
476/487 [============================&gt;.] - ETA: 0s - loss: 0.8658 - accuracy: 0.7155
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8655 - accuracy: 0.7156 - val_loss: 0.8604 - val_accuracy: 0.7173 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 0.8281 - accuracy: 0.7246
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/487 [&gt;.............................] - ETA: 1s - loss: 0.8595 - accuracy: 0.7177
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/487 [=&gt;............................] - ETA: 1s - loss: 0.8607 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 62/487 [==&gt;...........................] - ETA: 1s - loss: 0.8591 - accuracy: 0.7171
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 83/487 [====&gt;.........................] - ETA: 1s - loss: 0.8576 - accuracy: 0.7170
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
104/487 [=====&gt;........................] - ETA: 0s - loss: 0.8541 - accuracy: 0.7182
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
124/487 [======&gt;.......................] - ETA: 0s - loss: 0.8536 - accuracy: 0.7185
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
143/487 [=======&gt;......................] - ETA: 0s - loss: 0.8515 - accuracy: 0.7197
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
162/487 [========&gt;.....................] - ETA: 0s - loss: 0.8517 - accuracy: 0.7196
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
181/487 [==========&gt;...................] - ETA: 0s - loss: 0.8526 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
200/487 [===========&gt;..................] - ETA: 0s - loss: 0.8528 - accuracy: 0.7189
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
219/487 [============&gt;.................] - ETA: 0s - loss: 0.8523 - accuracy: 0.7189
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
238/487 [=============&gt;................] - ETA: 0s - loss: 0.8525 - accuracy: 0.7186
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
257/487 [==============&gt;...............] - ETA: 0s - loss: 0.8520 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
276/487 [================&gt;.............] - ETA: 0s - loss: 0.8521 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
295/487 [=================&gt;............] - ETA: 0s - loss: 0.8514 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
315/487 [==================&gt;...........] - ETA: 0s - loss: 0.8512 - accuracy: 0.7194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
334/487 [===================&gt;..........] - ETA: 0s - loss: 0.8511 - accuracy: 0.7194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
354/487 [====================&gt;.........] - ETA: 0s - loss: 0.8508 - accuracy: 0.7197
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
373/487 [=====================&gt;........] - ETA: 0s - loss: 0.8502 - accuracy: 0.7200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
390/487 [=======================&gt;......] - ETA: 0s - loss: 0.8500 - accuracy: 0.7200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
407/487 [========================&gt;.....] - ETA: 0s - loss: 0.8502 - accuracy: 0.7198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
425/487 [=========================&gt;....] - ETA: 0s - loss: 0.8506 - accuracy: 0.7196
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
444/487 [==========================&gt;...] - ETA: 0s - loss: 0.8504 - accuracy: 0.7195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
463/487 [===========================&gt;..] - ETA: 0s - loss: 0.8503 - accuracy: 0.7194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/487 [============================&gt;.] - ETA: 0s - loss: 0.8508 - accuracy: 0.7192
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_epoch10.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8506 - accuracy: 0.7192 - val_loss: 0.8477 - val_accuracy: 0.7208 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8714 - accuracy: 0.7158
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 19/487 [&gt;.............................] - ETA: 1s - loss: 0.8351 - accuracy: 0.7264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 36/487 [=&gt;............................] - ETA: 1s - loss: 0.8425 - accuracy: 0.7227
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 54/487 [==&gt;...........................] - ETA: 1s - loss: 0.8404 - accuracy: 0.7226
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 73/487 [===&gt;..........................] - ETA: 1s - loss: 0.8400 - accuracy: 0.7235
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 92/487 [====&gt;.........................] - ETA: 1s - loss: 0.8441 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
112/487 [=====&gt;........................] - ETA: 1s - loss: 0.8432 - accuracy: 0.7209
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
131/487 [=======&gt;......................] - ETA: 0s - loss: 0.8418 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
149/487 [========&gt;.....................] - ETA: 0s - loss: 0.8420 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/487 [=========&gt;....................] - ETA: 0s - loss: 0.8428 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
188/487 [==========&gt;...................] - ETA: 0s - loss: 0.8420 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/487 [===========&gt;..................] - ETA: 0s - loss: 0.8415 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
225/487 [============&gt;.................] - ETA: 0s - loss: 0.8419 - accuracy: 0.7212
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
244/487 [==============&gt;...............] - ETA: 0s - loss: 0.8419 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
263/487 [===============&gt;..............] - ETA: 0s - loss: 0.8413 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
282/487 [================&gt;.............] - ETA: 0s - loss: 0.8411 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
301/487 [=================&gt;............] - ETA: 0s - loss: 0.8409 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
320/487 [==================&gt;...........] - ETA: 0s - loss: 0.8412 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
335/487 [===================&gt;..........] - ETA: 0s - loss: 0.8405 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
354/487 [====================&gt;.........] - ETA: 0s - loss: 0.8403 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
373/487 [=====================&gt;........] - ETA: 0s - loss: 0.8405 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
392/487 [=======================&gt;......] - ETA: 0s - loss: 0.8402 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
411/487 [========================&gt;.....] - ETA: 0s - loss: 0.8406 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
430/487 [=========================&gt;....] - ETA: 0s - loss: 0.8403 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
449/487 [==========================&gt;...] - ETA: 0s - loss: 0.8400 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.8395 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8393 - accuracy: 0.7219
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8392 - accuracy: 0.7219 - val_loss: 0.8378 - val_accuracy: 0.7228 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8592 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8313 - accuracy: 0.7233
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8307 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8270 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 77/487 [===&gt;..........................] - ETA: 1s - loss: 0.8282 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 94/487 [====&gt;.........................] - ETA: 1s - loss: 0.8308 - accuracy: 0.7248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
113/487 [=====&gt;........................] - ETA: 1s - loss: 0.8295 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
133/487 [=======&gt;......................] - ETA: 0s - loss: 0.8302 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
152/487 [========&gt;.....................] - ETA: 0s - loss: 0.8304 - accuracy: 0.7248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
171/487 [=========&gt;....................] - ETA: 0s - loss: 0.8300 - accuracy: 0.7250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
190/487 [==========&gt;...................] - ETA: 0s - loss: 0.8293 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
209/487 [===========&gt;..................] - ETA: 0s - loss: 0.8300 - accuracy: 0.7249
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
228/487 [=============&gt;................] - ETA: 0s - loss: 0.8303 - accuracy: 0.7247
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
248/487 [==============&gt;...............] - ETA: 0s - loss: 0.8309 - accuracy: 0.7244
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
268/487 [===============&gt;..............] - ETA: 0s - loss: 0.8322 - accuracy: 0.7238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
288/487 [================&gt;.............] - ETA: 0s - loss: 0.8309 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 0.8306 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.8310 - accuracy: 0.7244
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/487 [====================&gt;.........] - ETA: 0s - loss: 0.8310 - accuracy: 0.7241
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
370/487 [=====================&gt;........] - ETA: 0s - loss: 0.8317 - accuracy: 0.7236
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
389/487 [======================&gt;.......] - ETA: 0s - loss: 0.8315 - accuracy: 0.7238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
408/487 [========================&gt;.....] - ETA: 0s - loss: 0.8310 - accuracy: 0.7240
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/487 [=========================&gt;....] - ETA: 0s - loss: 0.8302 - accuracy: 0.7241
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
448/487 [==========================&gt;...] - ETA: 0s - loss: 0.8302 - accuracy: 0.7242
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.8299 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
487/487 [==============================] - ETA: 0s - loss: 0.8299 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8299 - accuracy: 0.7243 - val_loss: 0.8295 - val_accuracy: 0.7256 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8336 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 22/487 [&gt;.............................] - ETA: 1s - loss: 0.8262 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 42/487 [=&gt;............................] - ETA: 1s - loss: 0.8252 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 62/487 [==&gt;...........................] - ETA: 1s - loss: 0.8226 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 82/487 [====&gt;.........................] - ETA: 1s - loss: 0.8259 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 0s - loss: 0.8262 - accuracy: 0.7251
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
121/487 [======&gt;.......................] - ETA: 0s - loss: 0.8264 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
142/487 [=======&gt;......................] - ETA: 0s - loss: 0.8244 - accuracy: 0.7258
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 0.8238 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
184/487 [==========&gt;...................] - ETA: 0s - loss: 0.8249 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8251 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8243 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
245/487 [==============&gt;...............] - ETA: 0s - loss: 0.8253 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
265/487 [===============&gt;..............] - ETA: 0s - loss: 0.8250 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
285/487 [================&gt;.............] - ETA: 0s - loss: 0.8243 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
305/487 [=================&gt;............] - ETA: 0s - loss: 0.8248 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
325/487 [===================&gt;..........] - ETA: 0s - loss: 0.8245 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
345/487 [====================&gt;.........] - ETA: 0s - loss: 0.8239 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
366/487 [=====================&gt;........] - ETA: 0s - loss: 0.8239 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.8233 - accuracy: 0.7260
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
407/487 [========================&gt;.....] - ETA: 0s - loss: 0.8233 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/487 [=========================&gt;....] - ETA: 0s - loss: 0.8230 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
449/487 [==========================&gt;...] - ETA: 0s - loss: 0.8225 - accuracy: 0.7262
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
469/487 [===========================&gt;..] - ETA: 0s - loss: 0.8224 - accuracy: 0.7263
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8220 - accuracy: 0.7263 - val_loss: 0.8222 - val_accuracy: 0.7270 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8205 - accuracy: 0.7461
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8137 - accuracy: 0.7326
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8155 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8183 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 77/487 [===&gt;..........................] - ETA: 1s - loss: 0.8191 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 0.8184 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
116/487 [======&gt;.......................] - ETA: 0s - loss: 0.8182 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
135/487 [=======&gt;......................] - ETA: 0s - loss: 0.8188 - accuracy: 0.7273
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
154/487 [========&gt;.....................] - ETA: 0s - loss: 0.8181 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
173/487 [=========&gt;....................] - ETA: 0s - loss: 0.8175 - accuracy: 0.7274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
192/487 [==========&gt;...................] - ETA: 0s - loss: 0.8165 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
212/487 [============&gt;.................] - ETA: 0s - loss: 0.8164 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
232/487 [=============&gt;................] - ETA: 0s - loss: 0.8181 - accuracy: 0.7274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
253/487 [==============&gt;...............] - ETA: 0s - loss: 0.8190 - accuracy: 0.7269
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/487 [===============&gt;..............] - ETA: 0s - loss: 0.8183 - accuracy: 0.7273
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
293/487 [=================&gt;............] - ETA: 0s - loss: 0.8175 - accuracy: 0.7276
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 0.8167 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/487 [===================&gt;..........] - ETA: 0s - loss: 0.8163 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/487 [====================&gt;.........] - ETA: 0s - loss: 0.8162 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
368/487 [=====================&gt;........] - ETA: 0s - loss: 0.8158 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.8157 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
404/487 [=======================&gt;......] - ETA: 0s - loss: 0.8163 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
423/487 [=========================&gt;....] - ETA: 0s - loss: 0.8162 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
442/487 [==========================&gt;...] - ETA: 0s - loss: 0.8161 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
461/487 [===========================&gt;..] - ETA: 0s - loss: 0.8153 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
480/487 [============================&gt;.] - ETA: 0s - loss: 0.8150 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8150 - accuracy: 0.7282 - val_loss: 0.8156 - val_accuracy: 0.7286 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8110 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8125 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8146 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8121 - accuracy: 0.7294
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 0.8121 - accuracy: 0.7291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/487 [=====&gt;........................] - ETA: 1s - loss: 0.8145 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 0.8150 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
136/487 [=======&gt;......................] - ETA: 0s - loss: 0.8142 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
156/487 [========&gt;.....................] - ETA: 0s - loss: 0.8150 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
175/487 [=========&gt;....................] - ETA: 0s - loss: 0.8142 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
194/487 [==========&gt;...................] - ETA: 0s - loss: 0.8136 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
214/487 [============&gt;.................] - ETA: 0s - loss: 0.8134 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
234/487 [=============&gt;................] - ETA: 0s - loss: 0.8130 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
254/487 [==============&gt;...............] - ETA: 0s - loss: 0.8126 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/487 [===============&gt;..............] - ETA: 0s - loss: 0.8126 - accuracy: 0.7288
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
295/487 [=================&gt;............] - ETA: 0s - loss: 0.8124 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
315/487 [==================&gt;...........] - ETA: 0s - loss: 0.8120 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
335/487 [===================&gt;..........] - ETA: 0s - loss: 0.8116 - accuracy: 0.7291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
356/487 [====================&gt;.........] - ETA: 0s - loss: 0.8104 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/487 [======================&gt;.......] - ETA: 0s - loss: 0.8102 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
396/487 [=======================&gt;......] - ETA: 0s - loss: 0.8099 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
416/487 [========================&gt;.....] - ETA: 0s - loss: 0.8095 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
435/487 [=========================&gt;....] - ETA: 0s - loss: 0.8095 - accuracy: 0.7297
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
455/487 [===========================&gt;..] - ETA: 0s - loss: 0.8090 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
474/487 [============================&gt;.] - ETA: 0s - loss: 0.8086 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8086 - accuracy: 0.7299 - val_loss: 0.8097 - val_accuracy: 0.7300 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8227 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8092 - accuracy: 0.7264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8096 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 0.8104 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 0.8075 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 98/487 [=====&gt;........................] - ETA: 1s - loss: 0.8040 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
118/487 [======&gt;.......................] - ETA: 0s - loss: 0.8028 - accuracy: 0.7312
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
138/487 [=======&gt;......................] - ETA: 0s - loss: 0.8025 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
157/487 [========&gt;.....................] - ETA: 0s - loss: 0.8039 - accuracy: 0.7311
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
178/487 [=========&gt;....................] - ETA: 0s - loss: 0.8032 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
199/487 [===========&gt;..................] - ETA: 0s - loss: 0.8020 - accuracy: 0.7316
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
220/487 [============&gt;.................] - ETA: 0s - loss: 0.8033 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/487 [=============&gt;................] - ETA: 0s - loss: 0.8040 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
261/487 [===============&gt;..............] - ETA: 0s - loss: 0.8044 - accuracy: 0.7308
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
281/487 [================&gt;.............] - ETA: 0s - loss: 0.8050 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
301/487 [=================&gt;............] - ETA: 0s - loss: 0.8044 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
321/487 [==================&gt;...........] - ETA: 0s - loss: 0.8045 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
341/487 [====================&gt;.........] - ETA: 0s - loss: 0.8040 - accuracy: 0.7308
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
361/487 [=====================&gt;........] - ETA: 0s - loss: 0.8037 - accuracy: 0.7308
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
382/487 [======================&gt;.......] - ETA: 0s - loss: 0.8033 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
403/487 [=======================&gt;......] - ETA: 0s - loss: 0.8032 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/487 [=========================&gt;....] - ETA: 0s - loss: 0.8034 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
445/487 [==========================&gt;...] - ETA: 0s - loss: 0.8027 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/487 [===========================&gt;..] - ETA: 0s - loss: 0.8028 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8028 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 16: val_loss improved from 0.80966 to 0.80423, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: val_loss improved from 0.80966 to 0.80423, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8028 - accuracy: 0.7313 - val_loss: 0.8042 - val_accuracy: 0.7314 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8746 - accuracy: 0.7129
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 21/487 [&gt;.............................] - ETA: 1s - loss: 0.8053 - accuracy: 0.7304
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 41/487 [=&gt;............................] - ETA: 1s - loss: 0.7979 - accuracy: 0.7339
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 61/487 [==&gt;...........................] - ETA: 1s - loss: 0.8002 - accuracy: 0.7334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 81/487 [===&gt;..........................] - ETA: 1s - loss: 0.8004 - accuracy: 0.7327
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
101/487 [=====&gt;........................] - ETA: 0s - loss: 0.8014 - accuracy: 0.7321
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
122/487 [======&gt;.......................] - ETA: 0s - loss: 0.7998 - accuracy: 0.7319
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
141/487 [=======&gt;......................] - ETA: 0s - loss: 0.8005 - accuracy: 0.7317
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
160/487 [========&gt;.....................] - ETA: 0s - loss: 0.7999 - accuracy: 0.7320
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
180/487 [==========&gt;...................] - ETA: 0s - loss: 0.7998 - accuracy: 0.7321
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
199/487 [===========&gt;..................] - ETA: 0s - loss: 0.7992 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
218/487 [============&gt;.................] - ETA: 0s - loss: 0.7994 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
237/487 [=============&gt;................] - ETA: 0s - loss: 0.7995 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/487 [==============&gt;...............] - ETA: 0s - loss: 0.7985 - accuracy: 0.7326
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
275/487 [===============&gt;..............] - ETA: 0s - loss: 0.7983 - accuracy: 0.7327
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
294/487 [=================&gt;............] - ETA: 0s - loss: 0.7990 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 0.7991 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/487 [===================&gt;..........] - ETA: 0s - loss: 0.7997 - accuracy: 0.7318
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
350/487 [====================&gt;.........] - ETA: 0s - loss: 0.7989 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
369/487 [=====================&gt;........] - ETA: 0s - loss: 0.7990 - accuracy: 0.7322
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
388/487 [======================&gt;.......] - ETA: 0s - loss: 0.7982 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
408/487 [========================&gt;.....] - ETA: 0s - loss: 0.7981 - accuracy: 0.7325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/487 [=========================&gt;....] - ETA: 0s - loss: 0.7980 - accuracy: 0.7324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
447/487 [==========================&gt;...] - ETA: 0s - loss: 0.7977 - accuracy: 0.7325
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_5806</span><span class="o">/</span><span class="mf">3673671120.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">24</span>         <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>     <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/utils/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">64</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
<span class="g g-Whitespace">     </span><span class="mi">66</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ni">fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">   </span><span class="mi">1407</span>                 <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1408</span>               <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1409</span>               <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1410</span>               <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1411</span>                 <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">913</span> 
<span class="g g-Whitespace">    </span><span class="mi">914</span>       <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">915</span>         <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">916</span> 
<span class="g g-Whitespace">    </span><span class="mi">917</span>       <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">_call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">945</span>       <span class="c1"># In this case we have created variables on the first call, so we run the</span>
<span class="g g-Whitespace">    </span><span class="mi">946</span>       <span class="c1"># defunned version which is guaranteed to never create variables.</span>
<span class="ne">--&gt; </span><span class="mi">947</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateless_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>     <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateful_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span>       <span class="c1"># Release the lock early so that multiple threads can perform the call</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2452</span>        <span class="n">filtered_flat_args</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_define_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2453</span>     <span class="k">return</span> <span class="n">graph_function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">2454</span>         <span class="n">filtered_flat_args</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">graph_function</span><span class="o">.</span><span class="n">captured_inputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">   </span><span class="mi">2455</span> 
<span class="g g-Whitespace">   </span><span class="mi">2456</span>   <span class="nd">@property</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">_call_flat</span><span class="nt">(self, args, captured_inputs, cancellation_manager)</span>
<span class="g g-Whitespace">   </span><span class="mi">1859</span>       <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="g g-Whitespace">   </span><span class="mi">1860</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_call_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">1861</span>           <span class="n">ctx</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_manager</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1862</span>     <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1863</span>         <span class="n">args</span><span class="p">,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">call</span><span class="nt">(self, ctx, args, cancellation_manager)</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span>               <span class="n">inputs</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>               <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">502</span>               <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>           <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/execute.py</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>     <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>     <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">55</span>                                         <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>     <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-sparsity">
<h2>Check sparsity<a class="headerlink" href="#check-sparsity" title="Permalink to this headline">#</a></h2>
<p>Make a quick check that the model was indeed trained sparse. Well just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing 0. Note logarithmic y axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.75
</pre></div>
</div>
<img alt="_images/2.3_compression_15_1.png" src="_images/2.3_compression_15_1.png" />
</div>
</div>
<p>Compare this to the first model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="n">model_orig</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span> <span class="c1">#locally</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model_orig</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span> <span class="c1">#for colab</span>

<span class="n">w_orig</span> <span class="o">=</span> <span class="n">model_orig</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">_</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w_orig</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Original&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Pruned&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x14cbabfa0&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_17_1.png" src="_images/2.3_compression_17_1.png" />
</div>
</div>
</section>
<section id="check-performance">
<h2>Check performance<a class="headerlink" href="#check-performance" title="Permalink to this headline">#</a></h2>
<p>How does this 75% sparse model compare against the unpruned model? Lets report the accuracy and make a ROC curve. The pruned model is shown with solid lines, the unpruned model is shown with dashed lines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span> <span class="c1">#locally</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span> <span class="c1">#for colab</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5188/5188 [==============================] - 4s 698us/step
5188/5188 [==============================] - 4s 728us/step
Accuracy unpruned: 0.7516506024096385
Accuracy pruned:   0.7429879518072289
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x14dd01c70&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_19_2.png" src="_images/2.3_compression_19_2.png" />
</div>
</div>
<section id="reduced-size-model">
<h3>Reduced size model<a class="headerlink" href="#reduced-size-model" title="Permalink to this headline">#</a></h3>
<p>What if instead of pruning our model we simply shrink the size? Lets now train a model where the hidden layers are a quarter of the size they are in the original model: 3 hidden layers with 16, then 8, then 8 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_small</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">16</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_1_half&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model_small</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/wmccorma/miniconda3/envs/ml-iaifi/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 3:45 - loss: 1.6479 - accuracy: 0.1084WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
452/487 [==========================&gt;...] - ETA: 0s - loss: 1.5647 - accuracy: 0.2630
***callbacks***
saving losses to model_1_half/losses.log

Epoch 1: val_loss improved from inf to 1.45849, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 1.45849, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 2ms/step - loss: 1.5577 - accuracy: 0.2705 - val_loss: 1.4585 - val_accuracy: 0.3769 - lr: 1.0000e-04
Epoch 2/30
477/487 [============================&gt;.] - ETA: 0s - loss: 1.3490 - accuracy: 0.4994
***callbacks***
saving losses to model_1_half/losses.log

Epoch 2: val_loss improved from 1.45849 to 1.24289, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 1.45849 to 1.24289, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.3470 - accuracy: 0.5006 - val_loss: 1.2429 - val_accuracy: 0.5633 - lr: 1.0000e-04
Epoch 3/30
474/487 [============================&gt;.] - ETA: 0s - loss: 1.1766 - accuracy: 0.5798
***callbacks***
saving losses to model_1_half/losses.log

Epoch 3: val_loss improved from 1.24289 to 1.12312, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 1.24289 to 1.12312, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.1753 - accuracy: 0.5802 - val_loss: 1.1231 - val_accuracy: 0.5967 - lr: 1.0000e-04
Epoch 4/30
463/487 [===========================&gt;..] - ETA: 0s - loss: 1.0858 - accuracy: 0.6139
***callbacks***
saving losses to model_1_half/losses.log

Epoch 4: val_loss improved from 1.12312 to 1.05513, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 1.12312 to 1.05513, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0845 - accuracy: 0.6145 - val_loss: 1.0551 - val_accuracy: 0.6293 - lr: 1.0000e-04
Epoch 5/30
461/487 [===========================&gt;..] - ETA: 0s - loss: 1.0314 - accuracy: 0.6338
***callbacks***
saving losses to model_1_half/losses.log

Epoch 5: val_loss improved from 1.05513 to 1.01500, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 5: val_loss improved from 1.05513 to 1.01500, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0305 - accuracy: 0.6341 - val_loss: 1.0150 - val_accuracy: 0.6405 - lr: 1.0000e-04
Epoch 6/30
457/487 [===========================&gt;..] - ETA: 0s - loss: 0.9997 - accuracy: 0.6436
***callbacks***
saving losses to model_1_half/losses.log

Epoch 6: val_loss improved from 1.01500 to 0.99025, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 6: val_loss improved from 1.01500 to 0.99025, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9990 - accuracy: 0.6438 - val_loss: 0.9903 - val_accuracy: 0.6487 - lr: 1.0000e-04
Epoch 7/30
476/487 [============================&gt;.] - ETA: 0s - loss: 0.9776 - accuracy: 0.6544
***callbacks***
saving losses to model_1_half/losses.log

Epoch 7: val_loss improved from 0.99025 to 0.97078, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 7: val_loss improved from 0.99025 to 0.97078, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9773 - accuracy: 0.6546 - val_loss: 0.9708 - val_accuracy: 0.6602 - lr: 1.0000e-04
Epoch 8/30
463/487 [===========================&gt;..] - ETA: 0s - loss: 0.9600 - accuracy: 0.6656
***callbacks***
saving losses to model_1_half/losses.log

Epoch 8: val_loss improved from 0.97078 to 0.95339, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 8: val_loss improved from 0.97078 to 0.95339, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9590 - accuracy: 0.6661 - val_loss: 0.9534 - val_accuracy: 0.6717 - lr: 1.0000e-04
Epoch 9/30
475/487 [============================&gt;.] - ETA: 0s - loss: 0.9421 - accuracy: 0.6766
***callbacks***
saving losses to model_1_half/losses.log

Epoch 9: val_loss improved from 0.95339 to 0.93640, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 9: val_loss improved from 0.95339 to 0.93640, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9418 - accuracy: 0.6768 - val_loss: 0.9364 - val_accuracy: 0.6825 - lr: 1.0000e-04
Epoch 10/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.9249 - accuracy: 0.6877
***callbacks***
saving losses to model_1_half/losses.log

Epoch 10: val_loss improved from 0.93640 to 0.91934, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 10: val_loss improved from 0.93640 to 0.91934, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9248 - accuracy: 0.6878 - val_loss: 0.9193 - val_accuracy: 0.6925 - lr: 1.0000e-04
Epoch 11/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.9077 - accuracy: 0.6974
***callbacks***
saving losses to model_1_half/losses.log

Epoch 11: val_loss improved from 0.91934 to 0.90247, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 11: val_loss improved from 0.91934 to 0.90247, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9076 - accuracy: 0.6974 - val_loss: 0.9025 - val_accuracy: 0.7007 - lr: 1.0000e-04
Epoch 12/30
466/487 [===========================&gt;..] - ETA: 0s - loss: 0.8913 - accuracy: 0.7049
***callbacks***
saving losses to model_1_half/losses.log

Epoch 12: val_loss improved from 0.90247 to 0.88672, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 12: val_loss improved from 0.90247 to 0.88672, saving model to model_1_half/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 12: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8910 - accuracy: 0.7050 - val_loss: 0.8867 - val_accuracy: 0.7075 - lr: 1.0000e-04
Epoch 13/30
452/487 [==========================&gt;...] - ETA: 0s - loss: 0.8765 - accuracy: 0.7105
***callbacks***
saving losses to model_1_half/losses.log

Epoch 13: val_loss improved from 0.88672 to 0.87253, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 13: val_loss improved from 0.88672 to 0.87253, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8759 - accuracy: 0.7106 - val_loss: 0.8725 - val_accuracy: 0.7124 - lr: 1.0000e-04
Epoch 14/30
487/487 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.7151
***callbacks***
saving losses to model_1_half/losses.log

Epoch 14: val_loss improved from 0.87253 to 0.86002, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 14: val_loss improved from 0.87253 to 0.86002, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8627 - accuracy: 0.7151 - val_loss: 0.8600 - val_accuracy: 0.7161 - lr: 1.0000e-04
Epoch 15/30
477/487 [============================&gt;.] - ETA: 0s - loss: 0.8515 - accuracy: 0.7178
***callbacks***
saving losses to model_1_half/losses.log

Epoch 15: val_loss improved from 0.86002 to 0.84929, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 15: val_loss improved from 0.86002 to 0.84929, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8512 - accuracy: 0.7179 - val_loss: 0.8493 - val_accuracy: 0.7192 - lr: 1.0000e-04
Epoch 16/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.8412 - accuracy: 0.7204
***callbacks***
saving losses to model_1_half/losses.log

Epoch 16: val_loss improved from 0.84929 to 0.83998, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 16: val_loss improved from 0.84929 to 0.83998, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8412 - accuracy: 0.7204 - val_loss: 0.8400 - val_accuracy: 0.7214 - lr: 1.0000e-04
Epoch 17/30
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.8329 - accuracy: 0.7224
***callbacks***
saving losses to model_1_half/losses.log

Epoch 17: val_loss improved from 0.83998 to 0.83208, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 17: val_loss improved from 0.83998 to 0.83208, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8326 - accuracy: 0.7224 - val_loss: 0.8321 - val_accuracy: 0.7233 - lr: 1.0000e-04
Epoch 18/30
452/487 [==========================&gt;...] - ETA: 0s - loss: 0.8253 - accuracy: 0.7236
***callbacks***
saving losses to model_1_half/losses.log

Epoch 18: val_loss improved from 0.83208 to 0.82520, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 18: val_loss improved from 0.83208 to 0.82520, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8253 - accuracy: 0.7238 - val_loss: 0.8252 - val_accuracy: 0.7242 - lr: 1.0000e-04
Epoch 19/30
479/487 [============================&gt;.] - ETA: 0s - loss: 0.8193 - accuracy: 0.7249
***callbacks***
saving losses to model_1_half/losses.log

Epoch 19: val_loss improved from 0.82520 to 0.81960, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 19: val_loss improved from 0.82520 to 0.81960, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8189 - accuracy: 0.7251 - val_loss: 0.8196 - val_accuracy: 0.7251 - lr: 1.0000e-04
Epoch 20/30
481/487 [============================&gt;.] - ETA: 0s - loss: 0.8134 - accuracy: 0.7260
***callbacks***
saving losses to model_1_half/losses.log

Epoch 20: val_loss improved from 0.81960 to 0.81440, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 20: val_loss improved from 0.81960 to 0.81440, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8134 - accuracy: 0.7260 - val_loss: 0.8144 - val_accuracy: 0.7264 - lr: 1.0000e-04
Epoch 21/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.8087 - accuracy: 0.7268
***callbacks***
saving losses to model_1_half/losses.log

Epoch 21: val_loss improved from 0.81440 to 0.80992, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 21: val_loss improved from 0.81440 to 0.80992, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8086 - accuracy: 0.7268 - val_loss: 0.8099 - val_accuracy: 0.7269 - lr: 1.0000e-04
Epoch 22/30
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.8047 - accuracy: 0.7274
***callbacks***
saving losses to model_1_half/losses.log

Epoch 22: val_loss improved from 0.80992 to 0.80614, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 22: val_loss improved from 0.80992 to 0.80614, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8043 - accuracy: 0.7275 - val_loss: 0.8061 - val_accuracy: 0.7276 - lr: 1.0000e-04
Epoch 23/30
475/487 [============================&gt;.] - ETA: 0s - loss: 0.8009 - accuracy: 0.7281
***callbacks***
saving losses to model_1_half/losses.log

Epoch 23: val_loss improved from 0.80614 to 0.80257, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 23: val_loss improved from 0.80614 to 0.80257, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.8005 - accuracy: 0.7282 - val_loss: 0.8026 - val_accuracy: 0.7282 - lr: 1.0000e-04
Epoch 24/30
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.7967 - accuracy: 0.7290
***callbacks***
saving losses to model_1_half/losses.log

Epoch 24: val_loss improved from 0.80257 to 0.79940, saving model to model_1_half/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 24: val_loss improved from 0.80257 to 0.79940, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7971 - accuracy: 0.7288 - val_loss: 0.7994 - val_accuracy: 0.7288 - lr: 1.0000e-04
Epoch 25/30
448/487 [==========================&gt;...] - ETA: 0s - loss: 0.7943 - accuracy: 0.7291
***callbacks***
saving losses to model_1_half/losses.log

Epoch 25: val_loss improved from 0.79940 to 0.79659, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 25: val_loss improved from 0.79940 to 0.79659, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7940 - accuracy: 0.7294 - val_loss: 0.7966 - val_accuracy: 0.7290 - lr: 1.0000e-04
Epoch 26/30
473/487 [============================&gt;.] - ETA: 0s - loss: 0.7908 - accuracy: 0.7301
***callbacks***
saving losses to model_1_half/losses.log

Epoch 26: val_loss improved from 0.79659 to 0.79385, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 26: val_loss improved from 0.79659 to 0.79385, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7911 - accuracy: 0.7299 - val_loss: 0.7939 - val_accuracy: 0.7298 - lr: 1.0000e-04
Epoch 27/30
481/487 [============================&gt;.] - ETA: 0s - loss: 0.7885 - accuracy: 0.7305
***callbacks***
saving losses to model_1_half/losses.log

Epoch 27: val_loss improved from 0.79385 to 0.79150, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 27: val_loss improved from 0.79385 to 0.79150, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7885 - accuracy: 0.7305 - val_loss: 0.7915 - val_accuracy: 0.7304 - lr: 1.0000e-04
Epoch 28/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.7859 - accuracy: 0.7310
***callbacks***
saving losses to model_1_half/losses.log

Epoch 28: val_loss improved from 0.79150 to 0.78935, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 28: val_loss improved from 0.79150 to 0.78935, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7860 - accuracy: 0.7309 - val_loss: 0.7894 - val_accuracy: 0.7306 - lr: 1.0000e-04
Epoch 29/30
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.7836 - accuracy: 0.7315
***callbacks***
saving losses to model_1_half/losses.log

Epoch 29: val_loss improved from 0.78935 to 0.78712, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 29: val_loss improved from 0.78935 to 0.78712, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7837 - accuracy: 0.7315 - val_loss: 0.7871 - val_accuracy: 0.7313 - lr: 1.0000e-04
Epoch 30/30
472/487 [============================&gt;.] - ETA: 0s - loss: 0.7819 - accuracy: 0.7318
***callbacks***
saving losses to model_1_half/losses.log

Epoch 30: val_loss improved from 0.78712 to 0.78498, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 30: val_loss improved from 0.78712 to 0.78498, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.7815 - accuracy: 0.7319 - val_loss: 0.7850 - val_accuracy: 0.7318 - lr: 1.0000e-04
</pre></div>
</div>
</div>
</div>
<p>How does this small model compare in terms of performance?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_small</span> <span class="o">=</span> <span class="n">model_small</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy small:    </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_small</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_small</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5188/5188 [==============================] - 3s 617us/step
5188/5188 [==============================] - 3s 593us/step
5188/5188 [==============================] - 3s 614us/step
Accuracy unpruned: 0.7516506024096385
Accuracy pruned:   0.7429879518072289
Accuracy small:    0.7301265060240963
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x14dd18340&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_24_2.png" src="_images/2.3_compression_24_2.png" />
</div>
</div>
<p>This looks quite good. Can we go further? Lets try a sparsity of 95%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.95</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2>Train the model<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>Well use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory model_2
The model isnt very complex, so this should just take a few minutes even on the CPU.
If youve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_4&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/wmccorma/miniconda3/envs/ml-iaifi/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 14:42 - loss: 0.7493 - accuracy: 0.7510WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0058s). Check your callbacks.
464/487 [===========================&gt;..] - ETA: 0s - loss: 0.7543 - accuracy: 0.7457
***callbacks***
saving losses to model_4/losses.log

Epoch 1: val_loss improved from inf to 0.75662, saving model to model_4/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 0.75662, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_4/KERAS_check_model_last.h5

Epoch 1: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 3ms/step - loss: 0.7540 - accuracy: 0.7458 - val_loss: 0.7566 - val_accuracy: 0.7457 - lr: 1.0000e-04
Epoch 2/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.7504 - accuracy: 0.7468
***callbacks***
saving losses to model_4/losses.log

Epoch 2: val_loss improved from 0.75662 to 0.75323, saving model to model_4/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 0.75662 to 0.75323, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_4/KERAS_check_model_last.h5

Epoch 2: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.7504 - accuracy: 0.7468 - val_loss: 0.7532 - val_accuracy: 0.7470 - lr: 1.0000e-04
Epoch 3/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7473 - accuracy: 0.7477
***callbacks***
saving losses to model_4/losses.log

Epoch 3: val_loss improved from 0.75323 to 0.75066, saving model to model_4/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 0.75323 to 0.75066, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_4/KERAS_check_model_last.h5

Epoch 3: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.7473 - accuracy: 0.7478 - val_loss: 0.7507 - val_accuracy: 0.7477 - lr: 1.0000e-04
Epoch 4/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7488
***callbacks***
saving losses to model_4/losses.log

Epoch 4: val_loss improved from 0.75066 to 0.74793, saving model to model_4/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 0.75066 to 0.74793, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_4/KERAS_check_model_last.h5

Epoch 4: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.7446 - accuracy: 0.7488 - val_loss: 0.7479 - val_accuracy: 0.7488 - lr: 1.0000e-04
Epoch 5/30
466/487 [===========================&gt;..] - ETA: 0s - loss: 1.2871 - accuracy: 0.5409
***callbacks***
saving losses to model_4/losses.log

Epoch 5: val_loss did not improve from 0.74793

Epoch 5: val_loss did not improve from 0.74793

Epoch 5: saving model to model_4/KERAS_check_model_last.h5

Epoch 5: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.2867 - accuracy: 0.5414 - val_loss: 1.2841 - val_accuracy: 0.5455 - lr: 1.0000e-04
Epoch 6/30
482/487 [============================&gt;.] - ETA: 0s - loss: 1.2397 - accuracy: 0.5549
***callbacks***
saving losses to model_4/losses.log

Epoch 6: val_loss did not improve from 0.74793

Epoch 6: val_loss did not improve from 0.74793

Epoch 6: saving model to model_4/KERAS_check_model_last.h5

Epoch 6: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.2394 - accuracy: 0.5548 - val_loss: 1.2036 - val_accuracy: 0.5566 - lr: 1.0000e-04
Epoch 7/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.1740 - accuracy: 0.5626
***callbacks***
saving losses to model_4/losses.log

Epoch 7: val_loss did not improve from 0.74793

Epoch 7: val_loss did not improve from 0.74793

Epoch 7: saving model to model_4/KERAS_check_model_last.h5

Epoch 7: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.1736 - accuracy: 0.5627 - val_loss: 1.1523 - val_accuracy: 0.5637 - lr: 1.0000e-04
Epoch 8/30
463/487 [===========================&gt;..] - ETA: 0s - loss: 1.1347 - accuracy: 0.5688
***callbacks***
saving losses to model_4/losses.log

Epoch 8: val_loss did not improve from 0.74793

Epoch 8: val_loss did not improve from 0.74793

Epoch 8: saving model to model_4/KERAS_check_model_last.h5

Epoch 8: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.1334 - accuracy: 0.5692 - val_loss: 1.1204 - val_accuracy: 0.5690 - lr: 1.0000e-04
Epoch 9/30
472/487 [============================&gt;.] - ETA: 0s - loss: 1.1062 - accuracy: 0.5742
***callbacks***
saving losses to model_4/losses.log

Epoch 9: val_loss did not improve from 0.74793

Epoch 9: val_loss did not improve from 0.74793

Epoch 9: saving model to model_4/KERAS_check_model_last.h5

Epoch 9: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.1057 - accuracy: 0.5744 - val_loss: 1.0965 - val_accuracy: 0.5737 - lr: 1.0000e-04
Epoch 10/30
462/487 [===========================&gt;..] - ETA: 0s - loss: 1.0842 - accuracy: 0.5787
***callbacks***
saving losses to model_4/losses.log

Epoch 10: val_loss did not improve from 0.74793

Epoch 10: val_loss did not improve from 0.74793

Epoch 10: saving model to model_4/KERAS_check_model_last.h5

Epoch 10: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_4/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0844 - accuracy: 0.5783 - val_loss: 1.0777 - val_accuracy: 0.5768 - lr: 1.0000e-04
Epoch 11/30
465/487 [===========================&gt;..] - ETA: 0s - loss: 1.0678 - accuracy: 0.5814
***callbacks***
saving losses to model_4/losses.log

Epoch 11: val_loss did not improve from 0.74793

Epoch 11: val_loss did not improve from 0.74793

Epoch 11: saving model to model_4/KERAS_check_model_last.h5

Epoch 11: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0674 - accuracy: 0.5813 - val_loss: 1.0623 - val_accuracy: 0.5795 - lr: 1.0000e-04
Epoch 12/30
475/487 [============================&gt;.] - ETA: 0s - loss: 1.0530 - accuracy: 0.5838
***callbacks***
saving losses to model_4/losses.log

Epoch 12: val_loss did not improve from 0.74793

Epoch 12: val_loss did not improve from 0.74793

Epoch 12: saving model to model_4/KERAS_check_model_last.h5

Epoch 12: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0531 - accuracy: 0.5838 - val_loss: 1.0490 - val_accuracy: 0.5823 - lr: 1.0000e-04
Epoch 13/30
482/487 [============================&gt;.] - ETA: 0s - loss: 1.0407 - accuracy: 0.5859
***callbacks***
saving losses to model_4/losses.log

Epoch 13: val_loss did not improve from 0.74793

Epoch 13: val_loss did not improve from 0.74793

Epoch 13: saving model to model_4/KERAS_check_model_last.h5

Epoch 13: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.0405 - accuracy: 0.5859 - val_loss: 1.0369 - val_accuracy: 0.5842 - lr: 1.0000e-04
Epoch 14/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0285 - accuracy: 0.5877
***callbacks***
saving losses to model_4/losses.log

Epoch 14: val_loss did not improve from 0.74793

Epoch 14: val_loss did not improve from 0.74793

Epoch 14: saving model to model_4/KERAS_check_model_last.h5

Epoch 14: saving model to model_4/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0285 - accuracy: 0.5877 - val_loss: 1.0255 - val_accuracy: 0.5863 - lr: 1.0000e-04
Epoch 15/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.0209 - accuracy: 0.5889
***callbacks***
saving losses to model_4/losses.log

Epoch 15: val_loss did not improve from 0.74793

Epoch 15: val_loss did not improve from 0.74793

Epoch 15: saving model to model_4/KERAS_check_model_last.h5

Epoch 15: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.0205 - accuracy: 0.5890 - val_loss: 1.0205 - val_accuracy: 0.5870 - lr: 5.0000e-05
Epoch 16/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0156 - accuracy: 0.5898
***callbacks***
saving losses to model_4/losses.log

Epoch 16: val_loss did not improve from 0.74793

Epoch 16: val_loss did not improve from 0.74793

Epoch 16: saving model to model_4/KERAS_check_model_last.h5

Epoch 16: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.0157 - accuracy: 0.5898 - val_loss: 1.0157 - val_accuracy: 0.5878 - lr: 5.0000e-05
Epoch 17/30
461/487 [===========================&gt;..] - ETA: 0s - loss: 1.0111 - accuracy: 0.5904
***callbacks***
saving losses to model_4/losses.log

Epoch 17: val_loss did not improve from 0.74793

Epoch 17: val_loss did not improve from 0.74793

Epoch 17: saving model to model_4/KERAS_check_model_last.h5

Epoch 17: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 1.0110 - accuracy: 0.5905 - val_loss: 1.0111 - val_accuracy: 0.5886 - lr: 5.0000e-05
Epoch 18/30
485/487 [============================&gt;.] - ETA: 0s - loss: 1.0063 - accuracy: 0.5912
***callbacks***
saving losses to model_4/losses.log

Epoch 18: val_loss did not improve from 0.74793

Epoch 18: val_loss did not improve from 0.74793

Epoch 18: saving model to model_4/KERAS_check_model_last.h5

Epoch 18: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.0064 - accuracy: 0.5911 - val_loss: 1.0067 - val_accuracy: 0.5892 - lr: 5.0000e-05
Epoch 19/30
471/487 [============================&gt;.] - ETA: 0s - loss: 1.0021 - accuracy: 0.5917
***callbacks***
saving losses to model_4/losses.log

Epoch 19: val_loss did not improve from 0.74793

Epoch 19: val_loss did not improve from 0.74793

Epoch 19: saving model to model_4/KERAS_check_model_last.h5

Epoch 19: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 1.0021 - accuracy: 0.5916 - val_loss: 1.0024 - val_accuracy: 0.5898 - lr: 5.0000e-05
Epoch 20/30
471/487 [============================&gt;.] - ETA: 0s - loss: 0.9980 - accuracy: 0.5922
***callbacks***
saving losses to model_4/losses.log

Epoch 20: val_loss did not improve from 0.74793

Epoch 20: val_loss did not improve from 0.74793

Epoch 20: saving model to model_4/KERAS_check_model_last.h5

Epoch 20: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_4/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9978 - accuracy: 0.5922 - val_loss: 0.9982 - val_accuracy: 0.5902 - lr: 5.0000e-05
Epoch 21/30
461/487 [===========================&gt;..] - ETA: 0s - loss: 0.9937 - accuracy: 0.5926
***callbacks***
saving losses to model_4/losses.log

Epoch 21: val_loss did not improve from 0.74793

Epoch 21: val_loss did not improve from 0.74793

Epoch 21: saving model to model_4/KERAS_check_model_last.h5

Epoch 21: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9936 - accuracy: 0.5928 - val_loss: 0.9940 - val_accuracy: 0.5905 - lr: 5.0000e-05
Epoch 22/30
465/487 [===========================&gt;..] - ETA: 0s - loss: 0.9899 - accuracy: 0.5929
***callbacks***
saving losses to model_4/losses.log

Epoch 22: val_loss did not improve from 0.74793

Epoch 22: val_loss did not improve from 0.74793

Epoch 22: saving model to model_4/KERAS_check_model_last.h5

Epoch 22: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9895 - accuracy: 0.5931 - val_loss: 0.9899 - val_accuracy: 0.5910 - lr: 5.0000e-05
Epoch 23/30
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.9860 - accuracy: 0.5934
***callbacks***
saving losses to model_4/losses.log

Epoch 23: val_loss did not improve from 0.74793

Epoch 23: val_loss did not improve from 0.74793

Epoch 23: saving model to model_4/KERAS_check_model_last.h5

Epoch 23: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9854 - accuracy: 0.5936 - val_loss: 0.9858 - val_accuracy: 0.5915 - lr: 5.0000e-05
Epoch 24/30
481/487 [============================&gt;.] - ETA: 0s - loss: 0.9813 - accuracy: 0.5941
***callbacks***
saving losses to model_4/losses.log

Epoch 24: val_loss did not improve from 0.74793

Epoch 24: val_loss did not improve from 0.74793

Epoch 24: saving model to model_4/KERAS_check_model_last.h5

Epoch 24: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9813 - accuracy: 0.5940 - val_loss: 0.9817 - val_accuracy: 0.5920 - lr: 5.0000e-05
Epoch 25/30
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.9774 - accuracy: 0.5942
***callbacks***
saving losses to model_4/losses.log

Epoch 25: val_loss did not improve from 0.74793

Epoch 25: val_loss did not improve from 0.74793

Epoch 25: saving model to model_4/KERAS_check_model_last.h5

Epoch 25: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.5944 - val_loss: 0.9775 - val_accuracy: 0.5923 - lr: 5.0000e-05
Epoch 26/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9737 - accuracy: 0.5946
***callbacks***
saving losses to model_4/losses.log

Epoch 26: val_loss did not improve from 0.74793

Epoch 26: val_loss did not improve from 0.74793

Epoch 26: saving model to model_4/KERAS_check_model_last.h5

Epoch 26: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9738 - accuracy: 0.5945 - val_loss: 0.9753 - val_accuracy: 0.5925 - lr: 2.5000e-05
Epoch 27/30
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.9718 - accuracy: 0.5944
***callbacks***
saving losses to model_4/losses.log

Epoch 27: val_loss did not improve from 0.74793

Epoch 27: val_loss did not improve from 0.74793

Epoch 27: saving model to model_4/KERAS_check_model_last.h5

Epoch 27: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9716 - accuracy: 0.5946 - val_loss: 0.9730 - val_accuracy: 0.5927 - lr: 2.5000e-05
Epoch 28/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9693 - accuracy: 0.5949
***callbacks***
saving losses to model_4/losses.log

Epoch 28: val_loss did not improve from 0.74793

Epoch 28: val_loss did not improve from 0.74793

Epoch 28: saving model to model_4/KERAS_check_model_last.h5

Epoch 28: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.9694 - accuracy: 0.5949 - val_loss: 0.9707 - val_accuracy: 0.5928 - lr: 2.5000e-05
Epoch 29/30
464/487 [===========================&gt;..] - ETA: 0s - loss: 0.9672 - accuracy: 0.5951
***callbacks***
saving losses to model_4/losses.log

Epoch 29: val_loss did not improve from 0.74793
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 29: val_loss did not improve from 0.74793

Epoch 29: saving model to model_4/KERAS_check_model_last.h5

Epoch 29: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 1s 2ms/step - loss: 0.9670 - accuracy: 0.5952 - val_loss: 0.9684 - val_accuracy: 0.5934 - lr: 2.5000e-05
Epoch 30/30
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.9646 - accuracy: 0.5958
***callbacks***
saving losses to model_4/losses.log

Epoch 30: val_loss did not improve from 0.74793

Epoch 30: val_loss did not improve from 0.74793

Epoch 30: saving model to model_4/KERAS_check_model_last.h5

Epoch 30: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_4/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 1s 3ms/step - loss: 0.9646 - accuracy: 0.5958 - val_loss: 0.9659 - val_accuracy: 0.5941 - lr: 2.5000e-05
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>Check sparsity<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.9501953125
</pre></div>
</div>
<img alt="_images/2.3_compression_30_1.png" src="_images/2.3_compression_30_1.png" />
</div>
</div>
</section>
<section id="id3">
<h2>Check performance<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p>How does this 95% sparse model compare against the other models?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">COLAB</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
    <span class="n">model_prune75</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_2/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
    <span class="n">model_prune75</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;iaifi-summer-school/book/model_2/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune75</span> <span class="o">=</span> <span class="n">model_prune75</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune95</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned:     </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (75%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (95%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune75</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune95</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span>
    <span class="n">lines</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (75%)&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (95%)&quot;</span><span class="p">],</span>
    <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span>
    <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5188/5188 [==============================] - 3s 622us/step
5188/5188 [==============================] - 4s 691us/step
5188/5188 [==============================] - 4s 709us/step
Accuracy unpruned:     0.7516506024096385
Accuracy pruned (75%): 0.7493855421686747
Accuracy pruned (95%): 0.5956506024096385
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x14dd49520&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_32_2.png" src="_images/2.3_compression_32_2.png" />
</div>
</div>
<p>Ok, clearly 95% is too sparse for this model (at least using this scheme). For some classes you see that the performance is not terrible, but overall the performance loss is quite substantial.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2.2_advanced_config.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Advanced Configuration</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="2.4_quantization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Quantization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Javier Duarte, Dylan Rankin, and Patrick McCormack<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>