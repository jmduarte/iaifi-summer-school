
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Compression (Pruning) &#8212; IAIFI Summer School Tutorials</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jduarte.physics.ucsd.edu/iaifi-summer-school/2.3_compression.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quantization" href="2.4_quantization.html" />
    <link rel="prev" title="Advanced Configuration" href="2.2_advanced_config.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IAIFI Summer School Tutorials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    IAIFI Summer School Tutorials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Representations, Networks, and Symmetries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1.1_tabular_data_efps.html">
   Tabular Data using Energy Flow Polynomials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.2_jet_images.html">
   Jet Images
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.3_deep_sets.html">
   Deep Sets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.4_gnn_in.html">
   Interaction Network GNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.5_gnn_lorentz.html">
   Lorentz-Equivariant GNN
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model Compression and Fast Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2.1_getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.2_advanced_config.html">
   Advanced Configuration
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Compression (Pruning)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2.4_quantization.html">
   Quantization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jmduarte/iaifi-summer-school/main?urlpath=tree/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jmduarte/iaifi-summer-school/blob/main/book/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jmduarte/iaifi-summer-school/issues/new?title=Issue%20on%20page%20%2F2.3_compression.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/2.3_compression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Compression (Pruning)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dataset-if-you-are-restarting-from-this-point">
   Load the dataset (if you are restarting from this point)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-a-new-model">
   Construct a new model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-sparse">
   Train sparse
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-the-model">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-sparsity">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#check-performance">
   Check performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reduced-size-model">
     Reduced size model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Train the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Check sparsity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Check performance
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>apt-get  -qq  install  -y  graphviz  <span class="o">&amp;&amp;</span>  pip  install  pydot
<span class="o">!</span>pip  install  -U  matplotlib
<span class="o">!</span>pip  install  git+https://github.com/fastmachinelearning/hls4ml.git@main#egg<span class="o">=</span>hls4ml<span class="o">[</span>profiling<span class="o">]</span>
<span class="o">!</span>pip  install  <span class="nv">qkeras</span><span class="o">==</span><span class="m">0</span>.9.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)
E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (3.5.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (4.34.4)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (21.3)
Requirement already satisfied: numpy&gt;=1.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.21.6)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (9.2.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib) (0.11.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib) (4.3.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: six&gt;=1.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting hls4ml[profiling]
  Cloning https://github.com/fastmachinelearning/hls4ml.git (to revision main) to /tmp/pip-install-e_8g88x_/hls4ml_ae1ccbb5ec4f44ddb0e95f1e3caba5a5
  Running command git clone --filter=blob:none --quiet https://github.com/fastmachinelearning/hls4ml.git /tmp/pip-install-e_8g88x_/hls4ml_ae1ccbb5ec4f44ddb0e95f1e3caba5a5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Resolved https://github.com/fastmachinelearning/hls4ml.git to commit 62046d799a4dbec150addc7f78fea5b579efeda1
  Running command git submodule update --init --recursive -q
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Preparing metadata (setup.py) ... ?25l-
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> done
?25hRequirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.21.6)
Requirement already satisfied: six in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.16.0)
Requirement already satisfied: pyyaml in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (6.0)
Requirement already satisfied: h5py in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.7.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: onnx&gt;=1.4.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.12.0)
Requirement already satisfied: calmjs.parse in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.0)
Requirement already satisfied: tabulate in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.8.10)
Requirement already satisfied: pydigitalwavetools==1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.1)
Requirement already satisfied: qkeras in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.9.0)
Requirement already satisfied: pandas in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (1.3.5)
Requirement already satisfied: seaborn in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (0.11.2)
Requirement already satisfied: matplotlib in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from hls4ml[profiling]) (3.5.2)
Requirement already satisfied: typing-extensions&gt;=3.6.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (4.3.0)
Requirement already satisfied: protobuf&lt;=3.20.1,&gt;=3.12.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from onnx&gt;=1.4.0-&gt;hls4ml[profiling]) (3.19.4)
Requirement already satisfied: ply&gt;=3.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (3.11)
Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from calmjs.parse-&gt;hls4ml[profiling]) (63.3.0)
Requirement already satisfied: packaging&gt;=20.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (21.3)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (4.34.4)
Requirement already satisfied: cycler&gt;=0.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (0.11.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (3.0.9)
Requirement already satisfied: pillow&gt;=6.2.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (9.2.0)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from matplotlib-&gt;hls4ml[profiling]) (2.8.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pytz&gt;=2017.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pandas-&gt;hls4ml[profiling]) (2022.1)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.7.3)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (4.64.0)
Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (2.6.3)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (0.7.3)
Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.1.3)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras-&gt;hls4ml[profiling]) (1.0.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.0.4)
Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (7.34.0)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.28.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.7)
Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras-&gt;hls4ml[profiling]) (1.6.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.1.3)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.0.30)
Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.12.0)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.5)
Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.8.0)
Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.1.1)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.18.1)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.3.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.3)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.26.11)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2022.6.15)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.6.1)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.37.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.9.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.6)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.4.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.2.1)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.47.0)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.2.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.8)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (5.2.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (1.3.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.7.0)
Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.2.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.8.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras-&gt;hls4ml[profiling]) (3.2.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: qkeras==0.9.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (0.9.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: networkx&gt;=2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (2.6.3)
Requirement already satisfied: keras-tuner&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.1.3)
Requirement already satisfied: tensorflow-model-optimization&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (0.7.3)
Requirement already satisfied: scikit-learn&gt;=0.23.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0.2)
Requirement already satisfied: numpy&gt;=1.16.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.21.6)
Requirement already satisfied: setuptools&gt;=41.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (63.3.0)
Requirement already satisfied: pyparser in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.0)
Requirement already satisfied: scipy&gt;=1.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (1.7.3)
Requirement already satisfied: tqdm&gt;=4.48.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from qkeras==0.9.0) (4.64.0)
Requirement already satisfied: packaging in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (21.3)
Requirement already satisfied: requests in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.28.1)
Requirement already satisfied: ipython in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (7.34.0)
Requirement already satisfied: tensorboard in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
Requirement already satisfied: kt-legacy in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.0.4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: joblib&gt;=0.11 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from scikit-learn&gt;=0.23.1-&gt;qkeras==0.9.0) (3.1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: six~=1.10 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (1.16.0)
Requirement already satisfied: dm-tree~=0.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorflow-model-optimization&gt;=0.2.1-&gt;qkeras==0.9.0) (0.1.7)
Requirement already satisfied: parse==1.6.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyparser-&gt;qkeras==0.9.0) (1.6.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pexpect&gt;4.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.8.0)
Requirement already satisfied: pickleshare in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.5)
Requirement already satisfied: jedi&gt;=0.16 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.18.1)
Requirement already satisfied: decorator in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.1.1)
Requirement already satisfied: traitlets&gt;=4.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.3.0)
Requirement already satisfied: matplotlib-inline in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.1.3)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.30)
Requirement already satisfied: pygments in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.12.0)
Requirement already satisfied: backcall in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from packaging-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.0.9)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2022.6.15)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.3)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.26.11)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: markdown&gt;=2.6.8 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.4.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.2.1)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.8.1)
Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.47.0)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.2.0)
Requirement already satisfied: wheel&gt;=0.26 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.37.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.6)
Requirement already satisfied: protobuf&lt;3.20,&gt;=3.9.2 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.19.4)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.9.1)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.6.1)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.9)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (5.2.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (1.3.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.8.3)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.12.0)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.7.0)
Requirement already satisfied: wcwidth in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.2.5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (2.1.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: typing-extensions&gt;=3.6.4 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (4.3.0)
Requirement already satisfied: zipp&gt;=0.5 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.8.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;keras-tuner&gt;=1.0.1-&gt;qkeras==0.9.0) (3.2.0)
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="compression-pruning">
<h1>Compression (Pruning)<a class="headerlink" href="#compression-pruning" title="Permalink to this headline">#</a></h1>
<section id="load-the-dataset-if-you-are-restarting-from-this-point">
<h2>Load the dataset (if you are restarting from this point)<a class="headerlink" href="#load-the-dataset-if-you-are-restarting-from-this-point" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># import os</span>
<span class="c1"># os.environ[&#39;PATH&#39;] = &#39;/opt/Xilinx/Vivado/2019.2/bin:&#39; + os.environ[&#39;PATH&#39;]</span>
<span class="c1"># for this tutorial we wont be actually running Vivado, so I have commented these lines out</span>
<span class="c1">#     but if you want to look into actually running on an FPGA then simply uncomment these lines</span>

<span class="n">X_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_train_val.npy&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;X_test.npy&quot;</span><span class="p">)</span>
<span class="n">y_train_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_train_val.npy&quot;</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;y_test.npy&quot;</span><span class="p">)</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;classes.npy&quot;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 00:37:22.940182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 00:37:22.940223: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div>
</div>
</div>
</div>
</section>
<section id="construct-a-new-model">
<h2>Construct a new model<a class="headerlink" href="#construct-a-new-model" title="Permalink to this headline">#</a></h2>
<p>Well now use the same architecture as we originally used: 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.regularizers</span> <span class="kn">import</span> <span class="n">l1</span>
<span class="kn">from</span> <span class="nn">callbacks</span> <span class="kn">import</span> <span class="n">all_callbacks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">64</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-08-02 00:37:26.061610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.7.13/x64/lib
2022-08-02 00:37:26.061658: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-08-02 00:37:26.061680: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az28-205): /proc/driver/nvidia/version does not exist
2022-08-02 00:37:26.061964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-sparse">
<h2>Train sparse<a class="headerlink" href="#train-sparse" title="Permalink to this headline">#</a></h2>
<p>This time well use the Tensorflow model optimization sparsity to train a sparse model (forcing many weights to 0). In this instance, the target sparsity is 75%</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.75</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model">
<h2>Train the model<a class="headerlink" href="#train-the-model" title="Permalink to this headline">#</a></h2>
<p>Well use the same settings as the previous model: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory model_3
The model isnt very complex, so this should just take a few minutes even on the CPU.
If youve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_3&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_3/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 22:14 - loss: 1.6388 - accuracy: 0.3027
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0085s). Check your callbacks.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 17/487 [&gt;.............................] - ETA: 1s - loss: 1.6360 - accuracy: 0.2774   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 37/487 [=&gt;............................] - ETA: 1s - loss: 1.6164 - accuracy: 0.2992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 1.5991 - accuracy: 0.3224
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 74/487 [===&gt;..........................] - ETA: 1s - loss: 1.5847 - accuracy: 0.3398
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 92/487 [====&gt;.........................] - ETA: 1s - loss: 1.5714 - accuracy: 0.3534
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
110/487 [=====&gt;........................] - ETA: 1s - loss: 1.5582 - accuracy: 0.3641
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
128/487 [======&gt;.......................] - ETA: 1s - loss: 1.5457 - accuracy: 0.3736
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
146/487 [=======&gt;......................] - ETA: 0s - loss: 1.5325 - accuracy: 0.3851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/487 [=========&gt;....................] - ETA: 0s - loss: 1.5193 - accuracy: 0.3960
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/487 [==========&gt;...................] - ETA: 0s - loss: 1.5070 - accuracy: 0.4048
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
201/487 [===========&gt;..................] - ETA: 0s - loss: 1.4931 - accuracy: 0.4137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
220/487 [============&gt;.................] - ETA: 0s - loss: 1.4798 - accuracy: 0.4208
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
238/487 [=============&gt;................] - ETA: 0s - loss: 1.4674 - accuracy: 0.4281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/487 [==============&gt;...............] - ETA: 0s - loss: 1.4561 - accuracy: 0.4347
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/487 [===============&gt;..............] - ETA: 0s - loss: 1.4442 - accuracy: 0.4419
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
293/487 [=================&gt;............] - ETA: 0s - loss: 1.4322 - accuracy: 0.4498
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 1.4202 - accuracy: 0.4586
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
332/487 [===================&gt;..........] - ETA: 0s - loss: 1.4079 - accuracy: 0.4672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
352/487 [====================&gt;.........] - ETA: 0s - loss: 1.3962 - accuracy: 0.4751
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 1.3849 - accuracy: 0.4824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/487 [=======================&gt;......] - ETA: 0s - loss: 1.3747 - accuracy: 0.4888
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
411/487 [========================&gt;.....] - ETA: 0s - loss: 1.3643 - accuracy: 0.4953
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
430/487 [=========================&gt;....] - ETA: 0s - loss: 1.3546 - accuracy: 0.5011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
448/487 [==========================&gt;...] - ETA: 0s - loss: 1.3460 - accuracy: 0.5062
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
466/487 [===========================&gt;..] - ETA: 0s - loss: 1.3379 - accuracy: 0.5110
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
484/487 [============================&gt;.] - ETA: 0s - loss: 1.3301 - accuracy: 0.5155
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: val_loss improved from inf to 1.12515, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 5s 4ms/step - loss: 1.3290 - accuracy: 0.5161 - val_loss: 1.1252 - val_accuracy: 0.6363 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 1s - loss: 1.1001 - accuracy: 0.6299
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 1.1179 - accuracy: 0.6377
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 1.1186 - accuracy: 0.6368
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 1.1157 - accuracy: 0.6384
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 1.1090 - accuracy: 0.6411
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 1.1067 - accuracy: 0.6424
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
116/487 [======&gt;.......................] - ETA: 0s - loss: 1.1036 - accuracy: 0.6438
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
135/487 [=======&gt;......................] - ETA: 0s - loss: 1.1001 - accuracy: 0.6451
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
154/487 [========&gt;.....................] - ETA: 0s - loss: 1.0965 - accuracy: 0.6474
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
173/487 [=========&gt;....................] - ETA: 0s - loss: 1.0935 - accuracy: 0.6488
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
192/487 [==========&gt;...................] - ETA: 0s - loss: 1.0912 - accuracy: 0.6496
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
210/487 [===========&gt;..................] - ETA: 0s - loss: 1.0883 - accuracy: 0.6509
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
229/487 [=============&gt;................] - ETA: 0s - loss: 1.0850 - accuracy: 0.6528
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
248/487 [==============&gt;...............] - ETA: 0s - loss: 1.0830 - accuracy: 0.6542
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
267/487 [===============&gt;..............] - ETA: 0s - loss: 1.0808 - accuracy: 0.6551
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
285/487 [================&gt;.............] - ETA: 0s - loss: 1.0783 - accuracy: 0.6564
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
303/487 [=================&gt;............] - ETA: 0s - loss: 1.0756 - accuracy: 0.6577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
321/487 [==================&gt;...........] - ETA: 0s - loss: 1.0742 - accuracy: 0.6584
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
339/487 [===================&gt;..........] - ETA: 0s - loss: 1.0720 - accuracy: 0.6594
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
357/487 [====================&gt;.........] - ETA: 0s - loss: 1.0695 - accuracy: 0.6604
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/487 [======================&gt;.......] - ETA: 0s - loss: 1.0671 - accuracy: 0.6616
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
395/487 [=======================&gt;......] - ETA: 0s - loss: 1.0646 - accuracy: 0.6627
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
414/487 [========================&gt;.....] - ETA: 0s - loss: 1.0626 - accuracy: 0.6635
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
433/487 [=========================&gt;....] - ETA: 0s - loss: 1.0604 - accuracy: 0.6644
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
452/487 [==========================&gt;...] - ETA: 0s - loss: 1.0588 - accuracy: 0.6651
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
471/487 [============================&gt;.] - ETA: 0s - loss: 1.0569 - accuracy: 0.6660
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: val_loss improved from 1.12515 to 1.00705, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0550 - accuracy: 0.6668 - val_loss: 1.0071 - val_accuracy: 0.6900 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 3s - loss: 0.9859 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 1.0062 - accuracy: 0.6896
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.9995 - accuracy: 0.6892
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 1.0007 - accuracy: 0.6903
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 0.9995 - accuracy: 0.6897
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 94/487 [====&gt;.........................] - ETA: 1s - loss: 0.9969 - accuracy: 0.6908
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
112/487 [=====&gt;........................] - ETA: 1s - loss: 0.9973 - accuracy: 0.6904
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
131/487 [=======&gt;......................] - ETA: 0s - loss: 0.9967 - accuracy: 0.6908
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
149/487 [========&gt;.....................] - ETA: 0s - loss: 0.9950 - accuracy: 0.6917
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/487 [=========&gt;....................] - ETA: 0s - loss: 0.9932 - accuracy: 0.6928
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
187/487 [==========&gt;...................] - ETA: 0s - loss: 0.9909 - accuracy: 0.6939
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
206/487 [===========&gt;..................] - ETA: 0s - loss: 0.9904 - accuracy: 0.6940
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.9895 - accuracy: 0.6944
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
242/487 [=============&gt;................] - ETA: 0s - loss: 0.9876 - accuracy: 0.6951
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
261/487 [===============&gt;..............] - ETA: 0s - loss: 0.9861 - accuracy: 0.6958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
280/487 [================&gt;.............] - ETA: 0s - loss: 0.9846 - accuracy: 0.6962
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
299/487 [=================&gt;............] - ETA: 0s - loss: 0.9827 - accuracy: 0.6968
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
318/487 [==================&gt;...........] - ETA: 0s - loss: 0.9819 - accuracy: 0.6970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/487 [===================&gt;..........] - ETA: 0s - loss: 0.9811 - accuracy: 0.6972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
355/487 [====================&gt;.........] - ETA: 0s - loss: 0.9800 - accuracy: 0.6977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
373/487 [=====================&gt;........] - ETA: 0s - loss: 0.9787 - accuracy: 0.6981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/487 [=======================&gt;......] - ETA: 0s - loss: 0.9779 - accuracy: 0.6983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
409/487 [========================&gt;.....] - ETA: 0s - loss: 0.9766 - accuracy: 0.6988
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
428/487 [=========================&gt;....] - ETA: 0s - loss: 0.9751 - accuracy: 0.6993
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
448/487 [==========================&gt;...] - ETA: 0s - loss: 0.9735 - accuracy: 0.6998
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
467/487 [===========================&gt;..] - ETA: 0s - loss: 0.9724 - accuracy: 0.7001
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.9712 - accuracy: 0.7004
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: val_loss improved from 1.00705 to 0.94498, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.9712 - accuracy: 0.7004 - val_loss: 0.9450 - val_accuracy: 0.7098 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9507 - accuracy: 0.7021
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 19/487 [&gt;.............................] - ETA: 1s - loss: 0.9421 - accuracy: 0.7089
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 37/487 [=&gt;............................] - ETA: 1s - loss: 0.9391 - accuracy: 0.7099
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 53/487 [==&gt;...........................] - ETA: 1s - loss: 0.9418 - accuracy: 0.7102
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 72/487 [===&gt;..........................] - ETA: 1s - loss: 0.9409 - accuracy: 0.7108
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 91/487 [====&gt;.........................] - ETA: 1s - loss: 0.9406 - accuracy: 0.7106
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
110/487 [=====&gt;........................] - ETA: 1s - loss: 0.9394 - accuracy: 0.7103
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
129/487 [======&gt;.......................] - ETA: 0s - loss: 0.9358 - accuracy: 0.7114
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
148/487 [========&gt;.....................] - ETA: 0s - loss: 0.9349 - accuracy: 0.7113
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
167/487 [=========&gt;....................] - ETA: 0s - loss: 0.9331 - accuracy: 0.7115
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
186/487 [==========&gt;...................] - ETA: 0s - loss: 0.9327 - accuracy: 0.7116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
205/487 [===========&gt;..................] - ETA: 0s - loss: 0.9314 - accuracy: 0.7116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.9297 - accuracy: 0.7120
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
242/487 [=============&gt;................] - ETA: 0s - loss: 0.9289 - accuracy: 0.7121
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
261/487 [===============&gt;..............] - ETA: 0s - loss: 0.9281 - accuracy: 0.7122
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
280/487 [================&gt;.............] - ETA: 0s - loss: 0.9276 - accuracy: 0.7122
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
299/487 [=================&gt;............] - ETA: 0s - loss: 0.9265 - accuracy: 0.7127
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
318/487 [==================&gt;...........] - ETA: 0s - loss: 0.9257 - accuracy: 0.7128
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
337/487 [===================&gt;..........] - ETA: 0s - loss: 0.9243 - accuracy: 0.7132
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
356/487 [====================&gt;.........] - ETA: 0s - loss: 0.9234 - accuracy: 0.7134
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
375/487 [======================&gt;.......] - ETA: 0s - loss: 0.9225 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
393/487 [=======================&gt;......] - ETA: 0s - loss: 0.9220 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
411/487 [========================&gt;.....] - ETA: 0s - loss: 0.9216 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
430/487 [=========================&gt;....] - ETA: 0s - loss: 0.9207 - accuracy: 0.7138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
449/487 [==========================&gt;...] - ETA: 0s - loss: 0.9197 - accuracy: 0.7140
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
468/487 [===========================&gt;..] - ETA: 0s - loss: 0.9186 - accuracy: 0.7144
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
486/487 [============================&gt;.] - ETA: 0s - loss: 0.9183 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: val_loss improved from 0.94498 to 0.90045, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9183 - accuracy: 0.7143 - val_loss: 0.9005 - val_accuracy: 0.7187 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8668 - accuracy: 0.7334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8882 - accuracy: 0.7204
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.8906 - accuracy: 0.7192
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 56/487 [==&gt;...........................] - ETA: 1s - loss: 0.9393 - accuracy: 0.6904
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 75/487 [===&gt;..........................] - ETA: 1s - loss: 1.0509 - accuracy: 0.6278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 93/487 [====&gt;.........................] - ETA: 1s - loss: 1.0974 - accuracy: 0.6038
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
111/487 [=====&gt;........................] - ETA: 1s - loss: 1.1174 - accuracy: 0.5983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
128/487 [======&gt;.......................] - ETA: 1s - loss: 1.1267 - accuracy: 0.5994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
146/487 [=======&gt;......................] - ETA: 0s - loss: 1.1302 - accuracy: 0.6032
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
164/487 [=========&gt;....................] - ETA: 0s - loss: 1.1304 - accuracy: 0.6078
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
182/487 [==========&gt;...................] - ETA: 0s - loss: 1.1292 - accuracy: 0.6114
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
201/487 [===========&gt;..................] - ETA: 0s - loss: 1.1259 - accuracy: 0.6152
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
221/487 [============&gt;.................] - ETA: 0s - loss: 1.1219 - accuracy: 0.6187
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/487 [=============&gt;................] - ETA: 0s - loss: 1.1183 - accuracy: 0.6211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
261/487 [===============&gt;..............] - ETA: 0s - loss: 1.1148 - accuracy: 0.6236
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
281/487 [================&gt;.............] - ETA: 0s - loss: 1.1104 - accuracy: 0.6262
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
300/487 [=================&gt;............] - ETA: 0s - loss: 1.1073 - accuracy: 0.6276
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
319/487 [==================&gt;...........] - ETA: 0s - loss: 1.1039 - accuracy: 0.6293
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
338/487 [===================&gt;..........] - ETA: 0s - loss: 1.1007 - accuracy: 0.6308
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
357/487 [====================&gt;.........] - ETA: 0s - loss: 1.0969 - accuracy: 0.6325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
376/487 [======================&gt;.......] - ETA: 0s - loss: 1.0936 - accuracy: 0.6339
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
394/487 [=======================&gt;......] - ETA: 0s - loss: 1.0905 - accuracy: 0.6352
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/487 [========================&gt;.....] - ETA: 0s - loss: 1.0871 - accuracy: 0.6365
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
432/487 [=========================&gt;....] - ETA: 0s - loss: 1.0837 - accuracy: 0.6379
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
451/487 [==========================&gt;...] - ETA: 0s - loss: 1.0805 - accuracy: 0.6392
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
470/487 [===========================&gt;..] - ETA: 0s - loss: 1.0774 - accuracy: 0.6405
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
487/487 [==============================] - ETA: 0s - loss: 1.0749 - accuracy: 0.6415
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 1.0749 - accuracy: 0.6415 - val_loss: 0.9990 - val_accuracy: 0.6722 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9407 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.9827 - accuracy: 0.6821
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.9886 - accuracy: 0.6775
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.9881 - accuracy: 0.6772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 0.9888 - accuracy: 0.6770
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 95/487 [====&gt;.........................] - ETA: 1s - loss: 0.9881 - accuracy: 0.6768
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
114/487 [======&gt;.......................] - ETA: 1s - loss: 0.9864 - accuracy: 0.6775
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
133/487 [=======&gt;......................] - ETA: 0s - loss: 0.9847 - accuracy: 0.6778
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
152/487 [========&gt;.....................] - ETA: 0s - loss: 0.9829 - accuracy: 0.6782
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
171/487 [=========&gt;....................] - ETA: 0s - loss: 0.9807 - accuracy: 0.6790
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
190/487 [==========&gt;...................] - ETA: 0s - loss: 0.9798 - accuracy: 0.6792
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
209/487 [===========&gt;..................] - ETA: 0s - loss: 0.9790 - accuracy: 0.6795
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
229/487 [=============&gt;................] - ETA: 0s - loss: 0.9780 - accuracy: 0.6798
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
249/487 [==============&gt;...............] - ETA: 0s - loss: 0.9765 - accuracy: 0.6806
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
269/487 [===============&gt;..............] - ETA: 0s - loss: 0.9742 - accuracy: 0.6818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/487 [================&gt;.............] - ETA: 0s - loss: 0.9730 - accuracy: 0.6823
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
309/487 [==================&gt;...........] - ETA: 0s - loss: 0.9722 - accuracy: 0.6827
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/487 [===================&gt;..........] - ETA: 0s - loss: 0.9715 - accuracy: 0.6827
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
347/487 [====================&gt;.........] - ETA: 0s - loss: 0.9703 - accuracy: 0.6832
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
366/487 [=====================&gt;........] - ETA: 0s - loss: 0.9691 - accuracy: 0.6837
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/487 [======================&gt;.......] - ETA: 0s - loss: 0.9678 - accuracy: 0.6842
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
403/487 [=======================&gt;......] - ETA: 0s - loss: 0.9664 - accuracy: 0.6846
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
420/487 [========================&gt;.....] - ETA: 0s - loss: 0.9655 - accuracy: 0.6848
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
437/487 [=========================&gt;....] - ETA: 0s - loss: 0.9643 - accuracy: 0.6852
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
455/487 [===========================&gt;..] - ETA: 0s - loss: 0.9631 - accuracy: 0.6856
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
473/487 [============================&gt;.] - ETA: 0s - loss: 0.9621 - accuracy: 0.6861
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.9615 - accuracy: 0.6864 - val_loss: 0.9364 - val_accuracy: 0.6952 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9119 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 19/487 [&gt;.............................] - ETA: 1s - loss: 0.9254 - accuracy: 0.7005
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.9376 - accuracy: 0.6948
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.9364 - accuracy: 0.6950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 76/487 [===&gt;..........................] - ETA: 1s - loss: 0.9331 - accuracy: 0.6967
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 92/487 [====&gt;.........................] - ETA: 1s - loss: 0.9328 - accuracy: 0.6958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
109/487 [=====&gt;........................] - ETA: 1s - loss: 0.9308 - accuracy: 0.6964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/487 [======&gt;.......................] - ETA: 1s - loss: 0.9292 - accuracy: 0.6973
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
145/487 [=======&gt;......................] - ETA: 0s - loss: 0.9297 - accuracy: 0.6972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
163/487 [=========&gt;....................] - ETA: 0s - loss: 0.9293 - accuracy: 0.6972
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
178/487 [=========&gt;....................] - ETA: 0s - loss: 0.9293 - accuracy: 0.6970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
197/487 [===========&gt;..................] - ETA: 0s - loss: 0.9276 - accuracy: 0.6978
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
216/487 [============&gt;.................] - ETA: 0s - loss: 0.9265 - accuracy: 0.6984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
233/487 [=============&gt;................] - ETA: 0s - loss: 0.9257 - accuracy: 0.6985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
252/487 [==============&gt;...............] - ETA: 0s - loss: 0.9243 - accuracy: 0.6989
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
270/487 [===============&gt;..............] - ETA: 0s - loss: 0.9237 - accuracy: 0.6992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
287/487 [================&gt;.............] - ETA: 0s - loss: 0.9230 - accuracy: 0.6995
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
305/487 [=================&gt;............] - ETA: 0s - loss: 0.9217 - accuracy: 0.7000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
322/487 [==================&gt;...........] - ETA: 0s - loss: 0.9210 - accuracy: 0.7003
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
341/487 [====================&gt;.........] - ETA: 0s - loss: 0.9202 - accuracy: 0.7004
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
359/487 [=====================&gt;........] - ETA: 0s - loss: 0.9188 - accuracy: 0.7010
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
377/487 [======================&gt;.......] - ETA: 0s - loss: 0.9183 - accuracy: 0.7010
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
395/487 [=======================&gt;......] - ETA: 0s - loss: 0.9178 - accuracy: 0.7011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
414/487 [========================&gt;.....] - ETA: 0s - loss: 0.9174 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
432/487 [=========================&gt;....] - ETA: 0s - loss: 0.9170 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
450/487 [==========================&gt;...] - ETA: 0s - loss: 0.9168 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
469/487 [===========================&gt;..] - ETA: 0s - loss: 0.9163 - accuracy: 0.7012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
487/487 [==============================] - ETA: 0s - loss: 0.9157 - accuracy: 0.7015
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: val_loss did not improve from 0.90045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.9157 - accuracy: 0.7015 - val_loss: 0.9021 - val_accuracy: 0.7052 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.9369 - accuracy: 0.6934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8928 - accuracy: 0.7073
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8947 - accuracy: 0.7079
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8961 - accuracy: 0.7060
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 0.8967 - accuracy: 0.7064
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 0.8964 - accuracy: 0.7067
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
116/487 [======&gt;.......................] - ETA: 0s - loss: 0.8976 - accuracy: 0.7064
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
133/487 [=======&gt;......................] - ETA: 0s - loss: 0.8981 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
151/487 [========&gt;.....................] - ETA: 0s - loss: 0.8970 - accuracy: 0.7066
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
169/487 [=========&gt;....................] - ETA: 0s - loss: 0.8962 - accuracy: 0.7067
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
187/487 [==========&gt;...................] - ETA: 0s - loss: 0.8956 - accuracy: 0.7071
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
205/487 [===========&gt;..................] - ETA: 0s - loss: 0.8950 - accuracy: 0.7076
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 0.8952 - accuracy: 0.7074
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
240/487 [=============&gt;................] - ETA: 0s - loss: 0.8949 - accuracy: 0.7076
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
255/487 [==============&gt;...............] - ETA: 0s - loss: 0.8941 - accuracy: 0.7081
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/487 [===============&gt;..............] - ETA: 0s - loss: 0.8933 - accuracy: 0.7082
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
291/487 [================&gt;.............] - ETA: 0s - loss: 0.8921 - accuracy: 0.7087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
310/487 [==================&gt;...........] - ETA: 0s - loss: 0.8918 - accuracy: 0.7087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.8916 - accuracy: 0.7086
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 0.8913 - accuracy: 0.7088
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 0.8908 - accuracy: 0.7089
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
386/487 [======================&gt;.......] - ETA: 0s - loss: 0.8901 - accuracy: 0.7091
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
405/487 [=======================&gt;......] - ETA: 0s - loss: 0.8894 - accuracy: 0.7091
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
423/487 [=========================&gt;....] - ETA: 0s - loss: 0.8890 - accuracy: 0.7092
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
441/487 [==========================&gt;...] - ETA: 0s - loss: 0.8884 - accuracy: 0.7093
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
460/487 [===========================&gt;..] - ETA: 0s - loss: 0.8879 - accuracy: 0.7096
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
479/487 [============================&gt;.] - ETA: 0s - loss: 0.8868 - accuracy: 0.7100
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: val_loss improved from 0.90045 to 0.87748, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8865 - accuracy: 0.7102 - val_loss: 0.8775 - val_accuracy: 0.7122 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8805 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8701 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 38/487 [=&gt;............................] - ETA: 1s - loss: 0.8712 - accuracy: 0.7154
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 55/487 [==&gt;...........................] - ETA: 1s - loss: 0.8702 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 73/487 [===&gt;..........................] - ETA: 1s - loss: 0.8695 - accuracy: 0.7147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 91/487 [====&gt;.........................] - ETA: 1s - loss: 0.8712 - accuracy: 0.7138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
110/487 [=====&gt;........................] - ETA: 1s - loss: 0.8704 - accuracy: 0.7145
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
128/487 [======&gt;.......................] - ETA: 1s - loss: 0.8708 - accuracy: 0.7141
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
147/487 [========&gt;.....................] - ETA: 0s - loss: 0.8716 - accuracy: 0.7133
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
165/487 [=========&gt;....................] - ETA: 0s - loss: 0.8712 - accuracy: 0.7137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
183/487 [==========&gt;...................] - ETA: 0s - loss: 0.8702 - accuracy: 0.7142
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
201/487 [===========&gt;..................] - ETA: 0s - loss: 0.8703 - accuracy: 0.7140
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
219/487 [============&gt;.................] - ETA: 0s - loss: 0.8694 - accuracy: 0.7143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
237/487 [=============&gt;................] - ETA: 0s - loss: 0.8693 - accuracy: 0.7144
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
254/487 [==============&gt;...............] - ETA: 0s - loss: 0.8690 - accuracy: 0.7146
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
272/487 [===============&gt;..............] - ETA: 0s - loss: 0.8684 - accuracy: 0.7149
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
290/487 [================&gt;.............] - ETA: 0s - loss: 0.8679 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 0.8672 - accuracy: 0.7153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
326/487 [===================&gt;..........] - ETA: 0s - loss: 0.8675 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
345/487 [====================&gt;.........] - ETA: 0s - loss: 0.8669 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
364/487 [=====================&gt;........] - ETA: 0s - loss: 0.8672 - accuracy: 0.7150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
383/487 [======================&gt;.......] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
402/487 [=======================&gt;......] - ETA: 0s - loss: 0.8669 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
421/487 [========================&gt;.....] - ETA: 0s - loss: 0.8668 - accuracy: 0.7151
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
440/487 [==========================&gt;...] - ETA: 0s - loss: 0.8667 - accuracy: 0.7152
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/487 [===========================&gt;..] - ETA: 0s - loss: 0.8662 - accuracy: 0.7153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
479/487 [============================&gt;.] - ETA: 0s - loss: 0.8659 - accuracy: 0.7155
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: val_loss improved from 0.87748 to 0.86037, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8655 - accuracy: 0.7156 - val_loss: 0.8604 - val_accuracy: 0.7173 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8281 - accuracy: 0.7246
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 18/487 [&gt;.............................] - ETA: 1s - loss: 0.8627 - accuracy: 0.7175
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 35/487 [=&gt;............................] - ETA: 1s - loss: 0.8622 - accuracy: 0.7166
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 52/487 [==&gt;...........................] - ETA: 1s - loss: 0.8612 - accuracy: 0.7165
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 68/487 [===&gt;..........................] - ETA: 1s - loss: 0.8581 - accuracy: 0.7172
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 84/487 [====&gt;.........................] - ETA: 1s - loss: 0.8576 - accuracy: 0.7169
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
102/487 [=====&gt;........................] - ETA: 1s - loss: 0.8544 - accuracy: 0.7182
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
119/487 [======&gt;.......................] - ETA: 1s - loss: 0.8545 - accuracy: 0.7181
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
136/487 [=======&gt;......................] - ETA: 1s - loss: 0.8523 - accuracy: 0.7191
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
152/487 [========&gt;.....................] - ETA: 1s - loss: 0.8510 - accuracy: 0.7200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
167/487 [=========&gt;....................] - ETA: 0s - loss: 0.8517 - accuracy: 0.7195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
186/487 [==========&gt;...................] - ETA: 0s - loss: 0.8531 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
205/487 [===========&gt;..................] - ETA: 0s - loss: 0.8529 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
223/487 [============&gt;.................] - ETA: 0s - loss: 0.8530 - accuracy: 0.7186
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/487 [=============&gt;................] - ETA: 0s - loss: 0.8523 - accuracy: 0.7188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
259/487 [==============&gt;...............] - ETA: 0s - loss: 0.8521 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
275/487 [===============&gt;..............] - ETA: 0s - loss: 0.8522 - accuracy: 0.7190
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
293/487 [=================&gt;............] - ETA: 0s - loss: 0.8514 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
311/487 [==================&gt;...........] - ETA: 0s - loss: 0.8511 - accuracy: 0.7194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.8513 - accuracy: 0.7193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 0.8508 - accuracy: 0.7197
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 0.8504 - accuracy: 0.7198
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/487 [======================&gt;.......] - ETA: 0s - loss: 0.8501 - accuracy: 0.7200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
403/487 [=======================&gt;......] - ETA: 0s - loss: 0.8501 - accuracy: 0.7199
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
422/487 [========================&gt;.....] - ETA: 0s - loss: 0.8505 - accuracy: 0.7196
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
442/487 [==========================&gt;...] - ETA: 0s - loss: 0.8505 - accuracy: 0.7195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
461/487 [===========================&gt;..] - ETA: 0s - loss: 0.8503 - accuracy: 0.7195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
481/487 [============================&gt;.] - ETA: 0s - loss: 0.8508 - accuracy: 0.7192
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: val_loss improved from 0.86037 to 0.84773, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10: saving model to model_3/KERAS_check_model_epoch10.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8506 - accuracy: 0.7192 - val_loss: 0.8477 - val_accuracy: 0.7208 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8714 - accuracy: 0.7158
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 17/487 [&gt;.............................] - ETA: 1s - loss: 0.8324 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 36/487 [=&gt;............................] - ETA: 1s - loss: 0.8425 - accuracy: 0.7227
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 55/487 [==&gt;...........................] - ETA: 1s - loss: 0.8418 - accuracy: 0.7224
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 73/487 [===&gt;..........................] - ETA: 1s - loss: 0.8400 - accuracy: 0.7235
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 91/487 [====&gt;.........................] - ETA: 1s - loss: 0.8438 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
109/487 [=====&gt;........................] - ETA: 1s - loss: 0.8426 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
127/487 [======&gt;.......................] - ETA: 1s - loss: 0.8419 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
147/487 [========&gt;.....................] - ETA: 0s - loss: 0.8422 - accuracy: 0.7212
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
166/487 [=========&gt;....................] - ETA: 0s - loss: 0.8425 - accuracy: 0.7212
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
185/487 [==========&gt;...................] - ETA: 0s - loss: 0.8418 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8415 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
221/487 [============&gt;.................] - ETA: 0s - loss: 0.8417 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
239/487 [=============&gt;................] - ETA: 0s - loss: 0.8419 - accuracy: 0.7211
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
256/487 [==============&gt;...............] - ETA: 0s - loss: 0.8415 - accuracy: 0.7212
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
274/487 [===============&gt;..............] - ETA: 0s - loss: 0.8413 - accuracy: 0.7213
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.8411 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 0.8414 - accuracy: 0.7214
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
328/487 [===================&gt;..........] - ETA: 0s - loss: 0.8409 - accuracy: 0.7216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
346/487 [====================&gt;.........] - ETA: 0s - loss: 0.8404 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
365/487 [=====================&gt;........] - ETA: 0s - loss: 0.8403 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
383/487 [======================&gt;.......] - ETA: 0s - loss: 0.8401 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
401/487 [=======================&gt;......] - ETA: 0s - loss: 0.8404 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
419/487 [========================&gt;.....] - ETA: 0s - loss: 0.8404 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
437/487 [=========================&gt;....] - ETA: 0s - loss: 0.8403 - accuracy: 0.7215
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
455/487 [===========================&gt;..] - ETA: 0s - loss: 0.8398 - accuracy: 0.7217
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
474/487 [============================&gt;.] - ETA: 0s - loss: 0.8395 - accuracy: 0.7218
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: val_loss improved from 0.84773 to 0.83780, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8392 - accuracy: 0.7219 - val_loss: 0.8378 - val_accuracy: 0.7228 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8592 - accuracy: 0.7178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8313 - accuracy: 0.7233
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8307 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8270 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 77/487 [===&gt;..........................] - ETA: 1s - loss: 0.8282 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 96/487 [====&gt;.........................] - ETA: 1s - loss: 0.8307 - accuracy: 0.7248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
115/487 [======&gt;.......................] - ETA: 1s - loss: 0.8295 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/487 [=======&gt;......................] - ETA: 0s - loss: 0.8300 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
153/487 [========&gt;.....................] - ETA: 0s - loss: 0.8305 - accuracy: 0.7248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
171/487 [=========&gt;....................] - ETA: 0s - loss: 0.8300 - accuracy: 0.7250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
189/487 [==========&gt;...................] - ETA: 0s - loss: 0.8293 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
207/487 [===========&gt;..................] - ETA: 0s - loss: 0.8300 - accuracy: 0.7250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
224/487 [============&gt;.................] - ETA: 0s - loss: 0.8304 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/487 [=============&gt;................] - ETA: 0s - loss: 0.8306 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
255/487 [==============&gt;...............] - ETA: 0s - loss: 0.8312 - accuracy: 0.7244
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
273/487 [===============&gt;..............] - ETA: 0s - loss: 0.8319 - accuracy: 0.7240
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.8306 - accuracy: 0.7246
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
311/487 [==================&gt;...........] - ETA: 0s - loss: 0.8308 - accuracy: 0.7245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
329/487 [===================&gt;..........] - ETA: 0s - loss: 0.8310 - accuracy: 0.7244
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
348/487 [====================&gt;.........] - ETA: 0s - loss: 0.8310 - accuracy: 0.7241
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
367/487 [=====================&gt;........] - ETA: 0s - loss: 0.8315 - accuracy: 0.7238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/487 [======================&gt;.......] - ETA: 0s - loss: 0.8316 - accuracy: 0.7237
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
404/487 [=======================&gt;......] - ETA: 0s - loss: 0.8310 - accuracy: 0.7240
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
423/487 [=========================&gt;....] - ETA: 0s - loss: 0.8306 - accuracy: 0.7240
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
441/487 [==========================&gt;...] - ETA: 0s - loss: 0.8299 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
459/487 [===========================&gt;..] - ETA: 0s - loss: 0.8302 - accuracy: 0.7242
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
478/487 [============================&gt;.] - ETA: 0s - loss: 0.8298 - accuracy: 0.7243
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: val_loss improved from 0.83780 to 0.82954, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 4ms/step - loss: 0.8299 - accuracy: 0.7243 - val_loss: 0.8295 - val_accuracy: 0.7256 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8336 - accuracy: 0.7061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8254 - accuracy: 0.7265
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8257 - accuracy: 0.7267
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 57/487 [==&gt;...........................] - ETA: 1s - loss: 0.8245 - accuracy: 0.7269
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 75/487 [===&gt;..........................] - ETA: 1s - loss: 0.8260 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 94/487 [====&gt;.........................] - ETA: 1s - loss: 0.8262 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
112/487 [=====&gt;........................] - ETA: 1s - loss: 0.8260 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
131/487 [=======&gt;......................] - ETA: 0s - loss: 0.8260 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
149/487 [========&gt;.....................] - ETA: 0s - loss: 0.8241 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
168/487 [=========&gt;....................] - ETA: 0s - loss: 0.8238 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
186/487 [==========&gt;...................] - ETA: 0s - loss: 0.8252 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
204/487 [===========&gt;..................] - ETA: 0s - loss: 0.8251 - accuracy: 0.7253
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
222/487 [============&gt;.................] - ETA: 0s - loss: 0.8242 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
241/487 [=============&gt;................] - ETA: 0s - loss: 0.8247 - accuracy: 0.7256
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
260/487 [===============&gt;..............] - ETA: 0s - loss: 0.8252 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
279/487 [================&gt;.............] - ETA: 0s - loss: 0.8245 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
297/487 [=================&gt;............] - ETA: 0s - loss: 0.8244 - accuracy: 0.7255
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
315/487 [==================&gt;...........] - ETA: 0s - loss: 0.8248 - accuracy: 0.7252
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
334/487 [===================&gt;..........] - ETA: 0s - loss: 0.8242 - accuracy: 0.7254
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
353/487 [====================&gt;.........] - ETA: 0s - loss: 0.8238 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 0.8238 - accuracy: 0.7257
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
391/487 [=======================&gt;......] - ETA: 0s - loss: 0.8233 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
410/487 [========================&gt;.....] - ETA: 0s - loss: 0.8234 - accuracy: 0.7259
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
429/487 [=========================&gt;....] - ETA: 0s - loss: 0.8229 - accuracy: 0.7261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
448/487 [==========================&gt;...] - ETA: 0s - loss: 0.8226 - accuracy: 0.7262
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
465/487 [===========================&gt;..] - ETA: 0s - loss: 0.8223 - accuracy: 0.7262
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
483/487 [============================&gt;.] - ETA: 0s - loss: 0.8220 - accuracy: 0.7264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: val_loss improved from 0.82954 to 0.82225, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8220 - accuracy: 0.7263 - val_loss: 0.8222 - val_accuracy: 0.7270 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8205 - accuracy: 0.7461
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8137 - accuracy: 0.7326
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8155 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 58/487 [==&gt;...........................] - ETA: 1s - loss: 0.8183 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 77/487 [===&gt;..........................] - ETA: 1s - loss: 0.8191 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 96/487 [====&gt;.........................] - ETA: 1s - loss: 0.8183 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
115/487 [======&gt;.......................] - ETA: 1s - loss: 0.8182 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
134/487 [=======&gt;......................] - ETA: 0s - loss: 0.8189 - accuracy: 0.7273
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
153/487 [========&gt;.....................] - ETA: 0s - loss: 0.8181 - accuracy: 0.7271
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
173/487 [=========&gt;....................] - ETA: 0s - loss: 0.8175 - accuracy: 0.7274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
193/487 [==========&gt;...................] - ETA: 0s - loss: 0.8164 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
213/487 [============&gt;.................] - ETA: 0s - loss: 0.8163 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
233/487 [=============&gt;................] - ETA: 0s - loss: 0.8180 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
253/487 [==============&gt;...............] - ETA: 0s - loss: 0.8190 - accuracy: 0.7269
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
272/487 [===============&gt;..............] - ETA: 0s - loss: 0.8181 - accuracy: 0.7273
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
292/487 [================&gt;.............] - ETA: 0s - loss: 0.8172 - accuracy: 0.7277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
312/487 [==================&gt;...........] - ETA: 0s - loss: 0.8167 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
331/487 [===================&gt;..........] - ETA: 0s - loss: 0.8163 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
351/487 [====================&gt;.........] - ETA: 0s - loss: 0.8163 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
372/487 [=====================&gt;........] - ETA: 0s - loss: 0.8158 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
393/487 [=======================&gt;......] - ETA: 0s - loss: 0.8158 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
413/487 [========================&gt;.....] - ETA: 0s - loss: 0.8162 - accuracy: 0.7279
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
433/487 [=========================&gt;....] - ETA: 0s - loss: 0.8163 - accuracy: 0.7278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
453/487 [==========================&gt;...] - ETA: 0s - loss: 0.8156 - accuracy: 0.7280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
472/487 [============================&gt;.] - ETA: 0s - loss: 0.8150 - accuracy: 0.7282
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: val_loss improved from 0.82225 to 0.81557, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8150 - accuracy: 0.7282 - val_loss: 0.8156 - val_accuracy: 0.7286 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8110 - accuracy: 0.7275
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8125 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 39/487 [=&gt;............................] - ETA: 1s - loss: 0.8146 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 0.8117 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 0.8121 - accuracy: 0.7291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 0.8145 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 0.8150 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
136/487 [=======&gt;......................] - ETA: 0s - loss: 0.8142 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
155/487 [========&gt;.....................] - ETA: 0s - loss: 0.8152 - accuracy: 0.7281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
174/487 [=========&gt;....................] - ETA: 0s - loss: 0.8145 - accuracy: 0.7283
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
193/487 [==========&gt;...................] - ETA: 0s - loss: 0.8136 - accuracy: 0.7285
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
212/487 [============&gt;.................] - ETA: 0s - loss: 0.8134 - accuracy: 0.7284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
231/487 [=============&gt;................] - ETA: 0s - loss: 0.8128 - accuracy: 0.7286
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
251/487 [==============&gt;...............] - ETA: 0s - loss: 0.8130 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
270/487 [===============&gt;..............] - ETA: 0s - loss: 0.8128 - accuracy: 0.7287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
289/487 [================&gt;.............] - ETA: 0s - loss: 0.8126 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
308/487 [=================&gt;............] - ETA: 0s - loss: 0.8120 - accuracy: 0.7289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
327/487 [===================&gt;..........] - ETA: 0s - loss: 0.8119 - accuracy: 0.7290
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
346/487 [====================&gt;.........] - ETA: 0s - loss: 0.8109 - accuracy: 0.7293
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
365/487 [=====================&gt;........] - ETA: 0s - loss: 0.8101 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
385/487 [======================&gt;.......] - ETA: 0s - loss: 0.8098 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
405/487 [=======================&gt;......] - ETA: 0s - loss: 0.8097 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/487 [=========================&gt;....] - ETA: 0s - loss: 0.8093 - accuracy: 0.7297
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
443/487 [==========================&gt;...] - ETA: 0s - loss: 0.8094 - accuracy: 0.7296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
463/487 [===========================&gt;..] - ETA: 0s - loss: 0.8091 - accuracy: 0.7297
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
483/487 [============================&gt;.] - ETA: 0s - loss: 0.8086 - accuracy: 0.7298
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks***
saving losses to model_3/losses.log

Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: val_loss improved from 0.81557 to 0.80966, saving model to model_3/KERAS_check_best_model_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15: saving model to model_3/KERAS_check_model_last_weights.h5
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***callbacks end***


487/487 [==============================] - 2s 3ms/step - loss: 0.8086 - accuracy: 0.7299 - val_loss: 0.8097 - val_accuracy: 0.7300 - lr: 1.0000e-04
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/30
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 2s - loss: 0.8227 - accuracy: 0.7168
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 20/487 [&gt;.............................] - ETA: 1s - loss: 0.8092 - accuracy: 0.7264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 40/487 [=&gt;............................] - ETA: 1s - loss: 0.8105 - accuracy: 0.7276
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 59/487 [==&gt;...........................] - ETA: 1s - loss: 0.8104 - accuracy: 0.7272
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 78/487 [===&gt;..........................] - ETA: 1s - loss: 0.8075 - accuracy: 0.7295
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
 97/487 [====&gt;.........................] - ETA: 1s - loss: 0.8042 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
117/487 [======&gt;.......................] - ETA: 0s - loss: 0.8030 - accuracy: 0.7309
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
137/487 [=======&gt;......................] - ETA: 0s - loss: 0.8024 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
158/487 [========&gt;.....................] - ETA: 0s - loss: 0.8036 - accuracy: 0.7312
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
179/487 [==========&gt;...................] - ETA: 0s - loss: 0.8031 - accuracy: 0.7314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
200/487 [===========&gt;..................] - ETA: 0s - loss: 0.8017 - accuracy: 0.7317
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
221/487 [============&gt;.................] - ETA: 0s - loss: 0.8033 - accuracy: 0.7313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
242/487 [=============&gt;................] - ETA: 0s - loss: 0.8039 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
263/487 [===============&gt;..............] - ETA: 0s - loss: 0.8048 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
284/487 [================&gt;.............] - ETA: 0s - loss: 0.8047 - accuracy: 0.7306
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
304/487 [=================&gt;............] - ETA: 0s - loss: 0.8042 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
324/487 [==================&gt;...........] - ETA: 0s - loss: 0.8042 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
344/487 [====================&gt;.........] - ETA: 0s - loss: 0.8040 - accuracy: 0.7307
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
364/487 [=====================&gt;........] - ETA: 0s - loss: 0.8037 - accuracy: 0.7308
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
384/487 [======================&gt;.......] - ETA: 0s - loss: 0.8033 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
404/487 [=======================&gt;......] - ETA: 0s - loss: 0.8032 - accuracy: 0.7310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
424/487 [=========================&gt;....] - ETA: 0s - loss: 0.8034 - accuracy: 0.7310
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_5611</span><span class="o">/</span><span class="mf">3673671120.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">24</span>         <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>     <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/utils/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">64</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
<span class="g g-Whitespace">     </span><span class="mi">66</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ni">fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="g g-Whitespace">   </span><span class="mi">1407</span>                 <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1408</span>               <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1409</span>               <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1410</span>               <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1411</span>                 <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py</span> in <span class="ni">error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>       <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span>     <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>       <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">913</span> 
<span class="g g-Whitespace">    </span><span class="mi">914</span>       <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">915</span>         <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">916</span> 
<span class="g g-Whitespace">    </span><span class="mi">917</span>       <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py</span> in <span class="ni">_call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">945</span>       <span class="c1"># In this case we have created variables on the first call, so we run the</span>
<span class="g g-Whitespace">    </span><span class="mi">946</span>       <span class="c1"># defunned version which is guaranteed to never create variables.</span>
<span class="ne">--&gt; </span><span class="mi">947</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateless_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>     <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stateful_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span>       <span class="c1"># Release the lock early so that multiple threads can perform the call</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2452</span>        <span class="n">filtered_flat_args</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_define_function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2453</span>     <span class="k">return</span> <span class="n">graph_function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">2454</span>         <span class="n">filtered_flat_args</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">graph_function</span><span class="o">.</span><span class="n">captured_inputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">   </span><span class="mi">2455</span> 
<span class="g g-Whitespace">   </span><span class="mi">2456</span>   <span class="nd">@property</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">_call_flat</span><span class="nt">(self, args, captured_inputs, cancellation_manager)</span>
<span class="g g-Whitespace">   </span><span class="mi">1859</span>       <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="g g-Whitespace">   </span><span class="mi">1860</span>       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_call_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call</span><span class="p">(</span>
<span class="ne">-&gt; </span><span class="mi">1861</span>           <span class="n">ctx</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_manager</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1862</span>     <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1863</span>         <span class="n">args</span><span class="p">,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py</span> in <span class="ni">call</span><span class="nt">(self, ctx, args, cancellation_manager)</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span>               <span class="n">inputs</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>               <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">502</span>               <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>           <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/tensorflow/python/eager/execute.py</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>     <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>     <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">55</span>                                         <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>     <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-sparsity">
<h2>Check sparsity<a class="headerlink" href="#check-sparsity" title="Permalink to this headline">#</a></h2>
<p>Make a quick check that the model was indeed trained sparse. Well just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing 0. Note logarithmic y axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.75
</pre></div>
</div>
<img alt="_images/2.3_compression_12_1.png" src="_images/2.3_compression_12_1.png" />
</div>
</div>
<p>Compare this to the first model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_orig</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">w_orig</span> <span class="o">=</span> <span class="n">model_orig</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">_</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w_orig</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Original&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Pruned&quot;</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb44373f90&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_14_1.png" src="_images/2.3_compression_14_1.png" />
</div>
</div>
</section>
<section id="check-performance">
<h2>Check performance<a class="headerlink" href="#check-performance" title="Permalink to this headline">#</a></h2>
<p>How does this 75% sparse model compare against the unpruned model? Lets report the accuracy and make a ROC curve. The pruned model is shown with solid lines, the unpruned model is shown with dashed lines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned: 0.7516927710843373
Accuracy pruned:   0.7428975903614458
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb3f857d10&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_16_2.png" src="_images/2.3_compression_16_2.png" />
</div>
</div>
<section id="reduced-size-model">
<h3>Reduced size model<a class="headerlink" href="#reduced-size-model" title="Permalink to this headline">#</a></h3>
<p>What if instead of pruning our model we simply shrink the size? Lets now train a model where the hidden layers are a quarter of the size they are in the original model: 3 hidden layers with 16, then 8, then 8 neurons. Each layer will use <code class="docutils literal notranslate"><span class="pre">relu</span></code> activation.
Add an output layer with 5 neurons (one for each class), then finish with Softmax activation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_small</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">16</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc1&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu1&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc2&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu2&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fc3&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;relu3&quot;</span><span class="p">))</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">Dense</span><span class="p">(</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_uniform&quot;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">model_small</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_1_half&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_small</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model_small</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1_small/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
  1/487 [..............................] - ETA: 4:42 - loss: 1.5291 - accuracy: 0.3262WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>470/487 [===========================&gt;..] - ETA: 0s - loss: 1.4362 - accuracy: 0.3850
***callbacks***
saving losses to model_1_half/losses.log

Epoch 1: val_loss improved from inf to 1.34936, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 1.34936, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 1: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 1.4334 - accuracy: 0.3867 - val_loss: 1.3494 - val_accuracy: 0.4396 - lr: 1.0000e-04
Epoch 2/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.2798 - accuracy: 0.5151
***callbacks***
saving losses to model_1_half/losses.log

Epoch 2: val_loss improved from 1.34936 to 1.21631, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 1.34936 to 1.21631, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 2: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.2784 - accuracy: 0.5160 - val_loss: 1.2163 - val_accuracy: 0.5594 - lr: 1.0000e-04
Epoch 3/30
469/487 [===========================&gt;..] - ETA: 0s - loss: 1.1709 - accuracy: 0.5623
***callbacks***
saving losses to model_1_half/losses.log

Epoch 3: val_loss improved from 1.21631 to 1.12769, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 1.21631 to 1.12769, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 3: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.1693 - accuracy: 0.5627 - val_loss: 1.1277 - val_accuracy: 0.5736 - lr: 1.0000e-04
Epoch 4/30
478/487 [============================&gt;.] - ETA: 0s - loss: 1.0857 - accuracy: 0.6013
***callbacks***
saving losses to model_1_half/losses.log

Epoch 4: val_loss improved from 1.12769 to 1.04812, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 1.12769 to 1.04812, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 4: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 1.0851 - accuracy: 0.6021 - val_loss: 1.0481 - val_accuracy: 0.6488 - lr: 1.0000e-04
Epoch 5/30
474/487 [============================&gt;.] - ETA: 0s - loss: 1.0160 - accuracy: 0.6735
***callbacks***
saving losses to model_1_half/losses.log

Epoch 5: val_loss improved from 1.04812 to 0.99132, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 5: val_loss improved from 1.04812 to 0.99132, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 5: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 1.0155 - accuracy: 0.6739 - val_loss: 0.9913 - val_accuracy: 0.6873 - lr: 1.0000e-04
Epoch 6/30
487/487 [==============================] - ETA: 0s - loss: 0.9674 - accuracy: 0.6938
***callbacks***
saving losses to model_1_half/losses.log

Epoch 6: val_loss improved from 0.99132 to 0.95099, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 6: val_loss improved from 0.99132 to 0.95099, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 6: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 0.9674 - accuracy: 0.6938 - val_loss: 0.9510 - val_accuracy: 0.6983 - lr: 1.0000e-04
Epoch 7/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.9316 - accuracy: 0.7022
***callbacks***
saving losses to model_1_half/losses.log

Epoch 7: val_loss improved from 0.95099 to 0.91891, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 7: val_loss improved from 0.95099 to 0.91891, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 7: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 3ms/step - loss: 0.9312 - accuracy: 0.7023 - val_loss: 0.9189 - val_accuracy: 0.7051 - lr: 1.0000e-04
Epoch 8/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9022 - accuracy: 0.7086
***callbacks***
saving losses to model_1_half/losses.log

Epoch 8: val_loss improved from 0.91891 to 0.89320, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 8: val_loss improved from 0.91891 to 0.89320, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 8: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.9022 - accuracy: 0.7086 - val_loss: 0.8932 - val_accuracy: 0.7104 - lr: 1.0000e-04
Epoch 9/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8787 - accuracy: 0.7128
***callbacks***
saving losses to model_1_half/losses.log

Epoch 9: val_loss improved from 0.89320 to 0.87132, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 9: val_loss improved from 0.89320 to 0.87132, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 9: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8788 - accuracy: 0.7128 - val_loss: 0.8713 - val_accuracy: 0.7144 - lr: 1.0000e-04
Epoch 10/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8599 - accuracy: 0.7159
***callbacks***
saving losses to model_1_half/losses.log

Epoch 10: val_loss improved from 0.87132 to 0.85621, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 10: val_loss improved from 0.87132 to 0.85621, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_1_half/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8599 - accuracy: 0.7159 - val_loss: 0.8562 - val_accuracy: 0.7173 - lr: 1.0000e-04
Epoch 11/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.8471 - accuracy: 0.7182
***callbacks***
saving losses to model_1_half/losses.log

Epoch 11: val_loss improved from 0.85621 to 0.84522, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 11: val_loss improved from 0.85621 to 0.84522, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 11: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8470 - accuracy: 0.7183 - val_loss: 0.8452 - val_accuracy: 0.7187 - lr: 1.0000e-04
Epoch 12/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.8373 - accuracy: 0.7199
***callbacks***
saving losses to model_1_half/losses.log

Epoch 12: val_loss improved from 0.84522 to 0.83681, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 12: val_loss improved from 0.84522 to 0.83681, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 12: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 12: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8373 - accuracy: 0.7199 - val_loss: 0.8368 - val_accuracy: 0.7207 - lr: 1.0000e-04
Epoch 13/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8297 - accuracy: 0.7212
***callbacks***
saving losses to model_1_half/losses.log

Epoch 13: val_loss improved from 0.83681 to 0.82991, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 13: val_loss improved from 0.83681 to 0.82991, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 13: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 7ms/step - loss: 0.8296 - accuracy: 0.7212 - val_loss: 0.8299 - val_accuracy: 0.7218 - lr: 1.0000e-04
Epoch 14/30
473/487 [============================&gt;.] - ETA: 0s - loss: 0.8233 - accuracy: 0.7223
***callbacks***
saving losses to model_1_half/losses.log

Epoch 14: val_loss improved from 0.82991 to 0.82427, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 14: val_loss improved from 0.82991 to 0.82427, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 14: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.8234 - accuracy: 0.7223 - val_loss: 0.8243 - val_accuracy: 0.7225 - lr: 1.0000e-04
Epoch 15/30
474/487 [============================&gt;.] - ETA: 0s - loss: 0.8181 - accuracy: 0.7230
***callbacks***
saving losses to model_1_half/losses.log

Epoch 15: val_loss improved from 0.82427 to 0.81937, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 15: val_loss improved from 0.82427 to 0.81937, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 15: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.8182 - accuracy: 0.7230 - val_loss: 0.8194 - val_accuracy: 0.7234 - lr: 1.0000e-04
Epoch 16/30
487/487 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.7237
***callbacks***
saving losses to model_1_half/losses.log

Epoch 16: val_loss improved from 0.81937 to 0.81514, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 16: val_loss improved from 0.81937 to 0.81514, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 16: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8136 - accuracy: 0.7237 - val_loss: 0.8151 - val_accuracy: 0.7243 - lr: 1.0000e-04
Epoch 17/30
479/487 [============================&gt;.] - ETA: 0s - loss: 0.8095 - accuracy: 0.7245
***callbacks***
saving losses to model_1_half/losses.log

Epoch 17: val_loss improved from 0.81514 to 0.81146, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 17: val_loss improved from 0.81514 to 0.81146, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 17: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.8096 - accuracy: 0.7245 - val_loss: 0.8115 - val_accuracy: 0.7250 - lr: 1.0000e-04
Epoch 18/30
484/487 [============================&gt;.] - ETA: 0s - loss: 0.8058 - accuracy: 0.7251
***callbacks***
saving losses to model_1_half/losses.log

Epoch 18: val_loss improved from 0.81146 to 0.80808, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 18: val_loss improved from 0.81146 to 0.80808, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 18: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8060 - accuracy: 0.7251 - val_loss: 0.8081 - val_accuracy: 0.7253 - lr: 1.0000e-04
Epoch 19/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.8031 - accuracy: 0.7254
***callbacks***
saving losses to model_1_half/losses.log

Epoch 19: val_loss improved from 0.80808 to 0.80524, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 19: val_loss improved from 0.80808 to 0.80524, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 19: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.8029 - accuracy: 0.7255 - val_loss: 0.8052 - val_accuracy: 0.7259 - lr: 1.0000e-04
Epoch 20/30
477/487 [============================&gt;.] - ETA: 0s - loss: 0.8000 - accuracy: 0.7262
***callbacks***
saving losses to model_1_half/losses.log

Epoch 20: val_loss improved from 0.80524 to 0.80243, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 20: val_loss improved from 0.80524 to 0.80243, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_1_half/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.8000 - accuracy: 0.7262 - val_loss: 0.8024 - val_accuracy: 0.7263 - lr: 1.0000e-04
Epoch 21/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7975 - accuracy: 0.7269
***callbacks***
saving losses to model_1_half/losses.log

Epoch 21: val_loss improved from 0.80243 to 0.79994, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 21: val_loss improved from 0.80243 to 0.79994, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 21: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 8ms/step - loss: 0.7975 - accuracy: 0.7270 - val_loss: 0.7999 - val_accuracy: 0.7268 - lr: 1.0000e-04
Epoch 22/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.7951 - accuracy: 0.7275
***callbacks***
saving losses to model_1_half/losses.log

Epoch 22: val_loss improved from 0.79994 to 0.79778, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 22: val_loss improved from 0.79994 to 0.79778, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 22: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 9ms/step - loss: 0.7951 - accuracy: 0.7275 - val_loss: 0.7978 - val_accuracy: 0.7273 - lr: 1.0000e-04
Epoch 23/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.7931 - accuracy: 0.7279
***callbacks***
saving losses to model_1_half/losses.log

Epoch 23: val_loss improved from 0.79778 to 0.79573, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 23: val_loss improved from 0.79778 to 0.79573, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 23: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7930 - accuracy: 0.7280 - val_loss: 0.7957 - val_accuracy: 0.7280 - lr: 1.0000e-04
Epoch 24/30
487/487 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7286
***callbacks***
saving losses to model_1_half/losses.log

Epoch 24: val_loss improved from 0.79573 to 0.79387, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 24: val_loss improved from 0.79573 to 0.79387, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 24: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.7911 - accuracy: 0.7286 - val_loss: 0.7939 - val_accuracy: 0.7284 - lr: 1.0000e-04
Epoch 25/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7892 - accuracy: 0.7291
***callbacks***
saving losses to model_1_half/losses.log

Epoch 25: val_loss improved from 0.79387 to 0.79224, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 25: val_loss improved from 0.79387 to 0.79224, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 25: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.7892 - accuracy: 0.7291 - val_loss: 0.7922 - val_accuracy: 0.7287 - lr: 1.0000e-04
Epoch 26/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.7874 - accuracy: 0.7294
***callbacks***
saving losses to model_1_half/losses.log

Epoch 26: val_loss improved from 0.79224 to 0.79057, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 26: val_loss improved from 0.79224 to 0.79057, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 26: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 4s 7ms/step - loss: 0.7876 - accuracy: 0.7294 - val_loss: 0.7906 - val_accuracy: 0.7293 - lr: 1.0000e-04
Epoch 27/30
476/487 [============================&gt;.] - ETA: 0s - loss: 0.7862 - accuracy: 0.7299
***callbacks***
saving losses to model_1_half/losses.log

Epoch 27: val_loss improved from 0.79057 to 0.78915, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 27: val_loss improved from 0.79057 to 0.78915, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 27: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 7ms/step - loss: 0.7860 - accuracy: 0.7299 - val_loss: 0.7892 - val_accuracy: 0.7300 - lr: 1.0000e-04
Epoch 28/30
479/487 [============================&gt;.] - ETA: 0s - loss: 0.7844 - accuracy: 0.7305
***callbacks***
saving losses to model_1_half/losses.log

Epoch 28: val_loss improved from 0.78915 to 0.78767, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 28: val_loss improved from 0.78915 to 0.78767, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 28: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7845 - accuracy: 0.7304 - val_loss: 0.7877 - val_accuracy: 0.7299 - lr: 1.0000e-04
Epoch 29/30
471/487 [============================&gt;.] - ETA: 0s - loss: 0.7830 - accuracy: 0.7309
***callbacks***
saving losses to model_1_half/losses.log

Epoch 29: val_loss improved from 0.78767 to 0.78623, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 29: val_loss improved from 0.78767 to 0.78623, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 29: saving model to model_1_half/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 2s 5ms/step - loss: 0.7830 - accuracy: 0.7308 - val_loss: 0.7862 - val_accuracy: 0.7304 - lr: 1.0000e-04
Epoch 30/30
475/487 [============================&gt;.] - ETA: 0s - loss: 0.7819 - accuracy: 0.7311
***callbacks***
saving losses to model_1_half/losses.log

Epoch 30: val_loss improved from 0.78623 to 0.78488, saving model to model_1_half/KERAS_check_best_model.h5

Epoch 30: val_loss improved from 0.78623 to 0.78488, saving model to model_1_half/KERAS_check_best_model_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_1_half/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 2s 4ms/step - loss: 0.7816 - accuracy: 0.7312 - val_loss: 0.7849 - val_accuracy: 0.7310 - lr: 1.0000e-04
</pre></div>
</div>
</div>
</div>
<p>How does this small model compare in terms of performance?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_small</span> <span class="o">=</span> <span class="n">model_small</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned:   </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy small:    </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_small</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_small</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned: 0.7516927710843373
Accuracy pruned:   0.7456506024096385
Accuracy small:    0.7289518072289156
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb468b5590&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_21_2.png" src="_images/2.3_compression_21_2.png" />
</div>
</div>
<p>This looks quite good. Can we go further? Lets try a sparsity of 95%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prune</span><span class="p">,</span>
    <span class="n">pruning_callbacks</span><span class="p">,</span>
    <span class="n">pruning_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow_model_optimization.sparsity.keras</span> <span class="kn">import</span> <span class="n">strip_pruning</span>

<span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pruning_schedule&quot;</span><span class="p">:</span> <span class="n">pruning_schedule</span><span class="o">.</span><span class="n">ConstantSparsity</span><span class="p">(</span>
        <span class="mf">0.95</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span>
    <span class="p">)</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2>Train the model<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>Well use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.
The callbacks will decay the learning rate and save the model into a directory model_2
The model isnt very complex, so this should just take a few minutes even on the CPU.
If youve restarted the notebook kernel after training once, set <code class="docutils literal notranslate"><span class="pre">train</span> <span class="pre">=</span> <span class="pre">False</span></code> to load the trained model rather than training again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">],</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">all_callbacks</span><span class="p">(</span>
        <span class="n">stop_patience</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lr_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">lr_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">lr_epsilon</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span>
        <span class="n">lr_cooldown</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">lr_minimum</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span>
        <span class="n">outputDir</span><span class="o">=</span><span class="s2">&quot;model_4&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_train_val</span><span class="p">,</span>
        <span class="n">y_train_val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="o">.</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Save the model again but with the pruning &#39;stripped&#39; to use the regular layer types</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_4/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1/487 [..............................] - ETA: 17:22 - loss: 0.7500 - accuracy: 0.7529WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7544 - accuracy: 0.7454
***callbacks***
saving losses to model_4/losses.log

Epoch 1: val_loss improved from inf to 0.75678, saving model to model_4/KERAS_check_best_model.h5

Epoch 1: val_loss improved from inf to 0.75678, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 1: saving model to model_4/KERAS_check_model_last.h5

Epoch 1: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 5s 6ms/step - loss: 0.7541 - accuracy: 0.7455 - val_loss: 0.7568 - val_accuracy: 0.7454 - lr: 1.0000e-04
Epoch 2/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.7504 - accuracy: 0.7468
***callbacks***
saving losses to model_4/losses.log

Epoch 2: val_loss improved from 0.75678 to 0.75333, saving model to model_4/KERAS_check_best_model.h5

Epoch 2: val_loss improved from 0.75678 to 0.75333, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 2: saving model to model_4/KERAS_check_model_last.h5

Epoch 2: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7505 - accuracy: 0.7468 - val_loss: 0.7533 - val_accuracy: 0.7468 - lr: 1.0000e-04
Epoch 3/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.7473 - accuracy: 0.7477
***callbacks***
saving losses to model_4/losses.log

Epoch 3: val_loss improved from 0.75333 to 0.75063, saving model to model_4/KERAS_check_best_model.h5

Epoch 3: val_loss improved from 0.75333 to 0.75063, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 3: saving model to model_4/KERAS_check_model_last.h5

Epoch 3: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7473 - accuracy: 0.7477 - val_loss: 0.7506 - val_accuracy: 0.7478 - lr: 1.0000e-04
Epoch 4/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7487
***callbacks***
saving losses to model_4/losses.log

Epoch 4: val_loss improved from 0.75063 to 0.74790, saving model to model_4/KERAS_check_best_model.h5

Epoch 4: val_loss improved from 0.75063 to 0.74790, saving model to model_4/KERAS_check_best_model_weights.h5

Epoch 4: saving model to model_4/KERAS_check_model_last.h5

Epoch 4: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.7445 - accuracy: 0.7487 - val_loss: 0.7479 - val_accuracy: 0.7489 - lr: 1.0000e-04
Epoch 5/30
479/487 [============================&gt;.] - ETA: 0s - loss: 1.2867 - accuracy: 0.5367
***callbacks***
saving losses to model_4/losses.log

Epoch 5: val_loss did not improve from 0.74790

Epoch 5: val_loss did not improve from 0.74790

Epoch 5: saving model to model_4/KERAS_check_model_last.h5

Epoch 5: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.2865 - accuracy: 0.5369 - val_loss: 1.2808 - val_accuracy: 0.5486 - lr: 1.0000e-04
Epoch 6/30
485/487 [============================&gt;.] - ETA: 0s - loss: 1.2340 - accuracy: 0.5611
***callbacks***
saving losses to model_4/losses.log

Epoch 6: val_loss did not improve from 0.74790

Epoch 6: val_loss did not improve from 0.74790

Epoch 6: saving model to model_4/KERAS_check_model_last.h5

Epoch 6: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.2339 - accuracy: 0.5611 - val_loss: 1.1963 - val_accuracy: 0.5635 - lr: 1.0000e-04
Epoch 7/30
476/487 [============================&gt;.] - ETA: 0s - loss: 1.1660 - accuracy: 0.5707
***callbacks***
saving losses to model_4/losses.log

Epoch 7: val_loss did not improve from 0.74790

Epoch 7: val_loss did not improve from 0.74790

Epoch 7: saving model to model_4/KERAS_check_model_last.h5

Epoch 7: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.1655 - accuracy: 0.5708 - val_loss: 1.1432 - val_accuracy: 0.5714 - lr: 1.0000e-04
Epoch 8/30
482/487 [============================&gt;.] - ETA: 0s - loss: 1.1242 - accuracy: 0.5774
***callbacks***
saving losses to model_4/losses.log

Epoch 8: val_loss did not improve from 0.74790

Epoch 8: val_loss did not improve from 0.74790

Epoch 8: saving model to model_4/KERAS_check_model_last.h5

Epoch 8: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.1240 - accuracy: 0.5774 - val_loss: 1.1107 - val_accuracy: 0.5768 - lr: 1.0000e-04
Epoch 9/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0962 - accuracy: 0.5821
***callbacks***
saving losses to model_4/losses.log

Epoch 9: val_loss did not improve from 0.74790

Epoch 9: val_loss did not improve from 0.74790

Epoch 9: saving model to model_4/KERAS_check_model_last.h5

Epoch 9: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0961 - accuracy: 0.5822 - val_loss: 1.0869 - val_accuracy: 0.5809 - lr: 1.0000e-04
Epoch 10/30
485/487 [============================&gt;.] - ETA: 0s - loss: 1.0754 - accuracy: 0.5857
***callbacks***
saving losses to model_4/losses.log

Epoch 10: val_loss did not improve from 0.74790

Epoch 10: val_loss did not improve from 0.74790

Epoch 10: saving model to model_4/KERAS_check_model_last.h5

Epoch 10: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 10: saving model to model_4/KERAS_check_model_epoch10.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0754 - accuracy: 0.5858 - val_loss: 1.0690 - val_accuracy: 0.5836 - lr: 1.0000e-04
Epoch 11/30
483/487 [============================&gt;.] - ETA: 0s - loss: 1.0592 - accuracy: 0.5880
***callbacks***
saving losses to model_4/losses.log

Epoch 11: val_loss did not improve from 0.74790

Epoch 11: val_loss did not improve from 0.74790

Epoch 11: saving model to model_4/KERAS_check_model_last.h5

Epoch 11: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0592 - accuracy: 0.5880 - val_loss: 1.0543 - val_accuracy: 0.5860 - lr: 1.0000e-04
Epoch 12/30
486/487 [============================&gt;.] - ETA: 0s - loss: 1.0455 - accuracy: 0.5896
***callbacks***
saving losses to model_4/losses.log

Epoch 12: val_loss did not improve from 0.74790

Epoch 12: val_loss did not improve from 0.74790

Epoch 12: saving model to model_4/KERAS_check_model_last.h5

Epoch 12: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0455 - accuracy: 0.5896 - val_loss: 1.0416 - val_accuracy: 0.5875 - lr: 1.0000e-04
Epoch 13/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0330 - accuracy: 0.5906
***callbacks***
saving losses to model_4/losses.log

Epoch 13: val_loss did not improve from 0.74790

Epoch 13: val_loss did not improve from 0.74790

Epoch 13: saving model to model_4/KERAS_check_model_last.h5

Epoch 13: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 1.0329 - accuracy: 0.5907 - val_loss: 1.0290 - val_accuracy: 0.5889 - lr: 1.0000e-04
Epoch 14/30
480/487 [============================&gt;.] - ETA: 0s - loss: 1.0210 - accuracy: 0.5919
***callbacks***
saving losses to model_4/losses.log

Epoch 14: val_loss did not improve from 0.74790

Epoch 14: val_loss did not improve from 0.74790

Epoch 14: saving model to model_4/KERAS_check_model_last.h5

Epoch 14: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0209 - accuracy: 0.5918 - val_loss: 1.0178 - val_accuracy: 0.5901 - lr: 1.0000e-04
Epoch 15/30
484/487 [============================&gt;.] - ETA: 0s - loss: 1.0126 - accuracy: 0.5927
***callbacks***
saving losses to model_4/losses.log

Epoch 15: val_loss did not improve from 0.74790

Epoch 15: val_loss did not improve from 0.74790

Epoch 15: saving model to model_4/KERAS_check_model_last.h5

Epoch 15: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0126 - accuracy: 0.5928 - val_loss: 1.0123 - val_accuracy: 0.5905 - lr: 5.0000e-05
Epoch 16/30
479/487 [============================&gt;.] - ETA: 0s - loss: 1.0073 - accuracy: 0.5934
***callbacks***
saving losses to model_4/losses.log

Epoch 16: val_loss did not improve from 0.74790

Epoch 16: val_loss did not improve from 0.74790

Epoch 16: saving model to model_4/KERAS_check_model_last.h5

Epoch 16: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0072 - accuracy: 0.5932 - val_loss: 1.0069 - val_accuracy: 0.5912 - lr: 5.0000e-05
Epoch 17/30
486/487 [============================&gt;.] - ETA: 0s - loss: 1.0019 - accuracy: 0.5938
***callbacks***
saving losses to model_4/losses.log

Epoch 17: val_loss did not improve from 0.74790

Epoch 17: val_loss did not improve from 0.74790

Epoch 17: saving model to model_4/KERAS_check_model_last.h5

Epoch 17: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 1.0018 - accuracy: 0.5938 - val_loss: 1.0015 - val_accuracy: 0.5916 - lr: 5.0000e-05
Epoch 18/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9964 - accuracy: 0.5943
***callbacks***
saving losses to model_4/losses.log

Epoch 18: val_loss did not improve from 0.74790

Epoch 18: val_loss did not improve from 0.74790

Epoch 18: saving model to model_4/KERAS_check_model_last.h5

Epoch 18: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9965 - accuracy: 0.5942 - val_loss: 0.9963 - val_accuracy: 0.5921 - lr: 5.0000e-05
Epoch 19/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9916 - accuracy: 0.5945
***callbacks***
saving losses to model_4/losses.log

Epoch 19: val_loss did not improve from 0.74790

Epoch 19: val_loss did not improve from 0.74790

Epoch 19: saving model to model_4/KERAS_check_model_last.h5

Epoch 19: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9914 - accuracy: 0.5946 - val_loss: 0.9912 - val_accuracy: 0.5927 - lr: 5.0000e-05
Epoch 20/30
486/487 [============================&gt;.] - ETA: 0s - loss: 0.9864 - accuracy: 0.5951
***callbacks***
saving losses to model_4/losses.log

Epoch 20: val_loss did not improve from 0.74790

Epoch 20: val_loss did not improve from 0.74790

Epoch 20: saving model to model_4/KERAS_check_model_last.h5

Epoch 20: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 20: saving model to model_4/KERAS_check_model_epoch20.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9864 - accuracy: 0.5951 - val_loss: 0.9864 - val_accuracy: 0.5931 - lr: 5.0000e-05
Epoch 21/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9818 - accuracy: 0.5955
***callbacks***
saving losses to model_4/losses.log

Epoch 21: val_loss did not improve from 0.74790

Epoch 21: val_loss did not improve from 0.74790

Epoch 21: saving model to model_4/KERAS_check_model_last.h5

Epoch 21: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9817 - accuracy: 0.5955 - val_loss: 0.9818 - val_accuracy: 0.5934 - lr: 5.0000e-05
Epoch 22/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9772 - accuracy: 0.5959
***callbacks***
saving losses to model_4/losses.log

Epoch 22: val_loss did not improve from 0.74790

Epoch 22: val_loss did not improve from 0.74790

Epoch 22: saving model to model_4/KERAS_check_model_last.h5

Epoch 22: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.9772 - accuracy: 0.5959 - val_loss: 0.9774 - val_accuracy: 0.5938 - lr: 5.0000e-05
Epoch 23/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.9730 - accuracy: 0.5962
***callbacks***
saving losses to model_4/losses.log

Epoch 23: val_loss did not improve from 0.74790

Epoch 23: val_loss did not improve from 0.74790

Epoch 23: saving model to model_4/KERAS_check_model_last.h5

Epoch 23: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 5ms/step - loss: 0.9728 - accuracy: 0.5963 - val_loss: 0.9731 - val_accuracy: 0.5944 - lr: 5.0000e-05
Epoch 24/30
480/487 [============================&gt;.] - ETA: 0s - loss: 0.9687 - accuracy: 0.5966
***callbacks***
saving losses to model_4/losses.log

Epoch 24: val_loss did not improve from 0.74790

Epoch 24: val_loss did not improve from 0.74790

Epoch 24: saving model to model_4/KERAS_check_model_last.h5

Epoch 24: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9687 - accuracy: 0.5966 - val_loss: 0.9691 - val_accuracy: 0.5947 - lr: 5.0000e-05
Epoch 25/30
485/487 [============================&gt;.] - ETA: 0s - loss: 0.9648 - accuracy: 0.5969
***callbacks***
saving losses to model_4/losses.log

Epoch 25: val_loss did not improve from 0.74790

Epoch 25: val_loss did not improve from 0.74790

Epoch 25: saving model to model_4/KERAS_check_model_last.h5

Epoch 25: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9647 - accuracy: 0.5970 - val_loss: 0.9652 - val_accuracy: 0.5951 - lr: 5.0000e-05
Epoch 26/30
481/487 [============================&gt;.] - ETA: 0s - loss: 0.9616 - accuracy: 0.5973
***callbacks***
saving losses to model_4/losses.log

Epoch 26: val_loss did not improve from 0.74790

Epoch 26: val_loss did not improve from 0.74790

Epoch 26: saving model to model_4/KERAS_check_model_last.h5

Epoch 26: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9616 - accuracy: 0.5973 - val_loss: 0.9630 - val_accuracy: 0.5953 - lr: 2.5000e-05
Epoch 27/30
478/487 [============================&gt;.] - ETA: 0s - loss: 0.9594 - accuracy: 0.5975
***callbacks***
saving losses to model_4/losses.log

Epoch 27: val_loss did not improve from 0.74790

Epoch 27: val_loss did not improve from 0.74790

Epoch 27: saving model to model_4/KERAS_check_model_last.h5

Epoch 27: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9593 - accuracy: 0.5977 - val_loss: 0.9606 - val_accuracy: 0.5958 - lr: 2.5000e-05
Epoch 28/30
482/487 [============================&gt;.] - ETA: 0s - loss: 0.9569 - accuracy: 0.5984
***callbacks***
saving losses to model_4/losses.log

Epoch 28: val_loss did not improve from 0.74790

Epoch 28: val_loss did not improve from 0.74790

Epoch 28: saving model to model_4/KERAS_check_model_last.h5

Epoch 28: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9570 - accuracy: 0.5984 - val_loss: 0.9583 - val_accuracy: 0.5969 - lr: 2.5000e-05
Epoch 29/30
483/487 [============================&gt;.] - ETA: 0s - loss: 0.9547 - accuracy: 0.5999
***callbacks***
saving losses to model_4/losses.log

Epoch 29: val_loss did not improve from 0.74790

Epoch 29: val_loss did not improve from 0.74790

Epoch 29: saving model to model_4/KERAS_check_model_last.h5

Epoch 29: saving model to model_4/KERAS_check_model_last_weights.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9547 - accuracy: 0.5999 - val_loss: 0.9561 - val_accuracy: 0.5984 - lr: 2.5000e-05
Epoch 30/30
487/487 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6017
***callbacks***
saving losses to model_4/losses.log

Epoch 30: val_loss did not improve from 0.74790

Epoch 30: val_loss did not improve from 0.74790

Epoch 30: saving model to model_4/KERAS_check_model_last.h5

Epoch 30: saving model to model_4/KERAS_check_model_last_weights.h5

Epoch 30: saving model to model_4/KERAS_check_model_epoch30.h5

***callbacks end***

487/487 [==============================] - 3s 6ms/step - loss: 0.9524 - accuracy: 0.6017 - val_loss: 0.9538 - val_accuracy: 0.6002 - lr: 2.5000e-05
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>Check sparsity<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">h</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">b</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f zeros = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>% of zeros = 0.9501953125
</pre></div>
</div>
<img alt="_images/2.3_compression_27_1.png" src="_images/2.3_compression_27_1.png" />
</div>
</div>
</section>
<section id="id3">
<h2>Check performance<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p>How does this 95% sparse model compare against the other models?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model_ref</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_1/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>
<span class="n">model_prune75</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model_2/KERAS_check_best_model.h5&quot;</span><span class="p">)</span>

<span class="n">y_ref</span> <span class="o">=</span> <span class="n">model_ref</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune75</span> <span class="o">=</span> <span class="n">model_prune75</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prune95</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy unpruned:     </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_ref</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (75%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune75</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Accuracy pruned (95%): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_prune95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_ref</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune75</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prune95</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
<span class="kn">from</span> <span class="nn">matplotlib.legend</span> <span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span>
    <span class="n">ax</span><span class="p">,</span>
    <span class="n">lines</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;unpruned&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (75%)&quot;</span><span class="p">,</span> <span class="s2">&quot;pruned (95%)&quot;</span><span class="p">],</span>
    <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span>
    <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy unpruned:     0.7516927710843373
Accuracy pruned (75%): 0.7506325301204819
Accuracy pruned (95%): 0.6019036144578314
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7ffb3d85e050&gt;
</pre></div>
</div>
<img alt="_images/2.3_compression_29_2.png" src="_images/2.3_compression_29_2.png" />
</div>
</div>
<p>Ok, clearly 95% is too sparse for this model (at least using this scheme). For some classes you see that the performance is not terrible, but overall the performance loss is quite substantial.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2.2_advanced_config.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Advanced Configuration</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="2.4_quantization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Quantization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Javier Duarte, Dylan Rankin, and Patrick McCormack<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>